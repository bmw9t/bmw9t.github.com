<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Brandon Walsh</title>
 <link href="http://lanyon.getpoole.com/atom.xml" rel="self"/>
 <link href="http://lanyon.getpoole.com/"/>
 <updated>2018-04-27T20:11:44-04:00</updated>
 <id>http://lanyon.getpoole.com</id>
 <author>
   <name>Brandon Walsh</name>
   <email>walsh@virginia.edu</email>
 </author>

 
 <entry>
   <title>Frustration is a Feature</title>
   <link href="http://lanyon.getpoole.com/blog/2018/01/03/frustration/"/>
   <updated>2018-01-03T09:44:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2018/01/03/frustration</id>
   <content type="html">&lt;p&gt;&lt;em&gt;The following talk was given at MLA18 as a part of Panel 203: Anxious Pedagogies - Negotiating Precarity and Insecurity in the Classroom. Technically I suppose the title should be “Anxiety Is a Feature,” but the alliteration was too tempting.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/frustration/1.jpg&quot; alt=&quot;title slide&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Thanks for putting this panel together, Shawna. And thanks, all of you, for your thoughts - I’ve learned a lot from our exchanges leading up to this panel.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/frustration/2.jpg&quot; alt=&quot;Text: &amp;quot;What are you teaching you're students?&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I’m the Head of Graduate Programs in the Scholars’ Lab, a digital humanities center at the UVA Library. I want to come at the question of anxious pedagogies from the perspective of my role in the lab, where I often teach programming and DH skills and methods in addition to my primary duties, which are developing and administering the lab’s educational and professional development programs for graduate students. I work with students very self-consciously trying to step outside of their comfort zones, and I’d like to think about the anxieties associated with these cases in particular.&lt;/p&gt;

&lt;p&gt;I want to ask what, exactly, it is that we’re teaching our students. If you’re a sighted reader of English, your skin has probably been crawling due to the grammatical error in my slide here. And that’s part of the point - this error is the subject of memes (but it’s one I constantly make in emails). You might be embarrassed for me and wish someone had pointed it out to me ahead of time. Let’s explore that.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/frustration/3.jpg&quot; alt=&quot;Basic Python syntax error&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There’s a Python error of a similar kind in this slide. In programming, such small mistakes are major issues that can cause a project to fail. They’re also common for beginning programmers and DHers. A student has an error like this, and, quite understandably, they ask for help from the teacher. The instructor, as a human being, quite understandably wants to help. I want to talk about that moment - the point at which a student needs help and the nature of the contribution that we as colleagues and mentors are prepared to give.&lt;/p&gt;

&lt;p&gt;The ability to identify the kinds of problems I’m pointing out depends a lot on background and training. To expect such problems to be immediately identifiable makes a lot of assumptions about education, literacy, and background that no instructor should make. This is as true of the first example as in the second, which expects that someone has a background in programming and so knows that a computer would not be able to infer a relationship between the variables ‘fruit’ and ‘fruits’ - adding the extra ‘s’ in that last line by accident causes problems.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/frustration/4.jpg&quot; alt=&quot;XKCD comic about how every day 10,000 people learn something for the first time.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I have seen so many students stare, with mounting frustration, at chunks of code, feeling that they are beyond them, that issues in code represent some failing on their own part rather than a natural part of programming (we all make mistakes). Sure, my job is to teach them the skills with which they can solve these problems - the syntax that will prevent such errors in the future. But it’s also to help them recognize that no one is born knowing this stuff. Born knowing anything. And that such anxieties and frustrations are part of what all of us all deal with on a regular basis.&lt;/p&gt;

&lt;p&gt;I am not suggesting that we should approach such student frustration as feelings to be worked past or to be toughed out. Instead I want to suggest that the most important, radical act that we can make as teachers is to center frustration and anxiety in our teaching. This feeling, that of knowing something is there but not seeing it, or of knowing something is wrong but not how to address it, are central to the very idea of what it means to learn and to teach. Sianne Ngai might call these “ugly feelings” - those feelings that lead to no cathartic action and that are associated, instead, with pause, frustration, and paralysis.&lt;/p&gt;

&lt;p&gt;I’d suggest that our primary role as teachers is not to teach any particular content. Nor is our primary role to teach methods. Our ultimate aim should be to help students learn how to learn, how to keep going with the material outside the context of our courses. And, importantly, how to do this work with, through, and alongside such difficult emotions.&lt;/p&gt;

&lt;p&gt;In DH we often valorize failure and what can be learned from it, but it can be difficult to know how to deal with the feelings associated with it. I’ve tried to develop exercises (drawing upon the work of &lt;a href=&quot;http://waynegraham.github.io/&quot;&gt;Wayne Graham&lt;/a&gt;, &lt;a href=&quot;http://jeremyboggs.net/&quot;&gt;Jeremy Boggs&lt;/a&gt;, &lt;a href=&quot;http://literaturegeek.com/&quot;&gt;Amanda Visconti&lt;/a&gt;, and &lt;a href=&quot;http://nowviskie.org/&quot;&gt;Bethany Nowviskie&lt;/a&gt;) that help students sit with and think through the frustration and anxiety associated with failure. To teach web design, I ask students to draw a series of prototypes for websites using pencil and paper, some explicitly designed to fail, so as to develop a better sense of what it might mean for a website to succeed. Or I ask students to explore a set of programming exercises that have bugs artificially introduced to them as a way of helping them learn concrete steps for exploring problems in the face of mounting anxiety.&lt;/p&gt;

&lt;p&gt;I’d love to hear from all of you if you have any thoughts for how to center, rather than expel, frustration and anxiety from teaching, learning, and the classroom. These issues are especially salient while teaching programming to humanists, as the interdisciplinary nature of it requires people step out of their comfort zone. But as others on this panel have articulated so well, these issues extend to the whole person. Beyond the content we teach and the act of learning it - our students are living in states of continual anxiety. To say nothing of the personal, social, or systemic traumas to which many of them have been subjected about which we may never know.&lt;/p&gt;

&lt;p&gt;Most of what we do in the Scholars’ Lab is help students navigate these situations in a professional context. Most of what I do tends to revolve around convincing students that they are good enough. That they are qualified enough to &lt;a href=&quot;http://scholarslab.org/visiting-workshops-at-washington-and-lee-university/&quot;&gt;teach a workshops on DH&lt;/a&gt; or &lt;a href=&quot;http://scholarslab.org/professional-development/&quot;&gt;to apply for any number of DH or alt-ac jobs&lt;/a&gt;.  That a little goes a long way. That imposter syndrome is something felt by everyone. That their work has worth.&lt;/p&gt;

&lt;p&gt;There are a number of things we can do as administrators to help mitigate the anxieties of our students. Advocate for them by actively campaigning for the bureaucratic status to serve on committees, teach courses, and offer them the support that they need. Petition our legislatures and administrations for more just labor relations. Figure out the small bureaucratic things that translate to big pains for our students - things like delayed payments, long turnarounds on applications, gatekeeping practices.&lt;/p&gt;

&lt;p&gt;My point, our point, really, is that our students and colleagues are consistently in positions of anxiety and frustration - in and out of the classroom. So I’d ask what can we do to make our institutions, our classrooms, and our one-on-one interactions with our students more empathetic, but also more consciously aware of and engaged in the negative emotions they might bring out. Because as the title of this short talk suggests - frustration and anxiety are not pedagogical bugs. They are features. Woven into the very texture of what it means to be human and to be a learner. The question is - what are we prepared to do about it?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Collaborative Writing to Build Digital Humanities Praxis</title>
   <link href="http://lanyon.getpoole.com/blog/2017/08/04/collaborative-writing-to-build-digital-humanities-praxis/"/>
   <updated>2017-08-04T14:40:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2017/08/04/collaborative-writing-to-build-digital-humanities-praxis</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[The following is the rough text of my short paper given at the 2017 Digital Humanities conference in Montréal.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/collaborative-writing/1.jpg&quot; alt=&quot;title slide&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Thanks very much for having me today! I’m Brandon Walsh, Head of Graduate Programs in the Scholars’ Lab at the University of Virginia Library. I’ll be talking a bit today about “Collaborative Writing to Build Digital Humanities Praxis.” Since the subject here is collaboration I wanted to spend a few minutes here on my collaborators.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/collaborative-writing/2.jpg&quot; alt=&quot;thank you slide&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This work was begun at my previous position at Washington and Lee University’s library. My principal collaborator here is and was Professor Sarah Horowitz, from Washington and Lee University. We conceived the project together, co-taught the associated course, and her writing figures prominently on the project I will describe. The other names here are individuals, institutions, or projects who figure explicitly in the talk, whether they know it or not. You can find a Zotero collection with the resources mentioned during the talk &lt;a href=&quot;http://goo.gl/2CuWj7&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So. To begin. Emergent programs like those associated with the &lt;a href=&quot;http://praxis-network.org&quot;&gt;Praxis Network&lt;/a&gt; have redefined the possibilities for digital humanities training by offering models for project-based pedagogy. These efforts provide innovative institutional frameworks for building up and sharing digital skills, but they primarily focus on graduate or undergraduate education. They tend to think in terms of students. The long-term commitments that programs like these require can make them difficult to adapt for the professional development of other librarians, staff, and faculty collaborators. While members of these groups might share deep interests in undertaking such programs themselves, their institutional commitments often prevent them from committing the time to such professional development, particularly if the outcomes are not immediately legible for their own structures of reporting. I argue that we can make such praxis programs viable for broader communities by expanding the range of their potential outcomes and forms. In particular, I want to explore the potential for collaborative writing projects to develop individual skillsets and, by extension, the capacity of digital humanities programs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/collaborative-writing/3.jpg&quot; alt=&quot;coursebook site&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While the example here focuses on a coursebook written for an undergraduate audience, I believe the model and set of pedagogical issues can be extrapolated to other circumstances. By considering writing projects as potential opportunities for project-based development, I argue that we can produce professionally legible outcomes that both serve institutional priorities and prove useful beyond local contexts.&lt;/p&gt;

&lt;p&gt;The particular case study for this talk is an &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook&quot;&gt;open coursebook&lt;/a&gt; written for a course on digital text analysis (Walsh and Horowitz, 2016). In fall of 2015, Professor Sarah Horowitz, a colleague in the history department at Washington and Lee University, approached the University Library with an interest in digital text analysis and a desire to incorporate these methods in her upcoming class. She had a growing interest in the topic, and she wanted support to help her take these ideas and make them a reality in her research and teaching. As the Mellon Digital Humanities Fellow working in the University Library, I was asked to support Professor Horowitz’s requests because of my own background working with and teaching text analysis. Professor Horowitz and I conceived of writing the coursebook as a means by which the Library could meet her needs while also building the capacity of the University’s digital humanities resources. The idea was that, rather than offer her a handful of workshops, the two of us would co-author materials together that could then be used by Professor Horowitz later on. The writing of these materials would be the scene of the teaching and learning. Our model in this regard was as an initiative undertaken by the Digital Fellows at the CUNY Graduate Center, where their Graduate Fellows produce documentation and shared digital resources for the wider community. We aimed to expand upon their example, however, by making collaborative writing a centerpiece of our pedagogical experiment.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/collaborative-writing/4.jpg&quot; alt=&quot;tech stack&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We included Professor Horowitz directly in the creation of the course materials, a process that required her to engage in a variety of technologies central to a certain kind of web publishing workflow: command line, Markdown, Git, and GitHub. We produced the materials on a platform called &lt;a href=&quot;https://www.gitbook.com/&quot;&gt;GitBook&lt;/a&gt;, which provides a handy interface for writing that invokes many elements of this tech stack in a non-obtrusive way. Their editor allows you to write in markdown and previews the resultant text for you, but it also responds to the standard slew of MS Word keyboard shortcuts that many writers are familiar with. In this way we were able to keep the focus on the writing even as we slowly expanded Professor Horowitz’s ability to work directly with these technologies. From a writing standpoint, the process also required synthesis of both text analysis techniques and disciplinary material relevant to a course in nineteenth-century history. I provided the former, Professor Horowitz would review and critique as she added the latter, then I would review, etc. The result, I think, is more than either of us could have produced on our own, and we each learned a lot about the other’s subject matter. The result of the collaboration is that, after co-writing the materials and teaching the course together, Professor Horowitz is prepared to offer the course herself in the future without the support of the library. We now also possess course materials that, through careful structuring and selection of platforms, could be reusable in other courses at our own institutions and beyond. In this case, we tried to take special care to make each lesson stand on its own and to compartmentalize each topic according to the various parts of each class workshop. One section would introduce a topic from a theoretical standpoint, the next would offer a case study using a particular tool, and the last would offer course exercises that were particular to our course. We hoped this structuring would make it easy for the work to be excerpted and built upon by others for their own unique needs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/collaborative-writing/5.jpg&quot; alt=&quot;table of contents&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Writing collaborations such as these can fit the professional needs of people in a variety of spaces in the university. Course preparation, for example, often takes place behind the scenes and away from the eyes of students and other scholars. You tend to only see the final result as it is performed with students in a workshop or participants in a class. With a little effort, this hidden teaching labor can be transformed into openly available resources capable of being remixed into other contexts. We are following here on the example of Shawn Graham (2016), who has illustrated through his own resources for a class on &lt;a href=&quot;http://workbook.craftingdigitalhistory.ca/&quot;&gt;Crafting Digital History&lt;/a&gt; that course materials can be effectively leveraged to serve a wider good in ways that still parse in a professional context. In our case, the collaboration produced public-facing web writing in the form of an open educational resource. The history department regarded the project as a success for its potential to bring new courses, skills, and students into the major as a result of Professor Horowitz’s training. The University Library valued the collaboration for its production of open access materials, development of faculty skills, and exploration of workflows and platforms for faculty collaboration. We documented and managed the writing process in a &lt;a href=&quot;https://github.com/walshbr/introduction-to-text-analysis&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/collaborative-writing/6.jpg&quot; alt=&quot;GitHub repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This versioned workflow was key to our conception of the project, as we hoped to structure the project in such a way that others could copy down and spin up their own versions of the course materials for their own needs. We were careful to compartmentalize the lessons according to their focus on theory, application, or course exercises, and we provided &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/book/conclusion/adapting/&quot;&gt;documentation&lt;/a&gt; to walk readers through the technical process of adapting the book to reflect their own disciplinary content. We wrote reasonably detailed directions aimed at two different audiences - those with a tech background and those without. We wanted people to be able to pull down, tear apart, and reuse those pieces that were relevant for them. We hoped to create a mechanism by which readers and teachers could iterate using our materials to create their own versions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/collaborative-writing/7.jpg&quot; alt=&quot;Adapting the Book&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Writing projects like this one provide spaces for shared learning experiences that position student and teacher as equals. By writing in public and asking students and faculty collaborators to discuss, produce, and revise open educational resources, we can break down distinctions between writer and audience, teacher and student, programmer and non-programmer. In this spirit, work by Robin DeRosa (2016) with the &lt;a href=&quot;https://openamlit.pressbooks.com/&quot;&gt;Open Anthology of Earlier American Literature&lt;/a&gt; and Cathy Davidson with HASTAC has shown that students can make productive contributions to digital humanities research at the same time that they learn themselves. These contributions offer a more intimate form of pedagogy – a more caring and inviting form of building that can draw newcomers into the field by way of non-hierarchical peer mentoring. It is no secret that academia contains “severe power imbalances” that adversely affect teaching and the lives of instructors, students, and peers (McGill, 2016). I see collaborative writing as helping to create shared spaces of exploration that work against such structures of power. They can help to generate what Bethany Nowviskie (2016) has recently advocated as a turn towards a “feminist ethics of care” to “illuminate the relationships of small components, one to another, within great systems.” By writing together, teams engage in what Nowviskie (2011) calls the “perpetual peer review” of collaborative work. Through conversations about ethical collaboration and shared credit early in the process, we can privilege the voice of the learner as a valued contributor to a wider community of practitioners even before they might know the technical details of the tools or skills under discussion.&lt;/p&gt;

&lt;p&gt;Collaborative writing projects can thus serve as training in digital humanities praxis: they can help introduce the skills, tools, and theories associated with the field, and projects like ours do so in public. Productive failure in this space has long been a hallmark of work in the digital humanities, so much so that “Failure” was listed as a keyword in the new anthology Digital Pedagogy in the Humanities (Croxall and Warnick, 2016). Writing in public carries many of the same rewards – and risks. Many of those new to digital work, in particular, rightfully fear putting their work online before it is published. The clearest way in which we can invite people into the rewards of public digital work is by sharing the burdens and risks of such work. In her recent work on generous thinking, Kathleen Fitzpatrick (2016) has advocated for “thinking with rather than reflexively against both the people and the materials with which we work.” By framing digital humanities praxis first and foremost as an activity whose successes and failures are shared, we can lower the stakes for newcomers. Centering this approach to digital humanities pedagogy in the practice of writing productively displaces the very digital tools and methodologies that it is meant to teach. Even if the ultimate goal is to develop a firm grounding in a particular digital topic, focusing on the writing invites students and collaborators into a space where anyone can contribute. By privileging the writing rather than technical skills as the means of engagement and ultimate outcome, we can shape a more inviting and generous introduction to digital humanities praxis.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Croxall, B. and Warnick, Q. (2016). “Failure.” In Digital Pedagogy in the Humanities: Concepts, Models, and Experiments. Modern Languages Association.&lt;/li&gt;
  &lt;li&gt;DeRosa, R. (2016). “The Open Anthology of Earlier American Literature.” https://openamlit.pressbooks.com/.&lt;/li&gt;
  &lt;li&gt;Fitzpatrick, K. (2016). “Generous Thinking: The University and the Public Good.” Planned Obsolescence. http://www.plannedobsolescence.net/generous-thinking-the-university-and-the-public-good/.&lt;/li&gt;
  &lt;li&gt;Graham, S. (2016). “Crafting Digital History.” http://workbook.craftingdigitalhistory.ca/.&lt;/li&gt;
  &lt;li&gt;McGill, B. (2016). “Serial Bullies: An Academic Failing and the Need for Crowd-Sourced Truthtelling.” Dynamic Ecology. https://dynamicecology.wordpress.com/2016/10/18/serial-bullies-an-academic-failing-and-the-need-for-crowd-sourced-truthtelling/.&lt;/li&gt;
  &lt;li&gt;Nowviskie, B. (2011). “Where Credit Is Due.” http://nowviskie.org/2011/where-credit-is-due/.&lt;/li&gt;
  &lt;li&gt;———. 2016. “Capacity Through Care.” http://nowviskie.org/2016/capacity-through-care/.
Ramsay, S. (2010). “Learning to Program.” http://stephenramsay.us/2012/06/10/learning-to-program/.&lt;/li&gt;
  &lt;li&gt;———. 2014. “The Hermeneutics of Screwing Around; or What You Do with a Million Books.” In Pastplay: Teaching and Learning History with Technology, edited by Kevin Kee. University of Michigan Press. http://hdl.handle.net/2027/spo.12544152.0001.001.&lt;/li&gt;
  &lt;li&gt;The Praxis Network (2017). University of Virginia Library’s Scholars’ Lab. http://praxis-network.org/.
Walsh, Brandon, and Sarah Horowitz. 2016. “Introduction to Text Analysis: A Coursebook.” http://www.walshbr.com/textanalysiscoursebook&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Remixing the Sound Archive: Cut-up Poetry Recordings</title>
   <link href="http://lanyon.getpoole.com/blog/2017/06/16/remixing-the-sound-archive/"/>
   <updated>2017-06-16T13:47:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2017/06/16/remixing-the-sound-archive</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Recently I spoke at NEMLA 2017 with &lt;a href=&quot;http://www.sherwoodweb.org/&quot;&gt;Ken Sherwood&lt;/a&gt; and &lt;a href=&quot;https://www.english.upenn.edu/people/chris-mustazza&quot;&gt;Chris Mustazza&lt;/a&gt;. The panel was on “Pedagogy and Poetry Audio: DH Approaches to Teaching Recorded Poetry/Archives,” and my own contribution extended some &lt;a href=&quot;http://walshbr.com/blog/2015/01/12/deformance-talk/&quot;&gt;past experiments&lt;/a&gt; with using deformance as a mode of analysis for audio recordings. The talk was given from notes, but the following is a rough recreation of what took place.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Robust public sound archives have made a wide variety of material accessible to students and researchers for the first time, and they provide helpful records of the history of poetic performance throughout the past century. But they can also appear overwhelming in their magnitude, particularly for students: where to begin listening? How to begin analyzing any recording, let alone multiple recordings in relation to each other? This talk argues that we can help students start to explore these archives if we think about them as more than just an account of past performances: sound collections can provide the materials for resonant experiments in audio composition. I want to think about new ways to explore these archives through automatic means, through the use of software that algorithmically explores the sound collection as an object of study by tampering with it, dismantling it, and reassembling it. In the process, we might just uncover new interpretive dimensions.&lt;/p&gt;

&lt;p&gt;This talk thus models an approach to poetry recordings founded in the deformance theories of Jerome McGann and Lisa Samuels and the cut-up techniques of the Dadaists. I prototype a pair of class assignments that ask students to slice up audio recordings of a particular poet, reassemble them into their own compositions, and reflect on the process. These acts of playful destruction and reconstruction help students think about poems as constructed sound objects and about poets as sound artists. By diving deeply into the extant record for a particular poet, students might produce performative audio essays that enact a reading of that artist’s sonic patterns. By treating sound archives as the raw ingredients for poetic remixes, we can explore and remake sound objects while also gaining new critical insight into performance practices. In the process of remixing the sound archive, we can encourage students to engage more fully with it. And while I frame this in terms of student work and pedagogy given the topic of the panel, it should become clear that I think of this as a useful research practice in its own right.&lt;/p&gt;

&lt;p&gt;I will frame the interventions and theoretical frameworks I am making before proposing two different models for how to approach such an assignment depending on the instructor’s own technical ability and pedagogical goals: one model that uses Audacity and another that uses Python to cut and reassemble poetry recordings. I will demonstrate example compositions from the latter. It will get weird.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide02.jpg&quot; alt=&quot;provocations for the talk&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are two provocations at the center of my talk founded in an assumption about the way students hear poetry recordings. In my experience, they often hear recordings not as sound artifacts but as representations of text. They might come to these recordings looking to hear the poet herself speak, or they might be looking to get new perspectives on the poem. But they fundamentally are interested in hearing a new version of a printed text, in hearing these things as analogues to print. This is all well and good - the connection to a text is clearly a part of what makes poetry recordings special, but I think our challenge as teachers and thinkers of poetry is to help students surface the sounded quality of the artifacts, to learn to dig deeper into digital sound in particular.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide03.jpg&quot; alt=&quot;provocations 2 - work in the medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My approach to this need - the need to get students to look beyond the text and towards the sound - is to get them working with these materials as heard objects. We are going to engage them in the medium. They are going to get their hands dirty. We are going to take sound - which might seem abstract and amorphous - and make it something they can touch, take apart, and reassemble. They are going to think about sound as something concrete and constructed by engaging in that very act of construction.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide04.jpg&quot; alt=&quot;audacity icon slide&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One approach to this might be to use a tool like &lt;a href=&quot;http://www.audacityteam.org/&quot;&gt;Audacity&lt;/a&gt;. If you’re not familiar, Audacity is an open source tool that lets you input sound clips and then edit them in a pared down interface. If you have an MP3 on your computer, right click it to open it in Audacity, and you will get something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide05.jpg&quot; alt=&quot;waveform in audacity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A waveform. Already we are a bit alienated from the text because this visualization doesn not really allow you to access the text of the poem as such. Interacting with the poem becomes akin to touching a visual representation of sound waves. Now, you can’t do everything in Audacity, and that’s what I like about it. When I was a music student in college I remember getting introduced to some pretty beefy sound software - &lt;a href=&quot;http://www.avid.com/pro-tools&quot;&gt;Pro Tools&lt;/a&gt; and &lt;a href=&quot;http://www.motu.com/products/software/dp&quot;&gt;Digital Performer&lt;/a&gt;. I also remember feeling pretty overwhelmed by what they had to offer. So many options! Hundreds and thousands of things to click on! What I like about Audacity is that it is a bit more stripped down. Instead of giving you all the potential options for working with sound, it does a smaller subset really well. Record, edit, mix, etc. Audacity is also open source, so it is free while the other ones are quite expensive.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide06.jpg&quot; alt=&quot;first assignment in audacity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I would suggest having your students engage with recordings using this software. Here is an example assignment you might put together that asks them to put together an audio essay. Using Audacity, I would have them assemble their own sound recording that mixes in examples from other poetry recordings under examination. You might frame the exercise by having them work through a tutorial on editing audio with audacity that I put together for &lt;a href=&quot;http://programminghistorian.org/lessons/editing-audio-with-audacity&quot;&gt;The Programming Historian&lt;/a&gt;. The Programming Historian provides tutorials for a variety of digital humanities tools and methods, so this piece on Audacity is meant for absolute beginners. It coaches people through working with the interface, and, over the course of the lesson, readers produce a small podcast.&lt;/p&gt;

&lt;p&gt;The lesson asks readers to use a stub Bach recording, but I would adapt it to have students assemble an essay that analyzes a poetic sound recording relevant to the course material. Instead of writing a paper on a recording, the students actually integrate their audible evidence into a new sound object, assembling the podcast by hand. Citation and description can join together in this model, and I can imagine having a student pay close attention to the audible qualities of the sounds they are discussing. The sky is the limit, but, personally, I like to imagine students analyzing TS Eliot’s voice by mimicking his style. Or you could imagine an analysis of his accent that tries to position his sense of locality, nation, and the globe by examining clips from a number of his recordings alongside clips of other speakers from around the world.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide07.jpg&quot; alt=&quot;pros and cons of audacity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I see several benefits to having students work in this way. Students could learn a lot about Audacity producing these kinds of audio essays, and anyone planning to work with audio in the future should possess some experience with this fundamental tool. The wealth of resources for Audacity mean that it is well-suited for beginners. There are far more substantial tutorials for the software besides my own, so students would be well supported to take on this reasonably intuitive interface.&lt;/p&gt;

&lt;p&gt;But there are also limitations here. For one, this type of engagement is a really slow process. Your students, after all, are engaging with a medium that they can only really experience in time. If you are working with four hours of recordings, you really have to have listened to all or most of that sound to work with it in a meaningful way. And to make anything useful, they will probably want to have listened to it multiple times and have made some notes. That is an extraordinary amount of time and energy, and we might be able to do better.&lt;/p&gt;

&lt;p&gt;In addition, the assembling process is deliberate. You are asking students to put together clips bit by bit in accordance with a particular reading. And this is the real problem that I want to address - the medium here is unlikely to show you anything new. It is meant to illustrate a reading you already have. You want to produce an interpretation, so you illustrate it with sound. The theory comes first - the praxis second.&lt;/p&gt;

&lt;p&gt;So I want to ask: what are some other ways we can work with audio that might show us truly new things? And how can we get around the need to listen slowly? The &lt;a href=&quot;https://blogs.ischool.utexas.edu/hipstas/publications/&quot;&gt;work by Tanya Clement and HiPSTAS&lt;/a&gt; offer compelling examples for distant listening and audio machine learning as answers to these questions. I want to offer an approach based on creativity and play. By embracing chance-based composition techniques at scale, we can start to develop more useful classroom assignments for audio.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide08.jpg&quot; alt=&quot;deformance quotation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In shifting the interpretative dimensions in this way, I am drawing on an idea that comes from Jerome McGann and Lisa Samuels: deformance. At the heart of their essay on “&lt;a href=&quot;http://www2.iath.virginia.edu/jjm2f/old/deform.html&quot;&gt;Deformance and Interpretation&lt;/a&gt;” is a quote from Emily Dickinson:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Did you ever read one of her Poems backward, because the plunge from the front overturned you? I sometimes (often have, many times) have — a Something overtakes the Mind –”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;McGann and Samuels take her very literally, and they proceed to model how reading a poem backwards, line by line, can offer generative readings. This process illustrated two main ideas. The first was that reading destructively and deformatively in this way exposes new parts of the poetry that you might not otherwise notice. You get a renewed sense of the constructedness of a poem, and the materiality of it rises to the surface. By reshaping, warping, or demolishing a poem, you actually learned something about its material components and, thus, the original poem itself. The second idea was that all acts of interpretation remade their objects of study in this way. By interpreting, the poem and our sense of it changed. So destructive reading performs this process in the fullest sense by enacting an interpretation that literally changes the shape or nature of the object. For a fuller history and more satisfying explanation of the interpretive dimensions of audio deformance for research, check out “&lt;a href=&quot;https://soundstudiesblog.com/2016/10/24/in-different-voices-vocal-deformance-and-performative-speech/&quot;&gt;Vocal Deformance and Performative Speech, or In Different Voices!&lt;/a&gt;” posted by Marit J. MacArthurt and Lee M. Miller over at &lt;em&gt;Sounding Out&lt;/em&gt;. They also work with T.S. Eliot, though they they are working with recordings by him rather than those done by amateur readers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide09.jpg&quot; alt=&quot;cut up poetry&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In thinking about this performative form of reading, I was struck at how similar it sounded to cut-up poetry, the practice of slicing apart and rearranging the text of a poem so as to create new materials as popularized by the Dadaists and William S. Burroughs. To make the link to the Audacity assignments I was discussing earlier, I became interested in how this kind of performative, random, and destructive form of reading might extend the experiments in listening that I discussed with Audacity. Rather than having students purposefully rearrange a sound recording themselves, perhaps we could release our control over the audio artifact. We would still engage students in the texture of the medium, but we would ask them to let their analysis and their manifestation of that thinking grow a little closer together. We would invite play and the unknown into the process.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide10.jpg&quot; alt=&quot;provocations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So we will ask them to engage in the material aspects of poetry by interacting with it as a physical, constructed thing. But the engagement will be different. We will have them engage. We will have them warp. We will have them cut up. Rather than using scissors, we will let a computer program do the slicing for us. The algorithm that goes into that program will offer our interpretive intervention, and we will surrender control over it just a bit, with the understanding that doing so will offer up new interpretive dimensions later on.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide11.jpg&quot; alt=&quot;python as a solution&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My approach to this was to use computer programs written in Python - a tool that allowed ways around some of the limitations that I already noted for working with Audacity. By working with a computer program I was able to produce something that could read hours of audio far quicker than I could. Python also allowed me to repurpose extant audio software packages to manipulate the audio according to my own algorithms/interpretations. In this case, I was working with &lt;a href=&quot;https://github.com/antiboredom/audiogrep&quot;&gt;Audiogrep&lt;/a&gt; and &lt;a href=&quot;https://github.com/jiaaro/pydub&quot;&gt;Pydub&lt;/a&gt;. I did not need to reinvent the wheel, as I could let these packages do the heavy lifting for me. In fact, a lot of what I did here was just manipulate the extant documentation and code examples for the tools in ways that felt intellectually satisfying. The programming became an interpretive intervention in its own right that, as I will show, brought with it all sorts of serendipitous problems. All the code I used is available &lt;a href=&quot;https://gist.github.com/walshbr/cbcdabc92995334ae52414d048ae5d92&quot;&gt;as a gist&lt;/a&gt; – it took some tinkering to get running, and it will not run for you out of the box without some manipulation. So feel free to get in touch if you wanted to try these things yourself. I can offer lessons learned!&lt;/p&gt;

&lt;p&gt;In working with these tools, it quickly became clear that I needed to spend time exploring their possibilities, playing with to see what I could do. In that spirit, I will do something a bit different for the remainder of this piece. Rather than give an assignment example up front, I will share some of the things you can do to audio with Python and why they might be meaningful from an interpretive standpoint. Then I will offer reflections at the end. My workflow was as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;I assembled a small corpus of sound artifacts – in this case, all the recordings of The Waste Land recorded by amateur readers on &lt;a href=&quot;https://librivox.org/&quot;&gt;LibriVox&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;I installed and configured the packages to get my Python scripts running.&lt;/li&gt;
  &lt;li&gt;Then I started playing, exploring all the options these Python packages had.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first step of this process involves having the script read in all the recordings so that they can be transcribed. To do so, Audiogrep calls another piece of software called &lt;a href=&quot;https://github.com/cmusphinx/pocketsphinx&quot;&gt;Pocketsphinx&lt;/a&gt; behind the scenes. The resulting transcriptions look like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if it is a litter box recording
&amp;lt;s&amp;gt; 4.570 4.590 0.999800
if 4.600 4.810 0.489886
it 4.820 4.870 0.127322
is 4.880 4.960 0.662690
a 4.970 5.000 0.372315
litter 5.010 5.340 0.939406
box 5.350 5.740 0.992825
recording(2) 5.750 6.360 0.551414
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The results show us that audio transcription, obviously, is a vexed process, just as OCR is a troubled way of interacting with print text. What you see here is a segment from the transcription along with a series of words that the program thinks it heard. In this case, the actual audio “This is a librivox recording” becomes heard by the computer as “If it is a litter box recording” Although my cat might be proud, this shows pretty clearly that the process of working algorithmically is inaccurate. In this case, listening with Python exposes what Ryan Cordell or Matthew Kirschenbaum might describe as the traces that the digital methods leave on the artifacts as we work with them. Here is the longer excerpt of the Audiogrep transcription for this particular recording of &lt;em&gt;The Wasteland&lt;/em&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;the wasteland
i t. s. eliot
if it is a litter box recording
oliver box recordings are in the public domain
for more information or to volunteer
these visits litter box dot org
according my elizabeth client
the wasteland
i t. s. eliot
section one
ariel of the dead
april is the cruelest month
reading lie lacks out of the dead land mixing memory and designer
staring down roots with spring rain
winter kept us warm
having earth and forgetful snow
feeding a little life with tribes two birds
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Lots of problems here. We could say that to listen algorithmically is to do entwine signal with noise, and, personally, I think this is great! From an interpretive standpoint, this exposes artifacts from the remaking process and shows how each intervention in the text remakes it. In a deformance theory of interpretation, you cannot work with a text without changing it, and the same is true of audio. In this case, the object literally transforms. Also note that multiple recordings will be transcribed differently. Every attempt to read the text through Python produces a new text, right in line with the performative interpretations that McGann and Samuels describe. Regional accents would produce new and different texts depending on the program’s ability to map them onto recognized words.&lt;/p&gt;

&lt;p&gt;But you can do much more than just transcribe things with Python. When this package transcribes words, it tags each of the words with a timestamp. So you can disassemble and reassemble the text at will, using these timestamps as hooks for guiding the program. Rather than painstakingly assembling readings by hand, you could search across the recording in the same way that you might a text file. Here is an example of what you can do with one of Audiogrep’s baked in functions - you can create supercuts of a single word or cluster of related words:&lt;/p&gt;

&lt;audio controls=&quot;&quot;&gt;
	&lt;source src=&quot;/assets/mp3s/nemla/voice-sound-supercut.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;
	&lt;source src=&quot;/assets/ogg/nemla/voice-sound-supercut.ogg&quot; type=&quot;audio/ogg&quot; /&gt;Your browser does not support this audio format.
&lt;/audio&gt;

&lt;p&gt;Sam Lavigne has other examples of similar audio mashups on &lt;a href=&quot;http://lav.io/2015/02/audiogrep-automatic-audio-supercuts/&quot;&gt;his site&lt;/a&gt; describing what you can do with Audiogrep. In this case, I’ve searched across all the recordings for instances of “sound” and “voice” and mashed up all those instances. You can also use regular expressions to search, allowing for pretty complicated ways of navigating a recording. Keep in mind that this is only searching across the transcriptions, which we already noted were inaccurate. So it is proper to say that this method is not telling you something about the text so much as about the recordings themselves. The program is producing a performative reading of what it understands the texts behind the audio to be. The script allows you to compare multiple recordings in a particular way that would be pretty painstaking to do by hand, but the process is imperfect and prone to error. Still, I find this to be a useful tool for collating the intonations and cadences of different readers. I am particularly interested in how amateur readers perform and re-perform the text in their own unique ways. This method allows me to ask, for example, whether all readers sonically interpret a particular line in the same or different ways.&lt;/p&gt;

&lt;p&gt;You can also have the program create your own, new sound artifacts drawing upon the elements of the originals. Since we have all the transcriptions, we can also create performative readings of our own. Rather than getting all instances of one word, we can put together a new text and have it spoken through the individual sound clips drawn from our input. Before playing the result, read through what I wrote.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Approaching sound in this way is a way for our students to reconstitute their own ideas through the very sound artifacts that they are studying. In so doing, they learn to consider them as sound, as material objects that can be turned over, re-examined, disrupted, and reassembled. But look at how much is gone. How much gets lost. The recording is notable for its absences, its gaps.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That should give you a hint about what kind of recording is about to come out. What follows is the program’s best attempt to recreate my passage using only words spoken by LibriVox readers as they perform Eliot’s text.&lt;/p&gt;

&lt;audio controls=&quot;&quot;&gt;
	&lt;source src=&quot;/assets/mp3s/nemla/speaking-with-text.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;
	&lt;source src=&quot;/assets/ogg/nemla/speaking-with-text.ogg&quot; type=&quot;audio/ogg&quot; /&gt;Your browser does not support this audio format.
&lt;/audio&gt;

&lt;p&gt;The recording itself performs the idea, which is that working in Python in this way produces a reading that is somewhat out of control of the user. You cannot really account ahead of time for what will be warped and misshaped, but some distortion is inevitable. By passing the program the passage, it will search through for instances of each word and try to reassemble them into a whole. The reading becomes the recording. But we are asking the computer to do something when it does not have all the elements it needs to complete the task - we have asked it build a house, but we have given it no material for doors or windows. The result is a garbled mess, but you can still make out a few words here and there that are familiar. We hear a few things that are recognizable, but we also get a lot of silences and noise, what we might think of as the frictions produced by the gaps between what the script recognizes correctly and what it does not. The result is sound art as much as sound interpretation.&lt;/p&gt;

&lt;p&gt;One last one. This one is a bit frightening.&lt;/p&gt;

&lt;audio controls=&quot;&quot;&gt;
	&lt;source src=&quot;/assets/mp3s/nemla/demon-voice.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;
	&lt;source src=&quot;/assets/ogg/nemla/demon-voice.ogg&quot; type=&quot;audio/ogg&quot; /&gt;Your browser does not support this audio format.
&lt;/audio&gt;

&lt;p&gt;While trying to mash up all the silences in the recording to get a supercut of people breathing, I made a conversion error. Because of my mistake, I accidentally dropped a millisecond every five or six milliseconds in the recording rather than dropping only the pieces of spoken word. From this I learned how to make any recording sound like a demon. I think moments of serendipity like this are crucial, because they expose the recording as a recording. This effect almost sounds analogous to the sort of artifacts that might get accidentally created in the recording process. The process of approaching the recording leaves nothing unchanged, but, if we are mindful of these transformations, we can use them in the service of discovery.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide17.jpg&quot; alt=&quot;reviewing what you can do with Python&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So, to review: you can use Python to create supercuts of particular words, to perform readings of a text, to expose artifacts from the recording and transcription process, or to create demons. So my assignment for python might go something like this.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide18.jpg&quot; alt=&quot;sample (joke) assignment with Python audio&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Take some recordings and play around. I think you get the most out of a research method like this by letting the praxis generate the theory. Then let the outcomes reflect and revise the theory. Your students can serendipitously learn new things from these sorts of experiments, even if they might seem silly. Instead of shying away from the failures involved in transforming sound recordings into transcriptions and back again, I propose that we instead take a Joycean approach that “errors are volitional and are the portals of discovery.” The exercise could ask you to consider the traces of digital remediation that are present in the artifacts themselves. Or, it could generate a discussion of regionalism and accents of the Librivox participants that threw the transcriber off. To go further (on the excellent question/suggestion of a NEMLA audience member), this process could expose the fact that, in transcribing audio, the program favors particular pronunciations and silences those voices who do not accord with its linguistic sense of “proper” English. You might get a new sense of the particular vocabulary of recorded words in a text, and what it leaves out. Or you might get a renewed sense of how interpretation is a two-way street that changes our texts as we take them in.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/nemla/slide19.jpg&quot; alt=&quot;pros and cons of using python for this&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So Python offers some robust ways of working with audio through some packages that are ready to go. This lets you scale up quickly and try new things, but it is worth noting that these methods require far more technical overhead than using Audacity. For this reason, I mentioned training wheels above. Depending on your course, it might be too much to ask students to program in Python from scratch for an assignment like this. So you might offer them starter functions or detailed guides so they do not need to implement the whole thing themselves. The hands-off approach here might be more than some instructors or researchers are willing to allow. Furthermore, while I do think these methods are appropriate for scaling up an examination of audio recordings to compare many different audio artifacts, there are &lt;a href=&quot;https://github.com/jiaaro/pydub/issues/135&quot;&gt;important limitations&lt;/a&gt; in the Python audio packages that, without significant tinkering, limit the size of the audio corpus you can work with.&lt;/p&gt;

&lt;p&gt;For me, though, the possibilities of these approaches are generative enough to work around these limitations. Methods like these are useful for exposing students to sound archives as more than just pieces of cultural history but also as materials to be used, re-used, and remixed into their own work. I have deliberately chosen as my examples here only recordings of texts as given by amateur readers to suggest that these materials have always been performed and re-preformed. The assignments above ask students to place themselves in this tradition of recreation, and the approach invites them to view these interventions with a sense of exploration and humor.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What Should You Do in a Week?</title>
   <link href="http://lanyon.getpoole.com/blog/2017/06/03/what-should-you-do-in-a-week/"/>
   <updated>2017-06-03T20:17:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2017/06/03/what-should-you-do-in-a-week</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted to the &lt;a href=&quot;http://scholarslab.org/digital-humanities/what-should-you-do-in-a-week/&quot;&gt;Scholars’ Lab blog&lt;/a&gt;.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For the past several years, I’ve taught a &lt;a href=&quot;http://humanitiesprogramming.github.io&quot;&gt;Humanities Programming&lt;/a&gt; course at &lt;a href=&quot;http://www.dhtraining.org/&quot;&gt;HILT&lt;/a&gt;. The course was piloted by Wayne Graham and Jeremy Boggs, but, these days, I co-teach the course with &lt;a href=&quot;http://scholarslab.org/people/ethan-reed/&quot;&gt;Ethan Reed&lt;/a&gt;, one of our DH fellows in the Scholars’ Lab. The course is a soup-to-nuts introduction to the kinds of methods and technologies that are useful for humanities programming. We’re changing the course a fair amount this year, so I thought I’d offer a few notes on what we’re doing and the pedagogical motivations for doing so. You can find our syllabus, slides, resources, and more on &lt;a href=&quot;https://humanitiesprogramming.github.io/syllabus/&quot;&gt;the site&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We broke the course down into two halves:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics: command line, Git, GitHub, HTML/CSS
    &lt;ul&gt;
      &lt;li&gt;Project: personal website&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Programming concepts: Ruby
    &lt;ul&gt;
      &lt;li&gt;Project: Rails application deployed through Heroku and up on GitHub&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the first half, people learned the basic stack necessary to work towards a personal website, then deploying that site through GitHub pages. In the second half, students took in a series of lessons about Ruby syntax, but the underlying goal was to teach them the programming concepts common to a number of programming languages. Then, we shifted gears and had them work through a series of Rails tutorials that pushed them towards a real-life situation where they’re working through and on a thing (in this case a sort of platform for crowdsourcing transcriptions of images).&lt;/p&gt;

&lt;p&gt;I really enjoyed teaching the Rails course, and I think there was a lot of good in it. But over the past few years it has raised a number of pedagogical questions for me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What can you reasonably hope to teach in a week-long workshop?&lt;/li&gt;
  &lt;li&gt;Is it better to do more with less or less with more?&lt;/li&gt;
  &lt;li&gt;What is the upper-limit on the amount of new information students can take in during the week?&lt;/li&gt;
  &lt;li&gt;What will students actually use/remember from the course once the week is over?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To be fair, week-long workshops like this one often raise similar concerns for me. I had two main concerns about our course in particular.&lt;/p&gt;

&lt;p&gt;The first was a question of audience. We got people of all different skill levels in the course. Some people were there to get going with programming for the first time. These newcomers often seemed really comfortable with the course during the first half, while the second half of the course could result in a lot of frustration when the difficulty of the material suddenly seemed to skyrocket. Other students were experienced developers with several languages under their belt who were there specifically to learn Rails. The first half of the course seemed to be largely review for this experienced group, while the second half was really what they were there to take on.  It’s great that we were able to pull in students with such diverse experiences, but I was especially concerned for the people new to programming who felt lost during the second half of the course. Those experienced folks looking to learn Rails? I think they can probably find their way into the framework some other way. But I didn’t want our course to turn people off from programming because the presentation of the material felt frustrating. We can fix that. I always feel as though we should be able to explain these methods to anyone, and I wanted our alumni to feel that they were empowered by their new experiences, not frustrated. I wanted our course to reflect that principle by focusing on this audience of people looking for an introduction, not an advanced tutorial.&lt;/p&gt;

&lt;p&gt;I also wondered a lot about the outcomes of the course. I wondered how many of the students really did anything with web applications after the course was over. Those advanced students there specifically for Rails probably did, and I’m glad that they had tangible skills to walk away with. But, for the average person just getting into digital humanities programming, I imagine that Rails wasn’t something they were going to use right away. After all, you use what you need to do what you need. And, while Rails gives you a lot of options, it’s not necessarily the tool you need for the thing in front of you - specially when you’re starting out.&lt;/p&gt;

&lt;p&gt;So we set about redesigning the course with some of these thoughts in mind and with a few principles:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Less is more.&lt;/li&gt;
  &lt;li&gt;A single audience is better than many.&lt;/li&gt;
  &lt;li&gt;If you won’t use it, you’ll lose it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I wondered how we might redesign the course to better reflect the kinds of work that are most common to humanists using programming for their work. I sat down and thought about common tasks that I use programming for beyond building apps/web services. I made a list of some common tasks that, when they confront me, I go, “I can write a script for that!” The resulting syllabus is &lt;a href=&quot;https://humanitiesprogramming.github.io/syllabus/&quot;&gt;on the site&lt;/a&gt;, but I’ll reiterate it here. The main changes took place in the second half of the course:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Basics: command line, git, GitHub, HTML/CSS
    &lt;ul&gt;
      &lt;li&gt;Project: personal website&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Programming concepts: Python
    &lt;ul&gt;
      &lt;li&gt;Project(s): Applied Python for acquiring, processing, and analyzing humanities data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The switch from Python to Ruby reflects, in part, my own changing practices, but I also find that the Pythonic syntax enforces good stylistic practices in learners. In place of working on a large Rails app, we keep the second half of the course focused on daily tasks that programming is good for. After learning the basic concepts from Python, we introduce a few case studies for applied Python. Like all our materials, these are available &lt;a href=&quot;http://humanitiesprogramming.github.io/resources/&quot;&gt;on our site&lt;/a&gt;. But I’d encourage interested folks to check out the Jupyter notebooks for these units if you’re interested. These are the new units on applications of Python to typical situations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/humanitiesprogramming/humanitiesprogramming.github.io/blob/master/python/notebooks/working-with-csv.ipynb&quot;&gt;Working with CSV files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/humanitiesprogramming/humanitiesprogramming.github.io/blob/master/python/notebooks/working-with-apis.ipynb&quot;&gt;Getting data from API’s&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/humanitiesprogramming/humanitiesprogramming.github.io/blob/master/python/notebooks/intro-to-scraping.ipynb&quot;&gt;Introduction to Web Scraping&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/humanitiesprogramming/humanitiesprogramming.github.io/blob/master/python/notebooks/text-analysis.ipynb&quot;&gt;Basic Text Analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the process of working through these materials, the students work with real, live humanities data drawn from &lt;a href=&quot;https://www.gutenberg.org/&quot;&gt;Project Gutenberg&lt;/a&gt;, the &lt;a href=&quot;https://dp.la/&quot;&gt;DPLA&lt;/a&gt;, and the &lt;a href=&quot;http://www.casebook.org/press_reports/&quot;&gt;Jack the Ripper Casebook&lt;/a&gt;. We walk the students through a few different options for building a corpus of data and working with it. After gathering data, we talk about problems with it and how to use it. Of course, you could run an entire course on such things. Our goal here is not to cover everything. In fact, I erred on the side of keeping the lessons relatively lightweight, with the assumption that the jump in difficulty level would require us to move pretty slowly. The main goal is to show how situations that appear to be much more complicated still boil down to the same basic concepts the students have just learned. We want to shrink the perceived gap between those beginning exercises and the kinds of scripts that are actually useful for your own day-to-day work. We introduce some slightly more advanced concepts along the way, but hopefully enough of the material will remain familiar that the students can excel. Ideally, the concepts we work through in these case studies will be more immediately useful to someone trying to introduce programming into their workflow for the first time. And, in being more immediately useful, the exercises might be more likely to give a lasting foundation for them to keep building on into the future.&lt;/p&gt;

&lt;p&gt;We’ve also rebranded the course slightly. The course description has changed, as we’ve attempted to soften jargon and make it clear that students are meant to come to the course not knowing the terms or technologies in the description (they’re going to learn them with us!). The course name has changed as well, first as a joke but then in a serious way. Instead of simply being called “Humanities Programming,” the course is now “Help! I’m a Humanist! - Programming for Humanists with Python.” The goal there is to expose the human aspect of the course - no one is born knowing this stuff, and learning it means dealing with a load of tough feelings: anxiety, frustration, imposter syndrome, etc. I wanted to foreground all of this right away by making my own internal monologue part of the course title. The course can’t alleviate all those feelings, but I hoped to make it clear that we’re taking them into account and thinking about the human side of what it means to teach and learn this material. We’re in it together.&lt;/p&gt;

&lt;p&gt;So. What can you do in a week? Quite a lot. What should you do - that’s a much tougher question. I’ve timed this post to go out right around when HILT starts. If I figure it out in the next week I’ll let you know.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>On Co-Teaching and Digital Humanities</title>
   <link href="http://lanyon.getpoole.com/blog/2017/03/22/co-teaching/"/>
   <updated>2017-03-22T12:53:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2017/03/22/co-teaching</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;http://digitalhumanities.wlu.edu/blog/2017/03/23/on-co-teaching-and-digital-humanities/&quot;&gt;WLUDH blog&lt;/a&gt;.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For me, co-teaching is the ultimate teaching experience. I’ve been fortunate to find several opportunities for it over the years. During graduate school, I co-taught a number of short courses, several DH classes, and a couple workshops. Here at W&amp;amp;L I’ve been able to teach alongside faculty from the history department and the Library. Each experience has been deeply rewarding. These days I’m spending more time thinking about digital humanities from a curricular and pedagogical standpoint, so I wanted to offer a few quick notes on how co-teaching might play a role in those discussions.&lt;/p&gt;

&lt;p&gt;I’m sympathetic to arguments against putting two or more people at the front of the classroom. It’s expensive to use two faculty members to teach a single course when one might do, so I can understand how, in a certain logic, the format seems profoundly inefficient. You have a set number of courses that need to be taught, and you need people to teach them. And I have also heard people say that co-teaching is a lot more work than teaching a course solo. I understand these objections. But I wanted to offer just a few notes on the benefits of co-teaching - why you might want to consider it as a path for growing your digital humanities program even in the face of such hesitations. I’ve found that the co-teaching experience fully compliments the work that we do as digital humanists for a number of reasons. I think of co-teaching as a way to make the teaching of digital humanities more fully reflect the ways we tend to practice it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Co-teaching allows for more interdisciplinary courses.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Interdisciplinarity is hard. By its very nature, it assumes research, thinking, and teaching that lie at the intersections of &lt;em&gt;at least&lt;/em&gt; two fields, usually more. In the case of digital humanities, this is exacerbated because the methodologies of the combined fields often seem to be so distinct from one another. Literary criticism and statistical methods, archival research and computer science, literary theory and web design. These binaries are flawed, of course, and these fields have a lot to say to and about each other. But, in the context of teaching digital humanities, sometimes bringing these fields together requires expertise that one teacher alone might not possess. A second instructor makes it easier to bridge perceived gaps in skills or training. And those skills, if they are meant to be taught, require time and energy from the instructors. On a more practical level, it can be profoundly helpful to have one instructor float in the classroom to offer technical assistance while the other leads discussion so as to prevent troubleshooting from breaking up the class. It is not enough to say that interdisciplinary courses need a second instructor. They often require additional hands on deck.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Co-teaching models collaboration for students.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Digital humanities work often requires multiple people to work together, but I’d wager that students often expect there to be a single person in charge of a class. Students might come into the class expecting a lecture model. Or, at the very least, they might expect the teacher to be an expert on the material. Or, they might expect the instructor to lead discussion. These formats are all well and good, and many instructors thrive on these models. I prefer to position my students as equal collaborators with me in the material of the course. We explore the material together, and, even if I might serve as a guiding hand, their observations are just as important as my own. I try to give my students space to assert themselves as experts, as real collaborators in the course. Co-teaching helps to set the stage for this kind of approach, because the baseline assumption is that no one person knows everything. If that were the case, you would not need a second instructor. There is always a second voice in the room. By unsettling the top-down hierarchy of the classroom, co-teaching helps to disperse authority out into other parts of the group. The co-teacher not in charge on a particular day might even be seated alongside the students, learning with them. This approach to teaching works especially well as a vehicle for digital humanities. After all, most digital humanities projects have many collaborators, each of whom brings a different set of skills to the table. No person operates as an expert in all parts of a collaborative project - not even the project manager. Digital humanities work is, by its nature, collaborative. Students should know this, see this, and feel this, and it can start at the front of the classroom.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Co-teaching transfers skills from one instructor to another.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Digital humanities faculty and staff are often brought in to support courses and projects by teaching particular methods or tools. This kind of training can sometimes happen in one-off workshops or in external labs, but the co-teaching model can offer a deeper, more immersive mentoring experience. Co-teaching can be as much for the instruction of the students as it is for the professional development of the teachers. For the willing faculty member, a semester-long engagement with material that stretches their own technical abilities can set them up to teach the material by themselves in the future. They can learn alongside the students and expand their portfolio of skills. At W&amp;amp;L we have had successes in a number of disciplines with this approach - faculty in history, journalism, and French have expanded their skills with text analysis, multimedia design and storytelling, and textual encoding all while developing and teaching new courses. We’ve even managed, at times, to document this process so that we have &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/&quot;&gt;demonstrable, professionally legible evidence&lt;/a&gt; of the kinds of work possible when two people work together. When both instructors share course time for the entire semester it can help to expand the capacity of a digital humanities program by spreading expertise among many collaborators.&lt;/p&gt;

&lt;p&gt;Of course, all of this requires a lot of buy-in, both from the faculty teaching together and from the administration overseeing the development of such courses. You need a lot of people ready to see the value in this process. The particulars of your campus might provide their own limitations or opportunities. Putting together collaborations like these takes time and energy, but it’s worth it. I think of co-teaching as an investment - in the future of the program, the students, and the instructors. What requires two instructors today might, with the right preparation and participation, only require one tomorrow.&lt;/p&gt;

&lt;p&gt;In case you want to read more, here are some other pieces on co-teaching from myself and past collaborators (happy to be pointed to others!):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sarah Storti - &lt;a href=&quot;http://scholarslab.org/digital-humanities/on-co-teaching-and-gratitude/&quot;&gt;On Co-Teaching and Gratitude&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Ed Triplett - &lt;a href=&quot;http://scholarslab.org/digital-humanities/one-teach-one-drift/&quot;&gt;One Teach, One Drift&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Here is another blip from me - &lt;a href=&quot;http://scholarslab.org/digital-humanities/washington-and-lee-trip/&quot;&gt;Washington and Lee Trip&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;And some of my syllabi and materials can be found &lt;a href=&quot;http://walshbr.com/teaching/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://humanitiesprogramming.github.io/&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>In, Out, Across, With: Collaborative Education and Digital Humanities (Job Talk for Scholars' Lab)</title>
   <link href="http://lanyon.getpoole.com/blog/2017/03/02/in-out-across-with/"/>
   <updated>2017-03-02T09:31:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2017/03/02/in-out-across-with</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;https://digitalhumanities.wlu.edu/blog/2017/03/06/in-out-across-with-collaborative-education-and-digital-humanities-job-talk-for-scholars-lab/&quot;&gt;WLUDH blog&lt;/a&gt; and the &lt;a href=&quot;http://scholarslab.org/digital-humanities/in-out-across-with-collaborative-education-and-digital-humanities-job-talk-for-head-of-graduate-programs/&quot;&gt;Scholars’ Lab blog&lt;/a&gt;]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I’ve accepted a new position as the &lt;a href=&quot;http://scholarslab.org/uncategorized/brandon-walsh-is-our-new-head-of-graduate-programs-starting-april-24-2017/&quot;&gt;Head of Graduate Programs in the Scholars’ Lab&lt;/a&gt;, and I’ll be transitioning into that role over the next few weeks! As a part of the interview process, we had to give a job talk. While putting together this presentation, I was lucky enough to have past examples to work from (as you’ll be able to tell, if you check out this past &lt;a href=&quot;http://literaturegeek.com/2016/02/28/DHjobtalk&quot;&gt;job talk&lt;/a&gt; by Amanda Visconti). Since my new position will involve helping graduate students through the process of applying for positions like these, it only feels right that I should post my own job talk as well as a few words on the thinking that went into it. Blemishes, jokes, and all, hopefully these materials will help someone in the future find a way in, just as the example of others did for me. And if you’re looking for more, Visconti has a great list of other examples linked from her &lt;a href=&quot;http://scholarslab.org/digital-humanities/disrupt-the-humanities-managing-director-job-talk/&quot;&gt;more recent job talk&lt;/a&gt; for the Scholars’ Lab.&lt;/p&gt;

&lt;p&gt;For the presentation, I was asked to respond to this prompt:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What does a student (from undergraduate to doctoral levels) need to learn or experience in order to add “DH” to his or her skill set?  Is that an end or a means of graduate education?  Can short-term digital assignments in discipline-specific courses go beyond “teaching with technology”?  Why not refer everyone to online tutorials?  Are there risks for doctoral students or the untenured in undertaking digital projects?  Drawing on your own experience, and offering examples or demonstrations of digital research projects, pedagogical approaches, or initiatives or organizations that you admire, make a case for a vision of collaborative education in advanced digital scholarship in the arts and humanities.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I felt that each question could be a presentation all its own, and I had strong opinions about each one. Dealing with all of them seemed like a tall order. I decided to spend the presentation close reading and deconstructing that first sentence, taking apart the idea that education and/or digital humanities could be thought of in terms of lists of skills at all. Along the way, my plan was to dip into the other questions as able, but I also assumed that I would have plenty of time during the interview day to give my thoughts on them. I also wanted to try to give as honest a sense as possible of the way I approach teaching and mentoring. For me, it’s all about people and giving them the care that they need. In conveying that, I hoped, I would give the sort of vision the prompt was asking for. I also tried to sprinkle references to the past and present of the Scholars’ Lab programs to ground the content of the talk. When I mention potential career options in the body of the talk, I am talking about specific alumni who came through the fellowship programs. And when I mention graduate fellows potentially publishing on their work with the Twitter API, well, &lt;a href=&quot;http://scholarslab.org/uncategorized/working-with-an-archive-of-the-now/&quot;&gt;that’s not hypothetical either&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So below find the lightly edited text of the talk I gave at the Scholars’ Lab - “In, Out, Across, With: Collaborative Education and Digital Humanities.” I’ve only substantively  modified one piece - swapping out one example for another.&lt;/p&gt;

&lt;p&gt;And a final note on delivery: I have heard plenty of people argue over whether it is better to read a written talk or deliver one from notes. My own sense is that the latter is far more common for digital humanities talks. I have seen both fantastic read talks and amazing extemporaneous performances, just as I have seen terrible versions of each. My own approach is, increasingly, to write a talk but deliver that talk more or less from memory. In this case, I had a pretty long commute to work, so I recorded myself reading the talk and listened to it a lot to get the ideas in my head. When I gave the presentation, I had the written version in front of me for reference, but I was mostly moving through my own sense of how it all fit together in real time (and trying to avoid looking at the paper). My hope is that this gave me the best of both worlds and resulted in a structured but engaging performance. Your mileage may vary!&lt;/p&gt;

&lt;h2 id=&quot;in-out-across-with-collaborative-education-and-digital-humanities&quot;&gt;In, Out, Across, With: Collaborative Education and Digital Humanities&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/job-talk-slides/slide01.jpg&quot; alt=&quot;Title slide&quot; /&gt; It’s always a treat to be able to talk with the members of the UVA Library community, and I am very grateful to be here. For those of you that don’t know me, I am Brandon Walsh, Mellon Digital Humanities Fellow and Visiting Assistant Professor of English at Washington and Lee University. The last time I was here, I gave a talk that had almost exclusively animal memes for slides. I can’t promise the same robust Internet culture in this talk, but talk to me after and I can hook you up. I swear I’ve still got it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/job-talk-slides/slide02.jpg&quot; alt=&quot;Zotero slide&quot; /&gt; In the spirit of Amanda Visconti, the resources that went into this talk (and a number of foundational materials on the subject) can all be found in a Zotero collection at the &lt;a href=&quot;https://goo.gl/r6MCwD&quot;&gt;above link&lt;/a&gt;. I’ll name check any that are especially relevant, but hopefully this set of materials will allow the thoughts in the talk to flower outwards for any who are interested in seeing its origins and echoes in the work of others.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/job-talk-slides/slide03.jpg&quot; alt=&quot;Thank you slide&quot; /&gt; And a final prefatory note: no person works, thinks or learns alone, so here are the names of the people in my talk whose thinking I touch upon as well as just some – but not all – of my colleagues at W&amp;amp;L who collaborate on the projects I mention. Top tier consists of people I cite or mention, second tier is for institutions or publications important to discussion, and final tier is for direct collaborators on this work.&lt;/p&gt;

&lt;p&gt;Today I want to talk to you about how best to champion the people involved in collaborative education in digital research. I especially want to talk about students. And when I mention “students” throughout this talk, I will mostly be speaking in the context of graduate students. But most of what I discuss will be broadly applicable to all newcomers to digital research. My talk is an exhortation to find ways to elevate the voices of people in positions like these to be contributors to professional and institutional conversations from day one and to empower them to define the methods and the outcomes of the digital humanities that we teach. This means taking seriously the messy, fraught, and emotional process of guiding students through digital humanities methods, research, and careers. It means advocating for the legibility of this digital work as a key component of their professional development. And it means enmeshing these voices in the broader network around them, the local context that they draw upon for support and that they can enrich in turn. I believe it is the mission of the Head of Graduate Programs to build up this community and facilitate these networks, to incorporate those who might feel like outsiders to the work that we do. Doing so enriches and enlivens our communities and builds a better and more diverse research and teaching agenda. &lt;img src=&quot;/assets/images/job-talk-slides/slide04.jpg&quot; alt=&quot;Title Slide 2&quot; /&gt; This talk is titled “In, Out, Across, With: Collaborative Education and Digital Humanities,” and I’ll really be focusing on the prepositions of my title as a metaphor for the nature of this sort of position. I see this role as one of connection and relation. The talk runs about 24 minutes, so we should have plenty of time to talk.&lt;/p&gt;

&lt;p&gt;When discussing digital humanities education, it is tempting to first and foremost discuss what, exactly, it is that you will be teaching. What should the students walk away knowing? To some extent, just as there is more than one way to make breakfast, you could devise numerous baseline curricula. &lt;img src=&quot;/assets/images/job-talk-slides/slide05.jpg&quot; alt=&quot;W&amp;amp;L Skills&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is what we came up with at Washington and Lee for students in our &lt;a href=&quot;http://digitalhumanities.wlu.edu/initiatives/undergraduate-fellowship/&quot;&gt;undergraduate digital humanities fellowship program&lt;/a&gt;. We tried to hit a number of kinds of skills that a practicing digital humanist might need. It’s by no means exhaustive, but the list is a way to start. We don’t expect one person to come away knowing everything, so instead we aim for students to have an introduction to a wide variety of technologies by the end of a semester or year. They’ll encounter some technologies applicable to project management, some to front-end design, as well as a variety of programming concepts broadly applicable to a variety of situations. Lists like this give some targets to hit. But still, even as someone who helped put this list together, it makes me worry a bit. I can imagine younger me being afraid of it! It’s easy for us to forget what it was like to be new, to be a beginner, to be learning for the first time, but I’d like to return us to that frame of thinking. I think we should approach lists like these with care, because they can be intimidating for the newcomer. So in my talk today I want to argue against lists of skills as ways of thinking.&lt;/p&gt;

&lt;p&gt;I don’t mean to suggest that programs need no curriculum, nor do I mean to suggest that no skills are necessary to be a digital humanist. But I would caution against focusing too much on the skills that one should have at the end of a program, particularly when talking about people who haven’t yet begun to learn. I would wager that many people on the outside looking in think of DH in the same way: it’s a big list of unknowns. I’d like to get away from that.&lt;/p&gt;

&lt;p&gt;Templates like this are important for developing courses, fellowship, and degree-granting programs, but I worry that the goodwill in them might all too easily seem like a form of gatekeeping to a new student. It is easy to imagine telling a student that “you have to learn GitHub before you can work on this project.” It’s just a short jump from this to a likely student response - “ah sorry - I don’t know that yet.” And from there I can all too easily imagine the common refrain that you hear from students of all levels - “If I can’t get that, then it’s because I’m not a technology person.” From there - “Digital humanities must not be for me.”&lt;/p&gt;

&lt;p&gt;Instead of building our curricula out of as-yet-unknown tool chains, I want to float, today, a vision of DH education as an introduction to a series of professional practices. Lists of skills might be ends but I fear they might foreclose beginnings. &lt;img src=&quot;/assets/images/job-talk-slides/slide06.jpg&quot; alt=&quot;SCI Slide&quot; /&gt; Instead, I will float something more in line with that of the Scholarly Communication Institute (held here at UVA for a time), which outlined what they saw as the needs of graduate and professional students in the digital age. I’ll particularly draw upon their first point here (last of my slides with tons of text, I swear): graduate students need training in “collaborative modes of knowledge production and sharing.”&lt;/p&gt;

&lt;p&gt;I want to think about teaching DH as introducing a process of discovery that collapses hierarchies between expert and newcomer: that’s a way to start. This sort of framing offers digital humanities not as a series of methods one does or does not know, but, rather, as a process that a group can engage in together. Do they learn methods and skills in the process? Of course! Anyone who has taken part in the sort of collaborative group projects undertaken by the Scholars’ Lab comes away knowing more than they came in with. But I want to continue thinking about process and, in particular, how that process can be more inclusive and more engaging. By empowering students to choose what they want to learn and how they want to learn it, we can help to expand the reach of our work and better serve our students as mentors and collaborators. There are a few different in ways in which I see this as taking place, and they’ll form the roadmap for the rest of the talk. &lt;img src=&quot;/assets/images/job-talk-slides/slide07.jpg&quot; alt=&quot;Roadmap Slide&quot; /&gt; Apologies - this looks like the sort of slide you would get at a business retreat. All the same - we need to adapt and develop new professional opportunities for our students at the same time that we plan flexible outcomes for our educational programs. These approaches are meant to serve increasingly diverse professional needs in a changing job market, and they need to be matched by deepening support at the institutional level.&lt;/p&gt;

&lt;p&gt;So to begin. One of our jobs as mentors is to encourage students to seek out professionally legible opportunities early on in their careers, and as shapers of educational programs we can go further and create new possibilities for them. At W&amp;amp;L, we have been &lt;a href=&quot;https://github.com/wludh/research-one-collab&quot;&gt;collaborating with the Scholars’ Lab&lt;/a&gt; to bring UVA graduate students to teach short-form workshops on digital research in W&amp;amp;L classrooms. Funded opportunities like this one can help students professionalize in new ways and in new contexts while paying it forward to the nearby community. A similar initiative at W&amp;amp;L that I’ve been working on has our own library faculty and undergraduate fellows visiting local high schools to speak with advanced AP computer science students about how their own programming work can apply to humanities disciplines. I’m happy to talk more about these in Q&amp;amp;A.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/job-talk-slides/slide08.jpg&quot; alt=&quot;Student slide&quot; /&gt; We also have our student collaborators present at conferences, both on their own work and on work they have done with faculty members, both independently and as co-presenters. Here is Abdur, one of our undergraduate Mellon DH fellows, talking about the writing he does for his thesis and how it is enriched by and different from the writing he does in digital humanities contexts at the Bucknell Digital Scholarship Conference last fall. While this sort of thing is standard for graduate students, it’s pretty powerful for an undergraduate to present on research in this way. Learning that it’s OK to fail in public can be deeply empowering, and opportunities like these encourage our students to think about themselves as valuable contributors to ongoing conversations long before they might otherwise feel comfortable doing so.&lt;/p&gt;

&lt;p&gt;But teaching opportunities and conferences are not the only ways to get student voices out there. I think there are ways of engaging student voices earlier, at home, in ways that can fit more situations. We can encourage students to engage in professional conversations by developing flexible outcomes in which we are equal participants. One approach to this with which I have been experimenting is group writing, which I think is undervalued as a taught skill and possible approach to DH pedagogy. An example: when a history faculty member at W&amp;amp;L approached the library (and by extension, me) for support in supplementing an extant history course with a component about digital text analysis, we could have agreed to offer a series of one-off workshops and be done with it. &lt;img src=&quot;/assets/images/job-talk-slides/slide09.jpg&quot; alt=&quot;Gitbook slide&quot; /&gt; Instead, this faculty member – Professor Sarah Horowitz – and I decided to collaborate on a more extensive project together, producing &lt;a href=&quot;http://www.walshbr.com/textanalysiscoursebook&quot;&gt;Introduction to Text Analysis: A Coursebook&lt;/a&gt;. The idea was to put the materials for the workshops together ahead of time, in collaboration, and to narrativize them into a set of lessons that would persist beyond a single semester as a kind of publication. The pedagogical labor that we put into reshaping her course could become, in some sense, professionally legible as a series of course modules that others could use beyond the term. So for the book, we co-authored a series of units on text analysis and gave feedback on each other’s work, editing and reviewing as well as reconfiguring them for the context of the course. Professor Horowitz provided more of the discipline-specific material that I could not, and I provided the materials more specific to the theories and methods of text analysis. Neither one of us could have written the book without the other.&lt;/p&gt;

&lt;p&gt;Professor Horowitz was, in effect, a student in this moment. She was also a teacher and researcher. She was learning at the same time that she produced original scholarly contributions. Even as we worked together, for me this collaborative writing project was also a pedagogical experiment that drew upon the examples of &lt;a href=&quot;https://openamlit.pressbooks.com/&quot;&gt;Robin DeRosa&lt;/a&gt;, &lt;a href=&quot;http://workbook.craftingdigitalhistory.ca/&quot;&gt;Shawn Graham&lt;/a&gt;, and &lt;a href=&quot;https://www.hastac.org/collections/field-notes-21st-century-literacies&quot;&gt;Cathy Davidson&lt;/a&gt;, in particular. &lt;img src=&quot;/assets/images/job-talk-slides/slide10.jpg&quot; alt=&quot;Davidson Slide&quot; /&gt; Davidson taught a graduate course on “21st Century Literacies” where each of her students wrote a chapter that was then collected and published as an open-access book. For us as for Davidson, the process of knowing, the process of uncovering is something that happens together. In public. And it’s documented so that others can benefit. Our teaching labor could become visible and professionally legible, as could the labor that Professor Horowitz put into learning new research skills. As she adapts and tries out ideas, and as we coalesce them into a whole, the writing product is both the means and the end of an introduction to digital humanities.&lt;/p&gt;

&lt;p&gt;Professor Horowitz also wanted to learn technical skills herself, and she learned quite a lot through the writing process. Rather than sitting through lectures or being directed to online tutorials by me, I thought she would learn better by engaging with and shaping the material directly. Her course and my materials would be better for it, as she would be helping to bind my lectures and workshops to her course material. The process would also require her to engage with a list of technologies for digital publishing. &lt;img src=&quot;/assets/images/job-talk-slides/slide11.jpg&quot; alt=&quot;Gitbook Toolchain Slide&quot; /&gt; Beyond the text analysis materials and concepts, the process exposed her to a lot of technologies: command line, Markdown, Git for version control, GitHub for project management. In the process of writing this document, in fact, she covered most of the same curriculum as our undergraduate DH fellows. &lt;img src=&quot;/assets/images/job-talk-slides/slide12.jpg&quot; alt=&quot;Fellows Skills Slide&quot; /&gt; She’s learning these things as we work together to produce course materials, but, importantly, the technical skills aren’t the focus of the work together. It’s a writing project! Rather than presenting the skills as ends in themselves, they were the means by which we were publishing a thing. They were immediately useful. And I think displacing the technology is helpful: it means that the outcomes and parameters for success are not based in the technology itself but, rather, in the thinking about and use of those methods. We also used a &lt;a href=&quot;https://www.gitbook.com&quot;&gt;particular platform&lt;/a&gt; that allowed Professor Horowitz to engage with these technologies in a light way so that they would not overwhelm our work – I’m happy to discuss more in the time after if you’re interested.&lt;/p&gt;

&lt;p&gt;This to say: the outcomes of such collaborative educations can be shaped to a variety of different settings and types of students. Take another model, &lt;a href=&quot;https://digitalfellows.commons.gc.cuny.edu/&quot;&gt;CUNY’s Graduate Center Digital Fellows program&lt;/a&gt;, whose students develop open tutorials on digital tools. Learning from this example, rather than simply direct students or colleagues towards online tutorials like these, why not have them write their own documents, legible for their own positions, that synthesize and remix the materials that they already have found? &lt;img src=&quot;/assets/images/job-talk-slides/slide13.jpg&quot; alt=&quot;Programming Historian Slide&quot; /&gt; The learning process becomes something productive in this framing. I can imagine, for example, directing collaboratively authored materials by students like these towards something like &lt;a href=&quot;http://programminghistorian.org/&quot;&gt;The Programming Historian&lt;/a&gt;. If you’re not familiar, The Programming Historian offers a variety of lessons on digital humanities methods, and they only require an outline as a pitch to their editorial team, not a whole written publication ready to go. Your graduate students could, say, work with the Twitter API over the course of a semester, blog about the research outcomes, and then pitch a tutorial to The Programming Historian on the API as a result of their work. It’s much easier to motivate yourselves to write something if you know that the publication has already been accepted. Obviously such acceptance is not a given, but working towards a goal like this can offer student researchers something to aim for. Their instructors could co-author these materials, even, so that everyone has skin in the game.&lt;/p&gt;

&lt;p&gt;This model changes the shape of what collaborative education can look like: it’s duration and its results. You don’t need a whole fellowship year. You could, in a reasonably short amount of time, tinker and play, and produce a substantial blog post, an article pitch, or a Library Research Guide (more on that in a moment).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/job-talk-slides/slide14.jpg&quot; alt=&quot;Jarvis Quote Slide&quot; /&gt;As Jeff Jarvis has said, “we need to move students up the education chain.” And trust me - the irony of quoting a piece titled “Lectures are Bullshit” during a lecture to you is not lost on me. But stay with me.&lt;/p&gt;

&lt;p&gt;Collaborative writing projects on DH topics are flexible enough to fit the many contexts for the kind of educational work that we do. After all, no one needs or values the same outcomes, and these shared and individual goals need to be worked out in conversation with the students themselves early on. Articulating these desires in a frank, written, and collaborative mode early on (in the genre of &lt;a href=&quot;http://praxis.scholarslab.org/charter/&quot;&gt;the project charter&lt;/a&gt;), can help the program directors to better shape the work to fit the needs of the students. But I also want to suggest that collaborative writing projects can be useful end products as well as launching pads, as they can fit the shape of many careers. After all, students come to digital humanities for a variety of different reasons. Some might be aiming to bolster a research portfolio on the path to a traditional academic career. Others might be deeply concerned about the likelihood of attaining such a position and be looking for other career options. Others still might instead be colleagues interested in expanding their research portfolio or skillset but unable to commit to a whole year of work on top of their current obligations. Writing projects could speak to all these situations.&lt;/p&gt;

&lt;p&gt;I see someone in charge of shaping graduate programs as needing to speak to these diverse needs. This person is both a steward of where students currently are – the goals and objectives they might currently have – as well as of where they might go – the potential lives they might (or might not!) lead. After all, graduate school, like undergraduate, is an enormously stressful time of personal and professional exploration. If we think simply about a student’s professional development as a process of finding a job, we overlook the real spaces in which help might be most desired. Frequently, those needs are the anxieties, stresses, and pressures of refashioning yourself as a professional. We should not be in the business of creating CV lines or providing lists of qualifications alone. We should focus on creating strong, well-adjusted professionals by developing ethical programs that guide them into the professional world by caring for them as people.&lt;/p&gt;

&lt;p&gt;In the graduate context, this involves helping students deal with the academic job market in particular. &lt;img src=&quot;/assets/images/job-talk-slides/slide15.jpg&quot; alt=&quot;Rogers Slide&quot; /&gt; To me in its best form, this means helping students to look at their academic futures and see proliferating possibilities instead of a narrow and uncertain route to a single job, to paraphrase the work of Katina Rogers. A sprinkler rather than a pipeline, in her metaphor. As Rogers’s work, in particular, has shown, recent graduate students increasingly feel that, while they experienced strong expectations that they would continue in the professoriate, they received inadequate preparation for the many different careers they might actually go on to have. &lt;a href=&quot;http://praxis.scholarslab.org&quot;&gt;The Praxis Program&lt;/a&gt; and the &lt;a href=&quot;http://praxis-network.org/&quot;&gt;Praxis Network&lt;/a&gt; are good examples of how to position digital humanities education as answers to these issues. Fellowship opportunities like these must be robust enough that they can offer experiences and outcomes beyond the purely technical, so that a project manager from one fellowship year can graduate with an MA and go into industry in a similar role just as well-prepared as a PhD student aiming to be a developer might go on to something entirely different. And the people working these programs must be prepared for the messy labor of helping students to realize that these are satisfactory, laudable professional goals.&lt;/p&gt;

&lt;p&gt;It should be clear that this sort of personal and professional support is the work of more than just one person. One of the strengths of a digital humanities center embedded in a library like this one at UVA is that fellows have the readymade potential to brush up against a variety of career options that become revealed when peaking outside of their disciplinary silos: digital humanities developers and project manager positions, sure, but also metadata specialists, archivists, and more. I think this kind of cross-pollination should be encouraged: library faculty and staff have a lot to offer student fellows and vice versa. Developing these relationships brings the fellows further into the kinds of the work done in the library and introduces them to careers that, while they might require further study to obtain, could be real options.&lt;/p&gt;

&lt;p&gt;To my mind the best fellowship programs are those fully aware of their institutional context and those that both leverage and augment the resources around them as they are able. We have been working hard on this at W&amp;amp;L. We are starting to institute a series of workshops led by the undergraduate fellows in consultation with the administrators of the fellowship program. The idea is that past fellows lead workshops for later cohorts on the technology they have learned, some of which we selectively open to the broader library faculty and staff. The process helps to solidify the student’s training – no better way to learn than to teach – but it also helps to expand the student community by retaining fellows as committed members. It also helps to fill out a student’s portfolio with a cv-ready line of teaching experience. This process also aims to build our own capacity within the library by distributing skills among a wider array of students, faculty, and staff. After all, student fellows and librarians have much they could learn from one another. I see the Head of Graduate Programs as facilitating such collaborations, as connecting the interested student with the engaged faculty/staff/librarian collaborator, inside their institution or beyond.&lt;/p&gt;

&lt;p&gt;But we must not forget that we are asking students and junior faculty to do risky things by developing these new interests, by spending time and energy on digital projects, let alone presenting and writing on them in professional contexts. The biggest risk is that we ask them to do so without supporting them adequately. All the technical training in the world means little if that work is illegible and irrelevant to your colleagues or committee. &lt;img src=&quot;/assets/images/job-talk-slides/slide16.jpg&quot; alt=&quot;Fitzpatrick Slide&quot; /&gt; In the words of Kathleen Fitzpatrick, we ask these students to “do the risky thing,” but we must “make sure that someone’s got their back.” I see the Head of Graduate Programs as the key in coordinating, fostering, and providing such care.&lt;/p&gt;

&lt;p&gt;Students and junior faculty need support – for technical implementation, sure – but they also need advocates – people who can vouch for the quality of their work and campaign on their behalf in the face of committees and faculty who might be otherwise unable to see the value of their work. Some of this can come from the library, from people able to put this work in the context of guidelines for the evaluation of digital scholarship. But some of this support and advocacy has to come from within their home departments. The question is really how to build up that support from the outside in. And that’s a long, slow process that occurs by making meaningful connections and through outreach programs. At W&amp;amp;L, we have worked to develop an &lt;a href=&quot;http://digitalhumanities.wlu.edu/initiatives/incentive-grants/&quot;&gt;incentive grant program&lt;/a&gt;, where we incentivize faculty members who might be new to digital humanities or otherwise skeptical to experiment with incorporating a digital project into their course. The result is a slow burn – we get maybe one or two new faculty each term trying something out. That might seem small, but it’s something, particularly at a small liberal arts college. This kind of slow evangelizing is key in helping the work done by digital humanists to be legible to everyone. Students and junior faculty need advocates for their work in and out of the library and their home departments, and the person in this position is tasked with overseeing such outreach.&lt;/p&gt;

&lt;p&gt;So, to return to the opening motif, lists of skillsets certainly have their place as we bring new people into the ever-expanding field: they’re necessary. They reflect a philosophy and a vision, and they’re the basis of growing real initiatives. But it’s the job of the Head of Graduate Programs to make sure that we never lose sight of the people and relationships behind them.&lt;/p&gt;

&lt;p&gt;Foremost, then, I see the Head of Graduate Programs as someone who takes the lists, documents, and curricula that I have discussed and connects them to the people that serve them and that they are meant to speak to. This person is one who builds relationships, who navigates the prepositions of my title. &lt;img src=&quot;/assets/images/job-talk-slides/slide17.jpg&quot; alt=&quot;Title Slide Last&quot; /&gt; It’s the job of such a person to blast the boundary between “you’re in” and “you’re out” so that the tech-adverse or shy student can find a seat at the table. This is someone who makes sure that the work of the fellows is represented across institutions and in their own departments. This person makes sure the fellows are well positioned professionally. This person builds up people and embeds them to networks where they can flourish. Their job is never to forget what it’s like to be the person trying to learn. Their job is to hear “I’m not a tech person” and answer “not yet, but you could be! and I know just the people to help. Let’s learn together.”&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Octopress, GitHub, and Custom Domains</title>
   <link href="http://lanyon.getpoole.com/blog/2017/02/25/octopress/"/>
   <updated>2017-02-25T12:00:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2017/02/25/octopress</id>
   <content type="html">&lt;p&gt;I have been using GitHub to host my site as a .github.io domain for years now, but I decided to switch to something a bit easier to remember as way of consolidating a few pieces of my digital identity (I had been variably using bmw9t and walshbr as public-facing usernames in different places). I’m now up and running with &lt;a href=&quot;https://reclaimhosting.com/&quot;&gt;Reclaim Hosting&lt;/a&gt;, and they have been fantastic in helping me to troubleshoot the issues.&lt;/p&gt;

&lt;p&gt;I ran into a quirky issue with my setup, though, and I thought I’d document it in case someone else runs into this in the future when trying to mix Octopress, GitHub, and custom domain mapping. My old workflow looked like this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Work locally.&lt;/li&gt;
  &lt;li&gt;Push to GitHub for version control, issue tracking, and transparency.&lt;/li&gt;
  &lt;li&gt;GitHub serves and hosts the site.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So I’m just changing that last piece to include Reclaim. Normally this involves two steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Visiting the settings page for your GitHub repository and giving it a custom domain.&lt;/li&gt;
  &lt;li&gt;Following the instructions &lt;a href=&quot;https://help.github.com/articles/quick-start-setting-up-a-custom-domain/&quot;&gt;here&lt;/a&gt; to have your own registered domain point to GitHub and vice versa. In the case of Reclaim Hosting, they had their own set of instructions for making things &lt;a href=&quot;https://community.reclaimhosting.com/t/domain-mapping-to-github/270&quot;&gt;work&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reclaim helped me work out kinks, and now the workflow, as I understand it, looks like this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Work locally&lt;/li&gt;
  &lt;li&gt;Push to GitHub for version control, issue tracking, and transparency&lt;/li&gt;
  &lt;li&gt;GitHub points to Reclaim, which grabs the content&lt;/li&gt;
  &lt;li&gt;Reclaim serves the content.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The problem I ran into appeared to be in step four - the content kept disappearing from the Reclaim domain for reasons that took me a while to figure out. Things would periodically return to the Reclaim splash page suggesting I had no content there. After a while, I realized that the problem was only manifesting later in the workflow but actually being caused earlier on.&lt;/p&gt;

&lt;p&gt;When you change the custom domain settings for your repository, GitHub actually creates a file in the repository for you. When you give a GitHub repository a custom domain, it creates a &lt;a href=&quot;https://github.com/walshbr/walshbr.github.io/blob/master/CNAME&quot;&gt;CNAME file in the repository’s root&lt;/a&gt;. This file contains the custom domain, so it’s pretty important.&lt;/p&gt;

&lt;p&gt;That was the problem. My blog is built in &lt;a href=&quot;http://octopress.org/&quot;&gt;Octopress&lt;/a&gt;, a souped up version of Jekyll. After working on content locally, Octopress has a rake command that pushes everything to GitHub. Octopress appears to wipe out the content of the repository and rebuild the whole thing every time. That new CNAME file? It was getting destroyed each time I pushed new content to the site, so whenever I updated my site the domain would appear to go down. The project kept forgetting that it had a custom domain.&lt;/p&gt;

&lt;p&gt;To get around this issue, I needed to make that CNAME file a more permanent part of the repository. I made a copy of the CNAME file locally and put it in the _source directory of the Octopress project - this is the directory that Octopress generates the blog from, so now new builds of the site will contain the record of the custom domain. Things seem more or less stable now, though I have fingers and toes crossed.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ripper Press Reports Dataset</title>
   <link href="http://lanyon.getpoole.com/blog/2016/12/12/ripper-dataset/"/>
   <updated>2016-12-12T09:51:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2016/12/12/ripper-dataset</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;http://digitalhumanities.wlu.edu/blog/2016/12/12/new-resource/&quot;&gt;WLULDH blog&lt;/a&gt;.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Update: since posting this, &lt;a href=&quot;http://laurabmcgrath.com/&quot;&gt;Laura McGrath&lt;/a&gt; reached out about finding an error in the CSV version of the data. The version linked to here should be cleaned up now. In addition, you will want to follow steps at the end of this post if using the CSV file in Excel. And thanks to &lt;a href=&quot;https://digitalhumanities.wlu.edu/blog/author/mackenzie-brooks/&quot;&gt;Mackenzie Brooks&lt;/a&gt; for her advice on working with CSV files in Excel.&lt;/p&gt;

&lt;p&gt;This semester I have been co-teaching a course on “Scandal, Crime, and Spectacle in the Nineteenth Century” with &lt;a href=&quot;https://www.wlu.edu/directory/profile?ID=x2047&quot;&gt;Professor Sarah Horowitz&lt;/a&gt; in the history department at W&amp;amp;L. We’ve been experimenting with ways to make the work we did for the course available for others beyond our students this term, which led to an &lt;a href=&quot;https://walshbr.github.io/blog/2016/10/24/text-analysis-coursebook/&quot;&gt;open coursebook on text analysis&lt;/a&gt; that we used to teach some basic digital humanities methods.&lt;/p&gt;

&lt;p&gt;I’m happy to make available today another resource that has grown out of the course. For their final projects, our students conducted analyses of a variety of historical materials. One of our student groups was particularly interested in &lt;a href=&quot;http://casebook.org/press_reports/&quot;&gt;Casebook: Jack the Ripper&lt;/a&gt;, a site that gathers transcriptions of primary and secondary materials related to the Whitechapel murders. The student group used just a few of the materials on the site for their analysis, but they only had the time to copy and paste a few things from the archive for use in &lt;a href=&quot;http://voyant-tools.org/&quot;&gt;Voyant&lt;/a&gt;. I found myself wishing that we could offer a version of the site’s materials better formatted for text analysis.&lt;/p&gt;

&lt;p&gt;So we made one! With the permission of the editors at the Casebook, we have scraped and repackaged one portion of their site, the collection of press reports related to the murders, in a variety of forms for digital researchers. More details about the dataset are below, and we’ve drawn from the descriptive template for datasets used by Michigan State University while putting it together. Just write to us if you’re interested in using the dataset - we’ll be happy to give you access to them under the terms described below. And also feel free to get in touch if you have thoughts about how to make datasets like this more usable for this kind of work. We’re planning on using this dataset and others like it in future courses here at W&amp;amp;L, so stay tuned for more resources in the future.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Jack the Ripper Press Reports Dataset&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The dataset can be downloaded &lt;a href=&quot;https://wlu.box.com/s/vfywfpwrivpb7iqc681mzu42tqjez0q9&quot;&gt;here&lt;/a&gt;. Write walshb@wlu.edu if you have any problems accessing the dataset. This work falls under a &lt;a href=&quot;https://creativecommons.org/licenses/by-nc/2.0/&quot;&gt;cc by-nc license&lt;/a&gt;. Anyone can use this data under these terms, but they must acknowledge, both in name and through hyperlink, &lt;a href=&quot;http://casebook.org/press_reports/&quot;&gt;Casebook: Jack the Ripper&lt;/a&gt; as the original source of the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This dataset features the full texts of 2677 newspaper articles between the years of 1844 and 1988 that reference the Whitechapel murders by Jack the Ripper. While the bulk of the texts are, in fact, contemporary to the murders, a handful of them skew closer to the present as press reports for contemporary crimes look back to the infamous case. The wide variety of sources available here gives a sense of how the coverage of the case differed by region, date, and publication.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Preferred Citation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Jack the Ripper Press Reports Dataset, Washington and Lee University Library.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The Jack the Ripper Press Reports Dataset was scraped from &lt;a href=&quot;https://casebook.org/&quot;&gt;Casebook: Jack the Ripper&lt;/a&gt; and republished with the permission of their editorial team in November 2016. The Washington and Lee University Digital Humanities group repackaged the reports here so that the collected dataset may be more easily used by interested researchers for text analysis.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Format&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The same dataset exists here organized in three formats: two folders, ‘by_journal’ and ‘index’, and a CSV file.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;by_journal: organizes all the press reports by journal title.&lt;/li&gt;
  &lt;li&gt;index: all files in a single folder.&lt;/li&gt;
  &lt;li&gt;casebook.csv: a CSV file containing all the texts and metadata.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each folder has related but slightly different file naming conventions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;by_journal:
    &lt;ul&gt;
      &lt;li&gt;journal_title/YearMonthDayPublished.txt&lt;/li&gt;
      &lt;li&gt;eg. augusta_chronicle/18890731.txt&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;index:
    &lt;ul&gt;
      &lt;li&gt;journal_title_YearMonthDayPublished.txt&lt;/li&gt;
      &lt;li&gt;eg. augusta_chronicle_18890731.txt&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The CSV file is organized according to the following column conventions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;id of text, full filename from within the index folder, journal title, publication date, text of article&lt;/li&gt;
  &lt;li&gt;eg. 1, index/august_chronicle_18890731.txt, augusta_chronicle, 1889-07-31, “lorem ipsum…”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Size&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The zip file contains two smaller folders and a CSV file. Each of these contains the same dataset organized in slightly different ways.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;by_journal - 24.9 MB&lt;/li&gt;
  &lt;li&gt;index of all articles- 24.8 MB&lt;/li&gt;
  &lt;li&gt;casebook.csv - 18.4 MB&lt;/li&gt;
  &lt;li&gt;Total: 68.1 MB uncompressed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Data Quality&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The text quality here is high, as the Casebook contributors transcribed them by hand.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Data collected and prepared by Brandon Walsh. Original dataset scraped from &lt;a href=&quot;http://casebook.org/press_reports/&quot;&gt;Casebook: Jack the Ripper&lt;/a&gt; and republished with their permission.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;If working with the CSV data in Excel, you have a few extra steps to import the data. Excel has character limits on cells and other configurations that will make things go sideways unless you take precautions. Here are the steps to import the CSV file:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Open Excel.&lt;/li&gt;
  &lt;li&gt;Make a blank spreadsheet.&lt;/li&gt;
  &lt;li&gt;Go to the Data menu.&lt;/li&gt;
  &lt;li&gt;Click “Get External Data”.&lt;/li&gt;
  &lt;li&gt;Select “Import Text File”.&lt;/li&gt;
  &lt;li&gt;Navigate to your CSV file and select it.&lt;/li&gt;
  &lt;li&gt;Select “Delimited” and hit next.&lt;/li&gt;
  &lt;li&gt;In the next section, uncheck “Tab” and check “Comma”, click next.&lt;/li&gt;
  &lt;li&gt;In the next section, click on the fifth column (the column one to the right of the date column).&lt;/li&gt;
  &lt;li&gt;At the top of the window, select “Text” as the column data format.&lt;/li&gt;
  &lt;li&gt;It will take a little bit to process.&lt;/li&gt;
  &lt;li&gt;Click ‘OK’ for any popups that come up.&lt;/li&gt;
  &lt;li&gt;It will still take a bit to process.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Your spreadsheet should now be populated with the Press Reports data.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Introduction to Text Analysis: A Coursebook</title>
   <link href="http://lanyon.getpoole.com/blog/2016/10/24/text-analysis-coursebook/"/>
   <updated>2016-10-24T14:06:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2016/10/24/text-analysis-coursebook</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;http://digitalhumanities.wlu.edu/blog/2016/10/27/introduction-to-text-analysis-a-coursebook/&quot;&gt;WLUDH blog&lt;/a&gt;]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I am happy to share publicly the initial release of a project that I have been shopping around in various talks and presentations for a while now. This semester, I co-taught a course on “Scandal, Crime, and Spectacle in the 19th Century” with Professor Sarah Horowitz in the history department here at Washington and Lee University. The course counted as digital humanities credit for our students, who were given a quick and dirty introduction to text analysis over the course of the term. In preparing for the class, I knew that I wanted my teaching materials on text analysis to be publicly available for others to use and learn from. One option might be to blog aggressively during the semester, but I worried that I would let the project slide, particularly once teaching got underway. Early conversations with Professor Horowitz suggested, instead, that we take advantage of time that we both had over the summer and experiment. By assembling our lesson plans far in advance, we could collaboratively author them and share them in a format that would be legible for publication both to our students, colleagues, and a wider audience. I would learn from her, she from me, and the product would be a set of resources useful to others.&lt;/p&gt;

&lt;p&gt;At a later date I will write more on the collaboration, particularly on how the co-writing process was a way for both of us to build our digital skill sets. For now, though, I want to share the results of our work - &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/&quot;&gt;Introduction to Text Analysis: A Coursebook&lt;/a&gt;. The materials here served as the backbone to roughly a one-credit introduction in text analysis, but we aimed to make them as modular as possible so that they could be reworked into other contexts. By compartmentalizing text analysis concepts, tool discussions, and exercises that integrate both, we hopefully made it a little easier for an interested instructor to pull out pieces for their own needs. All our materials are on &lt;a href=&quot;https://github.com/walshbr/textanalysiscoursebook/&quot;&gt;GitHub&lt;/a&gt;, so use them to your heart’s content. If you are a really ambitious instructor, you can take a look at our section on &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/book/conclusion/adapting/&quot;&gt;Adapting this Book&lt;/a&gt; for information on how to clone and spin up your own copy of the text materials. While the current platform complicates this process, as I’ll mention in a moment, I’m working to mitigate those issues. Most importantly to me, the book focuses on concepts and tools without actually introducing a programming language or (hopefully) getting too technical. While there were costs to these decisions, they were meant to make any part of the book accessible for complete newcomers, even if they haven’t read the preceding chapters. The book is really written with a student audience in mind, and we have the cute animal photos to prove it. Check out the &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/book/README/&quot;&gt;Preface&lt;/a&gt; and &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/book/introduction/for-instructors/&quot;&gt;Introduction&lt;/a&gt; to the book for more information about the thinking that went into it.&lt;/p&gt;

&lt;p&gt;The work is, by necessity, schematic and incomplete. Rather than suggesting that this be the definitive book on the subject (how could anything ever be?), we want to suggest that we always benefit from iteration. More teaching materials always help. Any resource can be a good one - bad examples can be productive failures. So we encourage you to build upon these materials in your courses, workshops, or otherwise. We also welcome feedback on these resources. If you see something that you want to discuss, question, or contest, please drop us a line on our &lt;a href=&quot;https://github.com/walshbr/textanalysiscoursebook/issues&quot;&gt;GitHub issues&lt;/a&gt; page. This work has already benefited from the kind feedback of others, either &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/book/acknowledgements/&quot;&gt;explicit&lt;/a&gt; or &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/book/conclusion/resources/&quot;&gt;implicit&lt;/a&gt;, and we are happy to receive any suggestions that can improve the materials for others.&lt;/p&gt;

&lt;p&gt;One last thing - this project was an experiment in open and collaborative publishing. In the process of writing the book, it became clear that the platform we used for producing it - &lt;a href=&quot;https://www.gitbook.com/&quot;&gt;GitBook&lt;/a&gt; - was becoming a problem. The platform was fantastic for spinning up a quick collaboration, and it really paid dividends in its ease of use for writers new to Markdown and version control. But the service was new and under heavy development. Ultimately, the code was out of our control, and I wanted something more stable and more fully in my hands for long-term sustainability. I am in the process of transferring the materials to a Jekyll installation that would run off GitHub pages. Rather than wait for this final, archive version of the site to be complete, it seemed better to release this current working version out into the world. I will update all the links here once I migrate things over. If the current hosting site is down, you can download a PDF copy of the most recent version of the book &lt;a href=&quot;/assets/introduction-to-text-analysis.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Update: I got around to doing that! You can find the new, improved, and more stable version of the site &lt;a href=&quot;http://walshbr.com/textanalysiscoursebook/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Text Analysis Workshop: Four Ways to Read a Text</title>
   <link href="http://lanyon.getpoole.com/blog/2016/09/21/ways-to-read/"/>
   <updated>2016-09-21T11:51:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2016/09/21/ways-to-read</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;http://digitalhumanities.wlu.edu/blog/2016/09/22/text-analysis-workshop-four-ways-to-read-a-text/&quot;&gt;WLUDH blog&lt;/a&gt;.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;On Monday I visited &lt;a href=&quot;http://library.wlu.edu/about/library-directory/mackenzie-brooks&quot;&gt;Mackenzie Brooks&lt;/a&gt;’s course on “Data in the Humanities” to introduce digital text analysis to her students. I faced a few challenges when planning for the visit:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Scope&lt;/strong&gt; - I had two hours for the workshop and a lot of material to cover. I was meant to introduce anything and everything, as much as I wanted in a general overview of text analysis.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Background&lt;/strong&gt; - This course is an introductory digital humanities course that counts as a science credit at W&amp;amp;L, so I assumed no prior knowledge of programming. Mackenzie will be covering some things with them later in the course, but at this stage I needed to avoid anything really technical.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Length&lt;/strong&gt; - Two hours was both a lot of time and no time at all. It was certainly not enough time to teach anyone to program for the first time. As an aside, I often find it hard to gauge how much material is appropriate for anything longer than 75 minutes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Content&lt;/strong&gt; - Since this was meant to be a general overview of the field, I did not want to lean too heavily on analysis by tools. I worried that if I did so the takeaway for the students would be how to use the tools, not the underlying concepts that the tools aided them in exploring.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I wound up developing a workshop I called “Introduction to Text Analysis: Four Ways to Read a Text.” Focusing on four ways meant that I felt comfortable cutting a section if things started to go long. It also meant that I was developing a workshop model that could easily fit varying lengths in the future. For example, I’ll be using portions of this workshop throughout my introduction to text analysis lectures in my own course this fall. The approach would necessarily be pretty distant - I couldn’t go into much detail for any one method in this time. Finally, I wanted the students to think about text analysis concepts first and then come to tools that would help them to do so, so I tried to displace the tools and projects from the conversation slightly. The hope was that, by enacting or intuiting the methods by hand first, the concepts would stick more easily than they might otherwise.&lt;/p&gt;

&lt;p&gt;The basic structure of the workshop was this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;I introduce a basic methodology for reading.&lt;/li&gt;
  &lt;li&gt;Students are presented with a handout asking them to read in a particular way with a prompt from me. They complete the exercise.&lt;/li&gt;
  &lt;li&gt;We talk about the process. We clarify the concept a little more together, and the students infer some of the basic difficulties and affordances of the approach.&lt;/li&gt;
  &lt;li&gt;Then I show a couple tools and projects that use that method for real results.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The four ways of reading I covered were close reading, bags of words, topic modeling, and sentiment analysis. So, to use the topic modeling portion as an example, any one of those units looked something like this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;I note how, until now, we have been discussing how counting words gives us a sense of the overall topic or scope of the text. Over time and in close proximity, individual words combine to give us a sense of what a text is about.&lt;/li&gt;
  &lt;li&gt;I give the students three paragraphs with the words scrambled and out of order (done pretty quickly in Python). I ask the students to get in groups and tell me what the underlying topics or themes are for each excerpt. They had to produce three single-word topics for each paragraph, and paragraphs could share topics.&lt;/li&gt;
  &lt;li&gt;We talk about how were able to determine the topics of the texts even with the paragraphs virtually unreadable. Even out of order, certain words in proximity together suggest the underlying theme of a text. We can think of texts as made up of a series of topics like these, clusters of words that occur in noticeable patterns near one another. We have human limits as to how much we can comprehend, but computers can help us run similar, mathematical versions of the same process to find out what words occur near each other in statistically significant patterns. The results can be thought of as the underlying topics or discourses that make up a series of documents. A lot of hand waving, I know, but I am assuming here that students will examine topic modeling in more detail at a later date. Better, I think, to introduce the broad strokes than lose students in the details.&lt;/li&gt;
  &lt;li&gt;I then share &lt;a href=&quot;http://dsl.richmond.edu/dispatch/pages/intro&quot;&gt;Mining the Dispatch&lt;/a&gt; as an example of topic modeling in action to show the students the kinds of research questions that can be explored using this method.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So, in essence, what I tried to do is create a hands-on approach to teaching text analysis concepts that is flexible enough to fit a variety of needs and contexts. My handouts and slides are all up on &lt;a href=&quot;https://github.com/bmw9t/waystoread&quot;&gt;a github repository&lt;/a&gt;. Feel free to share, reuse, and remix them in any way you would like.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Reading Speech: Virginia Woolf, Machine Learning, and the Quotation Mark</title>
   <link href="http://lanyon.getpoole.com/blog/2016/05/17/reading-speech/"/>
   <updated>2016-05-17T08:46:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2016/05/17/reading-speech</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;http://scholarslab.org/digital-humanities/reading-speech-virginia-woolf-machine-learning-and-the-quotation-mark/&quot;&gt;Scholars’ Lab blog&lt;/a&gt; as well as the &lt;a href=&quot;http://digitalhumanities.wlu.edu/blog/2016/05/17/reading-speech-virginia-woolf-machine-learning-and-the-quotation-mark/&quot;&gt;WLUDH blog&lt;/a&gt;. What follows is a slightly more fleshed out version of what I presented this past week at &lt;a href=&quot;http://hastac2016.org&quot;&gt;HASTAC 2016&lt;/a&gt; (complete with my memory-inflected transcript of the Q&amp;amp;A). I gave a bit more context for the project at the event than I do here, so it might be helpful to read my past two posts on the project &lt;a href=&quot;https://walshbr.github.io/blog/2015/03/23/woolf-huskey/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://walshbr.github.io/blog/2015/09/10/woolf-and-the-quotation-mark/&quot;&gt;here&lt;/a&gt; before going forward. This talk continues that conversation.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This year in the &lt;a href=&quot;http://www.scholarslab.org&quot;&gt;Scholar’s Lab&lt;/a&gt; I have been working with Eric on a machine learning project that studies speech in Virginia Woolf’s fiction. I have written elsewhere about the &lt;a href=&quot;https://walshbr.github.io/blog/2015/03/23/woolf-huskey/&quot;&gt;background for the project&lt;/a&gt; and &lt;a href=&quot;http://walshbr.github.io/blog/2015/09/10/woolf-and-the-quotation-mark/&quot;&gt;initial thoughts  towards its implications&lt;/a&gt;. For the purposes of this blog post, I will just present a single example to provide context. Consider the famous first line of &lt;em&gt;Mrs. Dalloway&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mrs Dalloway said, “I will buy the flowers myself.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nothing to remark on here, except for the fact that this is not how the sentence actually comes down to us. I have modified it from the original:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mrs Dalloway said she would buy the flowers herself.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My project concerns moments like these, where Woolf implies the presence of speech without marking it as such with punctuation. I have been working with Eric to lift such moments to the surface using computational methods so that I can study them more closely.&lt;/p&gt;

&lt;p&gt;I came to the project by first tagging such moments myself as I read through the text, but I quickly found myself approaching upwards of a hundred instances in a single novel-far too many for me to keep track of in any systematic way. What’s more, the practice made me aware of just how subjective my interpretation could be. Some moments, like this one, parse fairly well as speech. Others complicate distinctions between speech, narrative, and thought and are more difficult to identify. I became interested in the features of such moments. What is it about speech in a text that helps us to recognize it as such, if not for the quotation marks themselves? What could we learn about sound in a text from the ways in which it structures such sound moments?&lt;/p&gt;

&lt;p&gt;These interests led me towards a particular kind of machine learning, supervised classification, as an alternate means of discovering similar moments. For those unfamiliar with the concept, an analogy might be helpful. As I am writing this post on a flight to HASTAC and just finished watching a romantic comedy,  these are the tools that I will work with. Think about the genre of the romantic comedy. I only know what this genre is by virtue of having seen my fair share of them over the course of my life. Over time I picked up a sense of the features associated with these films: a serendipitous meeting leads to infatuation, things often seem resolved before they really are, and the films often focus on romantic entanglements more than any other details. You might have other features in mind, and not all romantic comedies will conform to this list. That’s fine: no one’s assumptions about genre hold all of the time. But we can reasonably say that, the more romantic comedies I watch, the better my sense of what a romantic comedy is. My chances of being able to watch a movie and successfully identify it as conforming to this genre will improve with further viewing. Over time, I might also be able to develop a sense of how little or how much a film departs from these conventions.&lt;/p&gt;

&lt;p&gt;Supervised classification works on a similar principle. By using the proper tools, we can feed a computer program examples of something in order to have it later identify similar objects. For this project, this process means training the computer to recognize and read for speech by giving it examples to work from. By providing examples of speech occurring within quotation marks, we can teach the program when quotation marks are likely to occur. By giving it examples of what I am calling ‘implied speech,’ it can learn how to identify those as well.&lt;/p&gt;

&lt;p&gt;For this project, I analyzed Woolf texts downloaded from &lt;a href=&quot;https://www.gutenberg.org/wiki/Main_Page&quot;&gt;Project Gutenberg&lt;/a&gt;. Eric and I put together scripts in Python 3 that used a package known as the &lt;a href=&quot;http://nltk.org/&quot;&gt;Natural Language Toolkit&lt;/a&gt; for classifying. All of this work can be found at the project’s &lt;a href=&quot;https://www.github.com/walshbr/woolf&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The project is still ongoing, and we are still working out some difficulties in our Python scripts. But I find the complications of the process to be compelling in their own right. For one, when working in this way we have to tell the computer what features we want it to pay attention to: a computer does not intuitively know how to make sense of the examples that we want to train it on. In the example of romantic comedies, I might say something along the lines of “while watching these films, watch out for the scenes and dialogue that use the word ‘love.’” We break down the larger genre into concrete features that can be pulled out so that the program knows what to watch out for.&lt;/p&gt;

&lt;p&gt;To return to Woolf, punctuation marks are an obvious feature of interest: the author suggests that we have shifted into the realm of speech by inserting these grammatical markings. Find a quotation mark-you are likely to be looking at speech. But I am interested in just those moments where we lose those marks, so it helps to develop a sense of how they might work. We can then begin to extrapolate those same features to places where the punctuation marks might be missing. We have developed two models for understanding speech in this way: an external and an internal model. To illustrate, I have taken a single sentence and bolded what the model takes to be meaningful features according to each model. Each represents a different way of thinking about how we recognize something as speech.&lt;/p&gt;

&lt;p&gt;External Model for Speech:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I love walking in London,” &lt;strong&gt;said Mrs. Dalloway&lt;/strong&gt;.  “Really it’s better than walking in the country.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The external model was our initial attempt to model speech. In it, we take an interest in the narrative context around quotation marks. In any text, we can say that there exist a certain range of keywords that signal a shift into speech: said, recalled, exclaimed, shouted, whispered, etc. Words like these help the narrative attribute speech to a character and are good indicators that speech is taking place. Given a list of words like this, we could reasonably build a sense of the locations around which speech is likely to be happening. So when training the program on this model, we had the classifier first identify locations of quotation marks. Around each quotation mark, the program took note of the diction and parts of speech that occurred within a given distance from the marking. We build up a sense of the context around speech.&lt;/p&gt;

&lt;p&gt;Internal Model for Speech:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“&lt;strong&gt;I love walking in London&lt;/strong&gt;,” said Mrs. Dalloway.  “&lt;strong&gt;Really it’s better than walking in the country&lt;/strong&gt;.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The second model we have been working with works in an inverse direction: instead of taking an interest in the surrounding context of speech, an internal model assumes that there are meaningful characteristics within the quotation itself. In this example, we might notice that the shift to the first-person ‘I’ is a notable feature in a text that is otherwise largely written in the third person. This word suggests a shift in register. Each time this model encounters a quotation mark it continues until it finds a second quotation mark. The model then records the diction and parts of speech inside the pair of markings.&lt;/p&gt;

&lt;p&gt;Each model suggests a distinct but related understanding for how sound works in the text. When I set out on this project, I had aimed to use the scripts to give me quantifiable evidence for moments of implied speech in Woolf’s work. The final step in this process, after all, is to actually use these models to identify speech: looking at texts they haven’t seen before, the scripts insert a caret marker every time they believe that a quotation mark should occur. But it quickly became apparent that the construction of the algorithms to describe such moments would be at least as interesting as any results that the project could produce. In the course of constructing them, I have had to think about the relationships among sound, text, and narrative in new ways.&lt;/p&gt;

&lt;p&gt;The algorithms are each interpretative in the sense that they reflect my own assumptions about my object of study. The models also reflect assumptions about the process of reading, how it takes place, and about how a reader converts graphic markers into representations of sound. In this sense, the process of preparing for and executing text analysis reflects a certain phenomenology of reading as much as it does a methodology of digital study. The scripting itself is an object of inquiry in its own right and reflects my own interpretation of what speech can be. These assumptions are worked and reworked as I craft algorithms and python scripts, all of which are as shot through with humanistic inquiry and interpretive assumptions as any close readings.&lt;/p&gt;

&lt;p&gt;For me, such revelations are the real reasons for pursuing digital study: attempting to describe complex humanities concepts computationally helps me to rethink basic assumptions about them that I had taken for granted. In the end, the pursuit of an algorithm to describe textual speech is nothing more or less than the pursuit of deeper and enriched theories of text and speech themselves.&lt;/p&gt;

&lt;p&gt;##Postscript&lt;/p&gt;

&lt;p&gt;I managed to take note of the questions I got when I presented this work at HASTAC, so what follows are paraphrases of my memory of them as well as some brief remarks that roughly reflect what I said in the moment. There may have been one other that I cannot quite recall, but alas such is the fallibility of the human condition.&lt;/p&gt;

&lt;p&gt;Q: You distinguish between speech and implied speech, but do you account at all for the other types of speech in Woolf’s novels? What about speech that is remembered speech that happened in earlier timelines not reflected in the present tense of the narrative’s events?&lt;/p&gt;

&lt;p&gt;A: I definitely encountered this during my first pass at tagging speech and implied speech in the text by hand. Instead of binaries like quoted speech/implied speech, I found myself wanting to mark for a range of speech types: present, actual; remembered, might not have happened; remembered incorrectly; remembered, implied; etc. I decided that a binary was more feasible for the machine learning problems that I was interested in, but the whole process just reinforced how subjective any reading process is: another reader might mark things differently. If these processes shape the construction of the theories that inform the project, then they necessarily also affect the algorithms themselves as well as the results they can produce. And it quickly becomes apparent that these decisions reflect a kind of phenomenology of reading as much as anything: they illlustrate my understanding of how a complicated set of markers and linguistic phenomenon contribute to our understanding that a passage is speech or not.&lt;/p&gt;

&lt;p&gt;Q: Did you encounter any variations in the particular markings that Woolf was using to punctuate speech? Single quotes, etc., and how did you account for them?&lt;/p&gt;

&lt;p&gt;A: Yes - the version of &lt;em&gt;Orlando&lt;/em&gt; that I am working with used single quotes to notate speech. So I was forced to account for such edge cases. But the question points at two larger issues: one authorial and one bibliographical. As I worked on Woolf I was drawn to the idea of being able to run such a script against a wider corpus. Since the project seemed to impinging on how we also understand psychologized speech, it would be fascinating to be able to search for implied speech in other authors. But, if you are familiar with, say, Joyce, you might remember that he hated quotation marks and used dashes to denote speech. The question is how much can you account for such edge cases, and, if not, the study becomes only one of a single author’s idiosyncrasies (which still has value). But from there the question spirals outwards. At least one of my models (the internal one) relies on quotation marks themselves as boundary markers. The model assumes that quotation marks will come in pairs, and this is not always the case. Sometimes authors, intentionally or accidentally, omit a closing quotation mark. I had to massage the data in at least half a dozen places where there was no quotation mark in the text and where its lack was causing my program to fail entirely. As textual criticism has taught us, punctuation marks are the single most likely things to be modified over time during the process of textual transmission by scribes, typesetters, editors, and authors. So in that sense, I am not doing a study of Woolf’s punctuation so much as a study of Woolf’s punctuation in these particular versions of the texts. One can imagine an exhaustive study that works on all versions of all Woolf’s texts as a study that might approach some semblance of a correct and thorough reading. For this project, however, I elected to take the lesser of two evils that would still allow me to work through the material. I worked with the texts that I had. I take all of this as proof that you have to know your corpus and your own shortcomings in order to responsibly work on the materials - such knowledge helps you to validate your responses, question your results, and reframe your approaches.&lt;/p&gt;

&lt;p&gt;Q: You talked a lot about text approaching sound, but what about the other way around - how do things like implied speech get reflected in audiobooks, for example? Is there anything in recordings of Woolf that imply a kind of punctuation that you can hear?&lt;/p&gt;

&lt;p&gt;A: I wrote about this extensively in my dissertation, but for here I will just say that I think the textual phenomenon the questioner is referencing occurs on a continuum. Some graphic markings, like pictures, shapes, punctuation marks, do not clearly translate to sound. And the reverse is true: the sounded quality of a recording can only ever be remediated by a print text. There are no perfect analogues between different media forms. Audiobook performers might attempt to convey things like punctuation or implied speech (in the audiobook of &lt;em&gt;Ulysses&lt;/em&gt;, for example, Jim Norton throws his voice and lowers his volume to suggest free indirect discourse). In the end, I think such moments are playing with an idea of what my dissertation calls audiotextuality, the idea that all texts recordings of texts, to varying degrees, contain both sound and print elements. The two spheres may work in harmony or against each other as a kind of productive friction. The idea is a slippery one, but I think it speaks to moments like the implied punctuation mark that come through in a particularly powerful audiobook recording.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Apps, Maps, & Models: A New View</title>
   <link href="http://lanyon.getpoole.com/blog/2016/02/29/apps-maps-models/"/>
   <updated>2016-02-29T08:54:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2016/02/29/apps-maps-models</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;http://digitalhumanities.wlu.edu/blog/2016/02/29/1937/&quot;&gt;Washington and Lee University Digital Humanities Blog&lt;/a&gt;]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Last Monday several of us here at WLUDH traveled down to Duke University for their symposium on &lt;a href=&quot;http://sites.duke.edu/digsymposium/&quot;&gt;Apps, Maps &amp;amp; Models: Digital Pedagogy in Art History, Archaeology &amp;amp; Visual Studies&lt;/a&gt;. I found the trip to be enlightening and invigorating. If you are interested in the event, you can find videos of the talks &lt;a href=&quot;http://nasher.capture.duke.edu/Panopto/Pages/Viewer.aspx?id=e6b77d46-cad9-442e-981c-473389e8ee15&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://nasher.capture.duke.edu/Panopto/Pages/Viewer.aspx?id=057a7ebb-7406-4d08-94d9-d4cab1e7c753&quot;&gt;here&lt;/a&gt; as well as a storify of the Twitter action &lt;a href=&quot;https://storify.com/dukewired/dah2016&quot;&gt;here&lt;/a&gt;. That the event was so well documented is a testimony to how well organized it was by the &lt;a href=&quot;http://www.dukewired.org/why-wired/&quot;&gt;Wired! Lab&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Many speakers at the event considered how the tools they were using might relate to more “traditional” modes for carrying out their research. They considered and responded to tough questions with and about their work. Are digital methods for tracing the topography of a surface, for example, fundamentally different in kind from analog means of doing so? If so, are they meant to displace those old tools? Why should we spend the time to learn the new technologies? A related question that comes up at almost every digital humanities presentation (though not at any of these): can digital humanities methods show us anything that we do not already know?&lt;/p&gt;

&lt;p&gt;Such questions can be particularly troubling when we are investing such time and energy on the work they directly critique, but we nonetheless need to have answers for them that demonstrate the value of digital humanities work, in and out of the classroom. Numerous well-known scholars have offered justifications of digital work in a variety of venues, and, to my mind, the symposium offered many answers of its own, in part by showcasing amazing work that spanned a variety of fields related to preservation, public humanities, and academic scholarship. Presenters were using digital technology to rebuild the past, using digital modeling to &lt;a href=&quot;https://www.apollo-magazine.com/virtual-florence-a-church-goes-digital/&quot;&gt;piece together the fragments of a ruined church that have since been incorporated into other structures&lt;/a&gt;. They were using these tools to engage the present, &lt;a href=&quot;https://aahvs.duke.edu/articles/medieval-color-comes-light&quot;&gt;to draw the attention of museum patrons to overlooked artifacts&lt;/a&gt;. The work on display at the symposium struck me, at its core, as engaging with questions and values that cut across disciplines, digital or otherwise.&lt;/p&gt;

&lt;p&gt;Most compelling to me, the symposium drew attention to how the tools we use to examine the objects of our study change our relationship to them. The presenters acknowledged that such an idea does hold dangers – after all, we want museum-goers to consider the objects in a collection, not just spend time perusing an iPad application meant to enrich them. But just as new tools offer new complications, changes in medium also offer changes in perspective. As was illustrated repeatedly at the symposium, drone photography, for all its deeply problematic political and personal valences, can offer you a new way of seeing the world, a new way of looking that is more comprehensive than the one we see from the ground. Even as we hold new methodologies and tools up to critique we can still consider how they might cause us to consider an object, a project, or a classroom differently.&lt;/p&gt;

&lt;p&gt;Seeing from a different angle allows us to ask new questions and re-evaluate old ones, an idea that speaks directly to my experience at the symposium. I work at the intersections of digital humanities, literary studies, and sound studies. So my participation in the symposium was as something of an outsider, someone ready to learn about an adjacent and overlapping field but, ultimately, not a home discipline. Thinking through my work from an outsider perspective made me want to ask many questions of my own work. The presenters here were deeply engaged in preserving and increasing access to the cultural record. How might I do the same through text analysis or through my work with audio artifacts? What questions and goals are common to all academic disciplines? How might I more thoroughly engage students in public humanities work?&lt;/p&gt;

&lt;p&gt;Obviously, the event left me with more questions than answers, but I think that is ultimately the sign of a successful symposium. I would encourage you to check out the videos of the conference, as this short note is necessarily reductive of such a productive event. The talks will offer you new thoughts on old questions and new ways of thinking about digital scholarship no matter your discipline.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Embedding COinS Metadata on a Page Using the Zotero API</title>
   <link href="http://lanyon.getpoole.com/blog/2016/02/15/coins-from-zotero/"/>
   <updated>2016-02-15T09:33:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2016/02/15/coins-from-zotero</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;http://digitalhumanities.wlu.edu/blog/2016/02/15/embedding-coins-data-on-a-page-using-the-zotero-api/&quot;&gt;Washington and Lee University Digital Humanities Blog&lt;/a&gt;]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This year I am working with Mackenzie, Steve McCormick, and his students on the &lt;a href=&quot;http://www.huondauvergne.org/&quot;&gt;Huon d’Auvergne&lt;/a&gt; project, a digital edition of a Franco-Italian romance epic. Last term we finished TEI-encoding of two of the manuscripts and put them online, and there is still much left to do. Making the digital editions of each manuscript online is a valuable scholarly endeavor in its own right, but we’ve also been spending a lot of time considering other ways in which we can enrich this scholarly production using the digital environment.&lt;/p&gt;

&lt;p&gt;All of which brings me to the &lt;a href=&quot;http://www.huondauvergne.org/biblio_temp&quot;&gt;bibliography&lt;/a&gt; for our site. At first, our bibliography page was just a transcription of a text file that Steve would send along with regular updates. This collection of materials is great to have in its own right, but a better solution would be to leverage the many digital humanities approaches to citation management to produce something a bit more dynamic.&lt;/p&gt;

&lt;p&gt;Steve already had everything in a Zotero, so my first step was to integrate the site’s bibliography with the Zotero collection that Steve was using to populate the list. I found a &lt;a href=&quot;https://github.com/davidswelt/zot_bib_web&quot;&gt;python 2 library called zot_bib_web&lt;/a&gt; that could do all this quite nicely with a bit of modification. Now, by running the script from my computer, the site’s bibliography will automatically pull in an updated Zotero collection for the project. Not only is it now easier to update our site (no more copying and pasting from a word document), but now others can contribute new resources to the same bibliography on Zotero by requesting to join the group and uploading citations. The project’s bibliography can continue to grow beyond us, and we will capture these additions as well.&lt;/p&gt;

&lt;p&gt;Mackenzie suggested that we take things a bit further by including &lt;a href=&quot;https://en.wikipedia.org/wiki/COinS&quot;&gt;COiNS&lt;/a&gt; metadata in the bibliography so that someone coming to our bibliography could export our information into the citation manager of their choosing. Zotero’s API can also do this, and I used a piece of the &lt;a href=&quot;https://github.com/urschrei/pyzotero&quot;&gt;pyzotero&lt;/a&gt; Python library to do so. The first step was to add this piece to the zot_bib_web code:&lt;/p&gt;

&lt;p&gt;zot = zotero.Zotero(library_id, library_type, api_key)
  coins = zot.collection_items(collection_id, content=’coins’)
  coin_strings = [str(coin) for coin in coins]
  for coin in coin_strings:
    fullhtml += coin&lt;/p&gt;

&lt;p&gt;Now, before the program outputs html for the bibliography, it goes out to the Zotero API and gets COinS metadata for all the citations, converts them into a format that will work for the embedding, and then attaches each returned span to the HTML for the bibliography.&lt;/p&gt;

&lt;p&gt;Now that I had the data that I needed, I wanted to make it work a bit more cleanly in our workflow. Initially, the program returned each bibliographic entry in its own page and meant for the whole bibliography to also be a stand-alone page on the website. I got rid of all that and, instead, wanted to embed them within the website as I already had it. I have the python program exporting the bibliography and COinS data into a small HTML file that I then attach to a div with an id of “includedContent”. inserted in the bibliography page. I use some jQuery to do so:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$(function(){
  $(&quot;#includedContent&quot;).load(&quot;/zotero-bib.html&quot;);
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Instead of distributing content across several different pages, I mark a placeholder area on the main site where all the bibliographic data and metadata will be dumped. All of the relevant data gets saved in a file ‘zot-bib.html’ that gets automatically included inside the shell of the bibliography.html page. From there, I just modified the style so that it would fit into the aesthetic of the site.&lt;/p&gt;

&lt;p&gt;Now anyone going to our bibliography page with a Zotero extension will see this in the right of the address bar:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/zotero-extension.jpg&quot; alt=&quot;Image of zotero functioning as an extension next to the sidebar.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Clicking on the folder icon will bring up the Zotero interface for downloading any of the items in our collection.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/zotero-download.jpg&quot; alt=&quot;Bulk downloading citations using zotero.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And to update this information we only need to run a single python script from the terminal to re-generate everything.&lt;/p&gt;

&lt;p&gt;The code is not live on the Huon site just yet, but you can download and manipulate these pieces from an example file I uploaded to the &lt;a href=&quot;https://github.com/wludh/huondauvergne/blob/zotero/zot_bib_web/zot_example.py&quot;&gt;Huon GitHub repository&lt;/a&gt;. You’ll probably want to start by installing zot_bib_web first to familiarize yourself with the configuration, and you’ll have a few settings to update before it will work for you: the library id, library type, api key, and collection ID will all need to be updated for your particular case, and the jQuery excerpt above will need to point to wherever you output the bibliography file.&lt;/p&gt;

&lt;p&gt;These steps have strengthened the way in which we handle bibliographic metadata so that it can be more useful for everyone, and we were really only able to do it because of the many great open source libraries that allow others to build on them. It’s a great thing - not having to reinvent the wheel.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Reflections on a Year of DH Mentoring</title>
   <link href="http://lanyon.getpoole.com/blog/2015/12/04/dh-mentoring/"/>
   <updated>2015-12-04T09:13:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2015/12/04/dh-mentoring</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[Crossposted on the &lt;a href=&quot;http://scholarslab.org/digital-humanities/reflections-on-a-year-of-dh-mentoring/&quot;&gt;Scholars’ Lab blog&lt;/a&gt; and the &lt;a href=&quot;http://digitalhumanities.wlu.edu/blog/2015/12/03/reflections-on-a-year-of-dh-mentoring/&quot;&gt;Digital Humanities at Washington and Lee blog&lt;/a&gt;]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This year I am working with &lt;a href=&quot;http://scholarslab.org/people/eric-rochester/&quot;&gt;Eric Rochester&lt;/a&gt; in the &lt;a href=&quot;http://scholarslab.org/&quot;&gt;Scholars’ Lab&lt;/a&gt; on a fellowship project that has me learning natural language processing (NLP), the application of computational methods to human languages. We’re adapting these techniques to study quotation marks in the novels of Virginia Woolf (read more about the project &lt;a href=&quot;http://scholarslab.org/digital-humanities/virginia-woolf-natural-language-processing-and-the-quotation-mark/&quot;&gt;here&lt;/a&gt;). We actually started several months before this academic year began, and, as we close out another semester, I have been spending time thinking about just what has made it such an effective learning experience for me. I already had a technical background from my time in the Scholars’ Lab at the beginning of the process, but I had no experience with Python or NLP. Now I feel most comfortable with the former of any other programming language and familiar enough with the latter to experiment with it in my own work.&lt;/p&gt;

&lt;p&gt;The general mode of proceeding has been this: depending on schedules and deadlines, we meet once or twice every two weeks. Between our meetings I would work as far and as much as I could, and the sessions would offer a space for Eric and me to talk about what I had done. The following are a handful of things we have done that, I think, have helped to create such an effective environment for learning new technical skills. Though they are particular to this study, I think they can be usefully extrapolated to apply to many other project-based courses of study in digital humanities. They are primarily written from the perspective of a student but with an eye to how and why the methods Eric used proved so effective for me.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let the Wheel Be Reinvented Before Sharing Shortcuts&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I came to Eric with a very small program adapted from Matt Jockers’s book on Text Analysis with R for Students of Literature that did little beyond count quotation marks and give some basic statistics. I was learning as I built the thing, so I was unaware that I was reinventing the wheel in many cases, rebuilding many protocols for dealing with commonly recognized problems that come from working with natural language. After working on my program and my approach to a degree of satisfaction, Eric pulled back the curtain to reveal that a commonly used python module, the Natural Language ToolKit &lt;a href=&quot;http://www.nltk.org/&quot;&gt;(NLTK)&lt;/a&gt;, could address many of my issues and more. NLTK came as something of a revelation, and working inductively in this way gave me a great sense of the underlying problems the tools could address. By inventing my own way to read in a text, clean it to make its text uniformly readable by the computer, and breaking the whole piece into a series of words that could be analyzed, I understood the magic behind a couple lines of NLTK code that could do all that for me. The experience also helped me to recognize ways in which we would have to adapt NLTK for our own purposes as I worked through the book.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Have a Plan, but Be Flexible&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After discussing NLTK and how it offered an easier way of doing the things that I wanted, Eric had me systematically work through the &lt;a href=&quot;http://www.nltk.org/book/&quot;&gt;NLTK book&lt;/a&gt; for a few months. Our meetings took on the character of an independent study: the book set the syllabus, and I went through the first seven chapters at my own pace. Working from a book gave our meetings structure, but we were careful not to hew too closely to the material. Not all chapters were relevant to the project, and we cut sections of the book accordingly. We shaped the course of study to the intellectual questions rather than the other way around.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Move from Theory to Practice / Textbook to Project&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As I worked through the book, I was able to recognize certain sections that felt most relevant to the Woolf work. Once I felt as though I had reached a critical mass, we switched from the book to the project itself and started working. I tend to learn from doing best, so the shift from theory to execution was a natural one. The quick and satisfying transition helped the work to feel productive right away: I was applying my new skills as I was still learning to feel comfortable with them. Where the initial months had more the feel of a traditional student-teacher interaction, the project-based approach we took up at this point felt more like a real and true collaboration. Eric and I would develop to-do items together, we would work alongside each other, and we would talk over the project together.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Document Everything&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Between our meetings I would work as far and as much as I could, carefully noting places at which I encountered problems. In some cases, these were conceptual problems that needed clarifying, and these larger questions frequently found their way into separate notes. But my questions were frequently about what a particular line of code, a particular command or function, might be doing. In that case, I made comments directly in the code describing my confusion. I quickly found that these notes were as much for me as for Eric–I needed to get back in the frame of mind that led to the confusion in the first place, and copious notes helped remind me what the problem was. These notes offered a point of departure for our meetings: we always had a place to start, and we did so based on the work that I had done.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Communicate in as Many Ways as Possible&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We met in person as much as possible, but we also used a variety of other platforms to keep things moving. Eric and I had all of our code on &lt;a href=&quot;https://github.com/erochest/woolf&quot;&gt;GitHub&lt;/a&gt; so that we could share everything that we had each been working on and discuss things from a distance if necessary. Email, obviously, can do a lot, but I found the chat capabilities of the Scholars’ Lab’s IRC channel to be far better for this sort of work. If I hit a particular snag that would only require a couple minutes for Eric to answer, we could quickly work things out through a web chat. With Skype and Google Hangouts we could even share the code on the other person’s computer even from hundreds of miles away. All of these things meant that we could keep working around whatever life events happened to call us away.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Recognize Spinning Wheels&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;These multiple avenues of communication are especially important when teaching technical skills. Not all questions or problems are the same: students can work through some on their own, but others can take them days to troubleshoot. Some amount of frustration is a necessary part of learning, and I do think it’s necessary that students learn to confront technical problems on their own. But not all frustration is pedagogically productive. There comes a point when you have tried a dozen potential solutions and you feel as though you have hit a wall. An extra set of eyes can (and should) help. Eric and I talked constantly about how to recognize when it was time for me to ask for help, and low-impact channels of communication like IRC could allow him to give me quick fixes to what, to me at least, seemed like impossible problems. Software development is a collaborative process, and asking for help is an important skill for humanists to develop.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In-person Meetings Can Take Many Forms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When we met, Eric and I did a lot of different things. First, we would talk through my questions from the previous week. If I felt a particular section of code was clunky or poorly done, he would talk and walk me through rewriting the same piece in a more elegant form. We would often pair program, where Eric would write code while I watched, carefully stopping him each time I had a question about something he was doing. And we often took time to reflect on where the collaboration was going - what my end goal was as well as what my tasks before the next meeting would be. Any project has many pieces that could be dealt with at any time, and Eric was careful to give me solo tasks that he felt I could handle on my own, reserving more difficult tasks for times in which we would be able to work together. All of this is to say that any single hour we spent together was very different from the last. We constantly reinvented what the meetings looked like, which kept them fresh and pedagogically effective.&lt;/p&gt;

&lt;p&gt;This is my best attempt to recreate my experience of working in such a close mentoring relationship with Eric. Obviously, the collaboration relies on an extremely low student-to-teacher ratio: I can imagine this same approach working very well for a handful of students, but this work required a lot of individual attention that would be hard to sustain for larger classes. One idea for scaling the process up might be to divide a course into groups, being training one, and then have students later in the process begin to mentor those who are just beginning. Doing so would preserve what I see as the main advantage of this approach: it helps to collapse the hierarchy between student and teacher and engage both in a common project. Learning takes place, but it does so in the context of common effort. I’d have to think more about how this mentorship model could be adapted to fit different scenarios. The work with Eric is ongoing, but it’s already been one of the most valuable learning experiences I have had.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Music Genre and Spotify Metadata</title>
   <link href="http://lanyon.getpoole.com/blog/2015/09/20/music-genre-and-spotify-metadata/"/>
   <updated>2015-09-20T16:51:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2015/09/20/music-genre-and-spotify-metadata</id>
   <content type="html">&lt;p&gt;&lt;em&gt;&lt;a href=&quot;http://scholarslab.org/?p=12173&quot;&gt;Crossposted on the Scholars’ Lab blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For the last couple weeks, I have been exploring APIs useful to sound studies for a sound recording and poetry project I am working on with former Scholars’ Lab fellow &lt;a href=&quot;https://annieswafford.wordpress.com/&quot;&gt;Annie Swafford&lt;/a&gt;. I was especially drawn to playing around with &lt;a href=&quot;https://www.spotify.com/us/&quot;&gt;Spotify&lt;/a&gt;, which has an &lt;a href=&quot;https://developer.spotify.com/web-api/&quot;&gt;API&lt;/a&gt; that allows you to access metadata for the large catalog of music available through their service. The experiment described below focuses on genre: a notoriously messy category that we nonetheless rely on to tell us how to process the materials we read, view, or hear. Genre tells us what to expect from the art we take in, and our construction and reception of generic categories can tell us a lot about ourselves. In music, especially, genres and subgenres can activate fierce debates about authenticity and belonging. Does your favorite group qualify as “authentic” jazz? What composers do you have to know in order to think of yourself as a real classical music aficionado? Playing with an artist’s metadata can expose a lot of the assumptions that were made in its collection, and I was especially interested in the ways in which Spotify models relations among artists.&lt;/p&gt;

&lt;p&gt;I wanted to explore Spotify’s metadata in a way that would model the interpretive messiness of generic categories. To do so, I built a program that bounces through Spotify’s metadata to produce multiple readings of the idea of genre in relation to a particular artist. Spotify offers a fairly robust API, and there are a number of handy wrappers that make it easier to work with. I used a Python module called &lt;a href=&quot;http://spotipy.readthedocs.org/en/latest/&quot;&gt;Spotipy&lt;/a&gt; for the material below, and you can find &lt;a href=&quot;https://github.com/bmw9t/spotify/blob/master/genre_machine.py&quot;&gt;the code for my little genre experiment over on my GitHub page&lt;/a&gt;. If you do try to run this on your own machine, note that you will need to clone Spotipy’s repository and manually install it from the terminal with the following command from within the downloaded repository:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ python setup.py install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Pip will install an older distribution of the code that will only run in Python 2, but Spotipy’s GitHub page has a more recent release that is compatible with Python 3.&lt;/p&gt;

&lt;p&gt;When run, the program outputs what I like to think of as the equivalent of music nerds arguing over musical genres. You provide an artist name and a number, and the terminal will work through Spotify’s API to produce the specified number of individual “mappings” of that artist’s genre as well as an aggregate list of all their associated genres. The program starts by pulling out all the genre categories associated with the given artist as well as those given to artists that Spotify flags as related. Once finished, the program picks one of those related artists at random and continues to do the same until the process returns no new genre categories, building up a list of associated genres over time.&lt;/p&gt;

&lt;p&gt;So, in short, you give the program an artist and it offers you a few attempts at describing that artist generically using Spotify’s catalog, the computational equivalent of instigating an argument about genre in your local record store. Here are the results for running the program three times for the band New Order:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Individual genre maps

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'new romantic', 'new wave pop', 'hi nrg', 'europop', 'power pop', 'album rock']

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'gothic metal', 'j-metal', 'visual kei', 'intelligent dance music', 'uk post-punk', 'metropopolis', 'ambient', 'big beat', 'electronic', 'illbient', 'piano rock', 'trance', 'progressive house', 'progressive trance', 'uplifting trance', 'quebecois', 'deep uplifting trance', 'garage rock', 'neo-psychedelic', 'space rock', 'japanese psychedelic']

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'uk post-punk', 'gothic rock', 'discofox', 'madchester', 'britpop', 'latin', 'latin pop', 'teen pop', 'classic colombian pop', 'rai', 'pop rap', 'southern hip hop', 'trap music', 'deep rai']

Aggregate genre map for New Order:

['dance rock', 'new wave', 'permanent wave', 'new romantic', 'new wave pop', 'hi nrg', 'europop', 'power pop', 'album rock', 'gothic metal', 'j-metal', 'visual kei', 'intelligent dance music', 'uk post-punk', 'metropopolis', 'ambient', 'big beat', 'electronic', 'illbient', 'piano rock', 'trance', 'progressive house', 'progressive trance', 'uplifting trance', 'quebecois', 'deep uplifting trance', 'garage rock', 'neo-psychedelic', 'space rock', 'japanese psychedelic', 'gothic rock', 'discofox', 'madchester', 'britpop', 'latin', 'latin pop', 'teen pop', 'classic colombian pop', 'rai', 'pop rap', 'southern hip hop', 'trap music', 'deep rai']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In each case, the genre maps all begin the same, with the categories directly assigned to the source artist. Because the process is slightly random, the program eventually maps the same artist’s genre differently each time. For each iteration, the program runs until twenty randomly selected related artists return no new genre categories, which I take to be a kind of threshold of completion for one understanding of an artist’s genre.&lt;/p&gt;

&lt;p&gt;The results suggest an amalgam of generic influence, shared characteristics, common lineages, and overlapping angles of approach. The decisions I made in how the program interacts with Spotify’s metadata suggest a definition of genre like the one offered by Alastair Fowler: “Representatives of a genre may then be regarded as making up a family whose septs and individual members are related in various ways, without necessarily having any single feature shared in common by all” (41). Genre is fluid and a matter of interpretive opinion - it is not necessarily based on objective links. The program reflects this in its results: sometimes a particular generic mapping feels very coherent, while at other times the script finds its way to very bizarre tangents. The connections do exist in the metadata if you drill down deeply enough, and it is possible to reproduce the links that brought about such output. But the more leaps the program takes from the original artist the more tenuous the connections appear to be. As I wrote this sentence, the program suggested a connection between garage rock revivalists The Strokes and big band jazz music: such output looks less like a conversation among music nerds and more like the material for a Ph.D. dissertation. As the program illustrates, generic description is the beginning of interpretation - not the ending.&lt;/p&gt;

&lt;p&gt;Of course, the program does not actually search all music ever: it only has access to the metadata for artists listed in Spotify, and some artists like Prince or the Beatles are notoriously missing from the catalog. Major figures like these have artist pages that serve as stubs for content drawn largely from compilation CDs, and the program can successfully crawl through these results. But this wrinkle points to a larger fact: the results the program produces are as skewed as the collection of musicians in the service’s catalog. Many of the errors I had to troubleshoot were related to the uneven nature of the catalog: early versions of the script were thrown into disarray when Spotify listed no related artists for a musician. On occasion, the API suggested a related artist who did not actually have an artist page in the system (often the case with new or less-established musicians). I massaged these gaps to make this particular exercise work (you’ll now get a tongue in cheek “Musical dead end” or “Artist deleted from Spotify” output for them), but the silences in the archive offer significant reminders of the commercial politics that go into generic and archival formation, particularly when an archive is proprietary. I can imagine tweaking things slightly to create a script that produces only those archival gaps, but that is work for another day. In the meantime, I’ll be trying to figure out &lt;a href=&quot;https://en.wikipedia.org/wiki/Yeezus&quot;&gt;how Kanye West might be considered Christmas music&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Works Cited:&lt;/p&gt;

&lt;p&gt;Fowler, Alastair David Shaw. Kinds of Literature: An Introduction to the Theory of Genres and Modes. Repr. Oxford: Clarendon Press, 1997. Print.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Virginia Woolf, Natural Language Processing, and the Quotation Mark</title>
   <link href="http://lanyon.getpoole.com/blog/2015/09/10/woolf-and-the-quotation-mark/"/>
   <updated>2015-09-10T11:21:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2015/09/10/woolf-and-the-quotation-mark</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Crossposted on the &lt;a href=&quot;http://scholarslab.org/?p=12117/&quot;&gt;Scholars’ Lab blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For my fellowship in the Scholars’ Lab this year I’ll be working with &lt;a href=&quot;http://scholarslab.org/people/eric-rochester/&quot;&gt;Eric&lt;/a&gt; to expand a project we began last year on Virginia Woolf and natural language processing. My dissertation focuses on sound recordings and modernism, and this year I will focus on how Woolf’s quotation marks offer evidence of her engagement with sound as a textual device. In my reading, the quotation mark is the most obvious point at which sound meets text, the most heavily used sound recording technology in use by writers. Patterns in quotation mark usage across large corpora can tell us a lot about the role that sound plays in literature, but, as you might expect, there are &lt;em&gt;lots&lt;/em&gt; of quotation marks - hundreds or thousands in any given text. Computational methods can help us make sense of the vast number and turn them into reasonable objects of study.&lt;/p&gt;

&lt;p&gt;You can find more information in &lt;a href=&quot;http://scholarslab.org/digital-humanities/hearing-silent-woolf/&quot;&gt;this post&lt;/a&gt; about my thinking on quotation marks and some preliminary results from thinking about them in relation to Woolf. As I discuss there, finding quotation marks in a text is not especially challenging, but this year Eric and I will be focusing on a particular wrinkle in Woolf’s use of the marks, best conveyed in &lt;em&gt;The Hours&lt;/em&gt;, Michael Cunningham’s late-century riff on Virginia Woolf. In &lt;em&gt;The Hours&lt;/em&gt;, Cunningham offers a fictionalized version of Woolf meditating on her composition process:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;She passes a couple, a man and woman younger than herself, walking together, leisurely, bent towards each other in the soft lemon-colored glow of a streetlamp, talking (she hears the man, “told me &lt;em&gt;something something something&lt;/em&gt; in this establishment, &lt;em&gt;something something&lt;/em&gt;, harrumph, indeed”) (166).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The repeated “&lt;em&gt;somethings&lt;/em&gt;” of the passage suggest the character’s imperfect experience of the conversation as well as the limits of her senses. As the moment is conveyed through the character’s perspective, the conversation will always be incomplete. Recording technology was largely unreliable during the early days of the twentieth century, and, similarly, the sound record of this conversation as given by the text is already degraded before we hear it. Cunningham points to how the sounded voice is given character in the ears of the listener, and, in a print context, in the pen of the writer. A printed voice can speak in a variety of ways and in a variety of modes.&lt;/p&gt;

&lt;p&gt;Cunningham’s passage contains echoes of what will eventually be the famous first sentence of Woolf’s &lt;em&gt;Mrs. Dalloway&lt;/em&gt;: “Mrs. Dalloway said she would buy the flowers herself.” The text implies that Mrs. Dalloway speaks, but it does not mark it as such: the same conversational tone in Cunningham remains here, but the narrator does not differentiate sound event from narrative by using quotation marks. We see moments of indirect speech like this all the time, when discourse becomes submerged in the texture of the narrative, but it doesn’t disappear entirely. Speech implies a lot: social relations, the thoughts of a speaking body, among others. Things get muddy when the line between narrative voice and speech becomes unclear. If quotation marks imply a different level of speech than unquoted speech, might they also imply changes in the social relations they represent?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Mrs. Dalloway&lt;/em&gt; is filled with moments like these, and this year I’ll be working to find ways to float them to the surface of the text. Examining these moments can tell us how conversation changes during the period, what people are talking about and for, how we conceive of the limits of print and sound, and about changing priorities in literary aesthetics. The goal this year is to train the computer to identify moments like this, moments that a human reader would be able to parse as spoken but that are not marked as such. Our first pass will be to work with the quoted material, which we can easily identify to build a series of trigger words that Woolf uses to flag speech as sound (said, asked, called, etc.). With this lexicon, we can then look for instances in her corpus where they pop up without punctuation. Teaching the computer to classify these passages correctly will be a big task, and this process alone will offer me lots of new material to work with as I untangle the relationship between modernist print and sound. In upcoming posts I’ll talk more about the process of learning natural language processing and about some preliminary results and problems. Stay tuned!&lt;/p&gt;

&lt;p&gt;Works Cited:&lt;/p&gt;

&lt;p&gt;Cunningham, Michael. &lt;em&gt;The Hours&lt;/em&gt;. New York: Picador USA : Distributed by Holtzbrinck Publishers, 2002. Print.&lt;/p&gt;

&lt;p&gt;Woolf, Virginia. &lt;em&gt;Mrs. Dalloway&lt;/em&gt;. 1st Harvest/HBJ ed. San Diego: Harcourt Brace Jovanovich, 1990. Print.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hearing Silent Woolf</title>
   <link href="http://lanyon.getpoole.com/blog/2015/03/23/woolf-huskey/"/>
   <updated>2015-03-23T16:37:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2015/03/23/woolf-huskey</id>
   <content type="html">&lt;p&gt;&lt;em&gt;[This week I presented at the &lt;a href=&quot;http://gradcouncil.com/2015-sessions/&quot;&gt;2015 Huskey Research Exhibition&lt;/a&gt; at UVA. The talk was delivered from very schematic notes, but below is a rough recreation of what I discussed. The talk I gave is a crash course in a new project I’ve started working on with the generous help of the &lt;a href=&quot;http://scholarslab.org&quot;&gt;Scholars’ Lab&lt;/a&gt; that thinks about sound in Virginia Woolf’s career using computational methods. &lt;a href=&quot;http://www.ericrochester.com/&quot;&gt;Eric Rochester&lt;/a&gt;, especially, has been endlessly giving of his time and expertise, helping me think through and prototype work on this material. The talk wound up receiving first prize for the digital humanities panel of which I was a part. The project is still very much inchoate, and I’d welcome thoughts on it.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When I talk to you, you make certain assumptions about me as a person based on what you’re hearing. You decide whether or not I might be worth paying attention to, and you develop a sense of our social relations based around the sound of my voice. The voice conveys and generates assumptions about the body and about power: am I making myself heard? Am I registering as a speaking voice? Am I worth listening to?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://commons.wikimedia.org/wiki/File:Day_14_Occupy_Wall_Street_September_30_2011_Shankbone_2.JPG &quot;&gt;&lt;img src=&quot;/assets/images/occupy.jpg&quot; width=&quot;60%&quot; class=&quot;left&quot; alt=&quot;Occupy Wall Street September 30 2011&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The human microphone, made famous by Occupy Wall Street, nicely encapsulates the social dimensions of sound that interest me: one person speaks, and the people around her repeat what she says more loudly, again and again, amplifying the human voice without technology. Sound literally moves through multiple bodies and structures the social relations between people, and the whole movement is an attempt to make a group of people heard by those who would rather not listen.&lt;/p&gt;

&lt;p&gt;As a literary scholar, I am interested in how texts can speak in similar ways. The texts we read frequently contain large amounts of speech within them: conversations, monologues, poetic voice, etc. We talk about sound in texts all the time, and the same social and political dimensions of sound still remain even if a text appears silent on the page. If who can be heard and who gets to speak are both contested questions in the real world, they continue to structure our experiences of printed universes.&lt;/p&gt;

&lt;p&gt;All of this brings me to the quotation mark. The humble piece of punctuation does a lot of work for us every day, and I want to think more closely about how it can help us understand how texts speak. The quotation mark is the most obvious point at which sound meets text. Computational methods tend to focus on the vocabulary of a text as the building blocks of meaning, but they can also help us turn quotation marks into objects of inquiry. Quotation marks can tell us a lot about how texts engage with the human voice, but there are &lt;em&gt;lots&lt;/em&gt; of them in texts. Digital methods can help us make sense of the scale.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/woolf.jpg&quot; width=&quot;40%&quot; class=&quot;right&quot; alt=&quot;Woolf portrait&quot; /&gt;I examine Virginia Woolf’s quotation marks, in particular, for a number of reasons. Aesthetically, we can see her bridging the Victorian and modernist literary periods, though she tends to fall in with the latter of the two. Politically, she lived through periods of intense social and political upheaval at the beginning of the twentieth century. Very few recordings of Woolf remain, but she nonetheless thought deeply about sound recording. The worldwide market for gramophones exploded during her lifetime, and her texts frequently featured technologies of sound reproduction. Woolf’s gramophones frequently malfunction in her novels, and I’m interested in seeing how her quotation marks might analogously be irregular or broken intentionally. Woolf is especially good for thinking about punctuation marks in this way: she owned a printing press, and she often set type herself.&lt;/p&gt;

&lt;p&gt;The following series of histograms gives a rough estimation of how Woolf’s use of quotation changes over the course of her career. &lt;a href=&quot;https://github.com/erochest/woolf/commits/master&quot;&gt;On GitHub&lt;/a&gt; you can find the script I’ve been working on with Eric to generate these results. The number of quotations is plotted on the y-axis against their position in the novel on the x-axis, so each histogram represents more quoted speech with higher bars and more concentrated darknesses. If you have an especially good understanding of a particular novel, &lt;em&gt;Mrs. Dalloway&lt;/em&gt;, say, you could pick out moments of intense conversation based on sudden spikes in the number of quotations. The histograms are organized in such a way that to read chronologically through Woolf’s career you would read left to right line by line, as you would the text of a book. The top-left histogram is Woolf’s earliest novel, the bottom-right corner her last.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/images/huskey-histograms/1915_the_voyage_out.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1915_the_voyage_out.jpg&quot; width=&quot;32%&quot; alt=&quot;Histogram of quotation use in The Voyage Out&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;/assets/images/huskey-histograms/1919_night_and_day.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1919_night_and_day.jpg&quot; width=&quot;32%&quot; alt=&quot;Histogram of quotation use in Night and Day&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;/assets/images/huskey-histograms/1922_jacobs_room.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1922_jacobs_room.jpg&quot; width=&quot;32%&quot; alt=&quot;Histogram of quotation use in Jacob's Room&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;/assets/images/huskey-histograms/1925_mrs.dalloway.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1925_mrs.dalloway.jpg&quot; width=&quot;32%&quot; alt=&quot;Histogram of quotation use in Mrs. Dalloway&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;/assets/images/huskey-histograms/1927_to_the_lighthouse.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1927_to_the_lighthouse.jpg&quot; alt=&quot;Histogram of quotation use in To the Lighthouse&quot; width=&quot;32%&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;/assets/images/huskey-histograms/1928_orlando.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1928_orlando.jpg&quot; width=&quot;32%&quot; alt=&quot;Histogram of quotation use in Orlando&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;/assets/images/huskey-histograms/1931_the_waves.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1931_the_waves.jpg&quot; width=&quot;32%&quot; alt=&quot;Histogram of quotation use in The Waves&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;/assets/images/huskey-histograms/1937_the_years.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1937_the_years.jpg&quot; width=&quot;32%&quot; alt=&quot;Histogram of quotation use in The Years&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;/assets/images/huskey-histograms/1941_between_the_acts.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/1941_between_the_acts.jpg&quot; width=&quot;32%&quot; alt=&quot;Histogram of quotation use in Between the Acts&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To my eye, the output suggests high concentrations of conversation in the novels at the beginning and ending of Woolf’s career. We can see that her middle period, especially, appears to have a significant decrease in the amount of quoted speech. In one sense, this might make sense to someone familiar with Woolf’s career. Her first two novels feel more typically Victorian in their aesthetics, and she really gets into the thick of modernist experiment with her third novel. One way we often describe the shift from Victorian to the modernist period is as a shift inward, away from society and towards the psychology of the self. So it makes sense that we might see the amount of conversation between multiple speaking bodies significantly fall away over the course of those novels. &lt;a href=&quot;/assets/images/huskey-histograms/1931_the_waves.jpg&quot;&gt;The seventh histogram&lt;/a&gt; is especially interesting, because it suggests the least amount of speech of anything in her corpus. But if we visualize things a different way, we see that this novel, &lt;em&gt;The Waves&lt;/em&gt;, actually shows a huge spike in punctuated speech. This graph represents the percentage of each text that is contained within quotation marks, the amount of text represented as punctuated speech.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/images/huskey-histograms/percentage-quoted.jpg&quot;&gt;&lt;img src=&quot;/assets/images/huskey-histograms/percentage-quoted.jpg&quot; class=&quot;right&quot; alt=&quot;Graph of percentage of quoted material in The Waves&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This might look like a problem with the data: how could the text with the fewest number of quotations also have the highest percentage of quoted speech? But the script is actually giving me exactly what I asked for: &lt;em&gt;The Waves&lt;/em&gt; is a series of monologues by six disembodied voices, and the amount of non-speech text is extremely small. More generally, charting the percentage of quoted speech in the corpus appears to support my general readings of the original nine histograms: roughly three times as much punctuated speech in the early novels as in the middle period, with a slight leveling off in the end of her career.&lt;/p&gt;

&lt;p&gt;We could think of &lt;em&gt;The Waves&lt;/em&gt; as an anomaly, but I think it more clearly calls for a revision of such a reading of speech in Woolf’s career. The spike in quoted speech is a hint that there is something else going on in Woolf’s work. Perhaps we can use the example of &lt;em&gt;The Waves&lt;/em&gt; to propose that there might be a range of discourses, of types of speech in Woolf’s corpus. Before I suggested that speech diminished in the middle of Woolf’s career, but that’s not exactly true. My suspicion is that it just enters a different mode. Consider these two passages, both quoted from &lt;em&gt;Mrs. Dalloway&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mrs. Dalloway said she would buy the flowers herself.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Times without number Clarissa had visited Evelyn Whitbread in a nursing home.  Was Evelyn ill again?  Evelyn was a good deal out of sorts, said Hugh, intimating by a kind of pout or swell of his very well-covered, manly, extremely handsome, perfectly upholstered body (he was almost too well dressed always, but presumably had to be, with his little job at Court) that his wife had some internal ailment, nothing serious, which, as an old friend, Clarissa Dalloway would quite understand without requiring him to specify.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In each case, the text implies speech by Mrs. Dalloway and by Hugh without marking it as such with punctuation marks. Discourse becomes submerged in the texture of the narrative, but it doesn’t disappear entirely. Moments like these suggest a range of discourses in Woolf’s corpus: dialogue, monologue, conversation, punctuated, implied, etc. All of these speech types have different implications, but it’s difficult to get a handle on them because of their scale. I began the project by simply trying to mark down moments of implied speech in &lt;em&gt;Mrs. Dalloway&lt;/em&gt; by hand. Once I got to about two hundred, it seemed like it was time to ask the computer for help.&lt;/p&gt;

&lt;p&gt;The current plan moving forward is to build a corpus of test passages containing both quoted speech and implied speech, train a python script against this set of passages, and then use this same script to search for instances of implied speech throughout Woolf’s corpus. Theoretically, at least, the script will search for a series of words that flag text as implied speech to a human reader - said, recalled, exclaimed, etc. Using this lexicon as a basis, the script would then pull out the context surrounding these words to produce a database of sentences meant to serve as speech. At Eric’s suggestion, I’m currently exploring the &lt;a href=&quot;http://www.nltk.org/index.html&quot;&gt;Natural Language Toolkit&lt;/a&gt; to take a stab at all of this. My own hypothesis is that there will be an inverse relationship between quoted speech and implied speech in her corpus, that the amount of speech left unflagged by quotation marks will increase in the middle of Woolf’s career. Once I have all this material, I’ll be able to subject the results to further analysis and to think more deeply about speech in Woolf’s work. Who speaks? What about? What counts as a voice, and what is left in an ambiguous, unsounded state?&lt;/p&gt;

&lt;p&gt;The project is very much in its beginning stages, but it’s already opening up the way that I think about speech in Woolf’s text. It tries to untangle the relationship between our print record and our sonic record, and further work will help show how discourse is unfolding over time in the modernist period.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Moving People, Linking Lives DH Symposium</title>
   <link href="http://lanyon.getpoole.com/blog/2015/02/02/moving-people-linking-lives-dh-symposium/"/>
   <updated>2015-02-02T14:33:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2015/02/02/moving-people-linking-lives-dh-symposium</id>
   <content type="html">&lt;p&gt;[I am very excited to be working with Alison Booth, Jenny Strauss Clay, and Amy Ogden to plan a digital humanities symposium this March. What follows is our general announcement of the event, cross-posted on the &lt;a href=&quot;http://scholarslab.org/uncategorized/moving-peoplelinking-lives-dh-symposium/&quot;&gt;Scholars’ Lab&lt;/a&gt; blog.]&lt;/p&gt;

&lt;p&gt;I am pleased to announce that “&lt;a href=&quot;http://movingpeoplelinkinglives.org&quot;&gt;Moving People, Linking Lives: An Interdisciplinary Symposium&lt;/a&gt;” will take place March 20-21, 2015 at the University of Virginia. Presentations and workshops will open dialogue across different fields, periods, and methods, from textual interpretation to digital research. Invited participants include specialists on narrative theory and life writing, prosopography or comparative studies of life narratives in groups, and the diverse field of digital humanities or computer-assisted research on cultural materials, from ancient texts to Colonial archives, from printed books to social media.&lt;/p&gt;

&lt;p&gt;Invited participants include: Elton Barker, Jason Boyd, James Phelan, Susan Brown, Margaret Cormack, Courtney Evans, Will Hanley, Ben Jasnow, Ruth Page, Sue Perdue, Sidonie Smith. We hope to have lots of locals involved with digital work participate as well, and we particularly encourage graduate students to join in for the weekend!&lt;/p&gt;

&lt;p&gt;Our symposium will bridge the gaps among our fields; share the innovations of several digital projects; and welcome the skeptical or the uninitiated, whether in our historical fields or in the applications of technology in the humanities. Booth, Clay, and Ogden have each led digital projects with some common themes and aims: locating, identifying, and interpreting the narratives—or very often, the lack of discursive records—about individuals in groups or documents, in Homer or other ancient text, Medieval French hagiography, and nineteenth-century printed collections of biographies in English. We want to open discussion of many potential methods including our own—data mining and digital editions of texts; relational databases and historical timelines and maps—for research on groups of interlinked persons, narratives or data about their lives, and documents or other records, and synthesizing and visualizing this research in accessible ways that reach students and the public. Digital innovation, however, should be informed by traditions of scholarly interpretation and advanced theoretical insights and commitments. Narrative theory and Theory generally, ideological critique including studies of gender and race, textual and book history studies, transnational and social historiography, philology and language studies, archeology, cultural geography and critical cartography, are all gaining influence on digital projects.&lt;/p&gt;

&lt;p&gt;Invited participants will be posting about their research to &lt;a href=&quot;http://movingpeoplelinkinglives.org&quot;&gt;our blog&lt;/a&gt; in the weeks leading up to the symposium, anyone is free to comment on the posts. In addition, our participants will be building a &lt;a href=&quot;http://movingpeoplelinkinglives.org/bibliography/&quot;&gt;Zotero-powered bibliography&lt;/a&gt; in the weeks leading up to the symposium full of rich materials related to the event’s discussion.&lt;/p&gt;

&lt;p&gt;Organized and hosted by Alison Booth, Jenny Strauss Clay, and Amy Odgen and sponsored by the Page Barbour Committee, the departments of English, French, and Art, the Institute for Humanities and Global Cultures, the Scholars’ Lab and Institute for Advanced Technology in the Humanities, and other entities at UVa, all events are free and open to the public. More information can be found on the blog as planning progresses, and you can follow us on twitter at @livesdh.&lt;/p&gt;

&lt;p&gt;Join in the conversation on the blog at &lt;a href=&quot;http://movingpeoplelinkinglives.org&quot;&gt;movingpeoplelinkinglives.org&lt;/a&gt;, and we hope to see many come out for fruitful interchange in March!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Collation and Writing Pedagogy</title>
   <link href="http://lanyon.getpoole.com/blog/2015/01/17/collation/"/>
   <updated>2015-01-17T09:41:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2015/01/17/collation</id>
   <content type="html">&lt;p&gt;[The following is the talk that I gave at the 2015 MLA Conference on a panel on “Pedagogy and Digital Editions.” The Google Docs section is a slight reworking and recontextualization of a &lt;a href=&quot;http://walshbr.github.io/blog/2013/09/25/writing-out-loud/&quot;&gt;previous post&lt;/a&gt; on the subject. I’m especially grateful to &lt;a href=&quot;https://twitter.com/damozel_&quot;&gt;Sarah Storti&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/andrew_stauffer&quot;&gt;Andrew Stauffer&lt;/a&gt; for their suggestions and comments on how to use Juxta Commons to teach writing.]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Collation and Writing Pedagogy with Juxta Commons and Google Docs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We typically think about using digital collation to compare those documents that already exist. The usual model gathers multiple copies, multiple witnesses, of the same text, and juxtaposes them to gather a sense of the very small, micro changes that have been made to a document. We use these changes to deconstruct our sense of a complete and unified final whole. Instead, we get a sense of a series of related texts, of a work manifesting in different forms, and of stages of a revision process for which we were not present. I am especially interested in the last of these categories: collation tools allow us to uncover revision histories that might be otherwise obscured. They help us to uncover past stages of the writing process, breaking apart a text that might seem concrete and fixed and make it appear fluid and subject to change.&lt;/p&gt;

&lt;p&gt;The illusion of a final unified text is a problem for textual editing, and collation tools have helped us to solve it for decades. This same problem, the tendency to think of texts as final objects with no prior histories, is at its core one of the key difficulties facing student writers. There is a danger for students to think of writing as crafting a marble structure – you chip away at it piece by piece until it forms a perfect, fixed form – the form it was meant to possess all along. Instead, I want to argue that collation tools can be used by teachers to help students conceive of writing as a kind of assemblage, a piecing together that instantiates one possible combination among many of a set of textual components. This mode of writing is, by contrast, characterized by play, transformation, and fluidity.&lt;/p&gt;

&lt;p&gt;I will talk about two tools today in this context - &lt;a href=&quot;http://juxtacommons.org/&quot;&gt;Juxta Commons&lt;/a&gt; and &lt;a href=&quot;http://www.google.com/docs/about/&quot;&gt;Google Docs&lt;/a&gt; – and the exercises I use with each. The former is a collation tool proper, and, while the latter is more typically used for collaborative writing, it lends itself quite readily to the practice. So my focus here is on the practical – how to think about and use these tools for to teach writing and revision. I hope to tease out more of their implications in the discussion.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Juxta Commons&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Juxta Commons, probably familiar to many, is the latest iteration of Juxta, a piece of software that allows a user to upload multiple textual witnesses and, at a glance, discern the differences. The tool’s digital nature means that the process is quantified and streamlined – no laboring over the collator. It also has the benefit of offering a number of visualizations for graphically understanding the differences between two witnesses, a fact that I find helpful for talking about student writing.&lt;/p&gt;

&lt;p&gt;A potential writing exercise for use with Juxta is simple: a student writes a paragraph, and they then rewrite that paragraph several times. Finally, the student uploads each version to Juxta before writing a brief reflection on the differences between the drafts. What remains constant? Where do changes cluster? Do these edits indicate any special anxiety or concern with any one particular element of the writing process – transitional sentences, thematic chaining, logic, etc.? Do the ideas themselves stay the same? Fixating on these details can allow students to conceive of writing as an assemblage of various components that result in the illusion of a coherent whole.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/variants.jpg&quot; width=&quot;100%&quot; alt=&quot;Revised paragraph from a student in Juxta Commons.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the example above, the student is writing a grant proposal for his tennis team. In an early draft, the class noted that the writing held the team at too much of a remove when the author wanted to stress its importance to him as a second family. Such a charge can seem like a big task, but processing the paragraph through the Juxta assignment throws into sharp relief the minute edits created in a revision to create such systemic change. Comparing the two revisions in Juxta, we can see that, by and large, the student revised the subjects of this first paragraph. “I” becomes “we,” and “friends” will become a “family.” He works to increase the sense of unity among the group of people he describes, a unity that will later become essential in his argument that the organization provides more to the community than just a place to play sports. The Juxta assignment allows a student better insight into how each of these component pieces can easily be sent into motion and radically change the character of the whole document. A large, sweeping suggestion like “adjust your tone” becomes revision by way of a thousand moving pieces. Much more doable.&lt;/p&gt;

&lt;p&gt;Juxta Commons has the added bonus of being envisioned as a commons - an online community of textual scholars. It is quite easy to share sets with others, and it would take little effort to set up a repository of shared collation sets among a classroom. To encourage objective reflection as a component of writing, I would ask each student to write a short reflection on a different student’s collation set, observing the differences and reflecting on the minute changes that got them there.&lt;/p&gt;

&lt;p&gt;Juxta’s strength as a collation tool is also its limitation for the sort of teaching exercise that I am describing. Juxta has the benefit of being quantitative: its visualizations can offer users quick and accurate depictions of things that might otherwise go unrecognized – a missing comma, or a single different word. Juxta works best with large documents that are largely the same. But if the corresponding passages become too different Juxta will be thrown into disarray.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/too_much_difference.jpg&quot; width=&quot;100%&quot; alt=&quot;Revised paragraph of student's work in Juxta that is too different to function properly in their system.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While it is very good at processing texts to find small differences, the software does not quite work if the documents are too different from one another. Its system allows for either exact similarity or difference at the level of character. It cannot tell, for example, if you have reworded a particular phrase or removed it entirely. The paragraph in this example was heavily rewritten, with only a few words in common between the two drafts. While this sort of at a glance collation could be useful to identify revised sections in longer documents, it does little to unsettle the idea of writing as a search for a fully realized whole. Juxta Commons works best for helping students to see the massive change that can be wrought by a collection of small changes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Google Docs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One of the difficulties with using Juxta to collate is that it relies on a student’s already extant drafts – revision must already have taken place, which seems to defeat the whole purpose of an exercise designed to unsettle the writing process. Google Docs is not a tool made for collation, but I do think that it can helpfully generate just those many witnesses that &lt;strong&gt;could&lt;/strong&gt; be collated. By using Google Docs as a collaborative writing space, classmates can help another generate different textual possibilities for a single sentence. My use of Google Docs in conjunction with a discussion of writing first came about in an advanced course on Academic and Professional Writing. We talked a lot about editing in the class, and many of the conversations about style took this shape:&lt;/p&gt;

&lt;p&gt;Student A: “Something about this word feels strange, but I don’t know what it is.” &lt;br /&gt;
Student B: “What if we moved the phrase to the beginning of the sentence?”&lt;br /&gt;
Student C: “We could get rid of that word and use this phrase instead.”&lt;/p&gt;

&lt;p&gt;Those statements are hard to wrap your head around. Just imagine if those conversations were spoken. Talking about writing can only get you so far: writing is graphic, after all. As I write and edit, I try out different options on the page. I model possibilities, but I do so &lt;em&gt;in&lt;/em&gt; writing. Discussing the editing process without visual representations of suggested changes can make things too abstract to be meaningful for students. They need to see the different possibilities, the different potential witnesses. I developed an exercise that I call “Writing Out Loud” that more closely mirrors my actual editing process. Using a Google Doc as a collaborative writing space, students are able to model alternate revisions visually and in real time for discussion.&lt;/p&gt;

&lt;p&gt;The setup requires a projector-equipped classroom and that students bring their laptops to class. Circulate the link to the Google Doc ahead of time, taking care that anyone with the link can edit the document. The template of the Google Doc consists of a blank space at the top for displaying the sentence under question and a series of workspaces for each student consisting of their name and a few blank lines. Separate workspaces prevent overlapping revisions, and they also minimize the disorienting effects of having multiple people writing on the same document.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/WOL_template.jpg&quot; width=&quot;40%&quot; class=&quot;right&quot; alt=&quot;Blank writing out loud template with space for each student to write.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We usually turn to the exercise when a student feels a particular sentence is not working but cannot articulate why. When this happens, I put the Writing Out Loud template on the projector with the original version of the sentence at the top. Using their own laptops, students sign onto the Doc and type out alternative versions of the sentence, and the multiple possible revisions show up on the overhead for everyone to see and discuss. After each student rewrites the sentence to be something that they feel works better, ask for volunteers to explain how the changes affect meaning. The whole process only takes a few minutes, and it allows you to abstract writing principles from the actual process of revision rather that the other way around. How does the structure of a sentence matter? How can word choice change everything? What pieces of a sentence are repetitive?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/WOL_filled.jpg&quot; width=&quot;100%&quot; alt=&quot;Different versions of the same sentence written by students using the template.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I especially like this exercise because it asks multiple students to engage in the revision process. It is always easier to revise when you have critical distance on a piece of writing, and outside editors with no attachment to a particular word or phrase can offer just that. In the above example, the sentence under discussion contained the colloquial phrase “get the word out.” The class offered a range of alternatives that range in their formality. Instead of receiving an edict to professionalize their tone, the student gets a glimpse of many possibilities from which he can choose. The exercise also allows the choices to exist side by side, making collation possible in a way that the usual revision process makes difficult. Most students, I would wager, work with one or, at most, two drafts open at a single time. Google Docs can allow a number of possibilities to emerge.&lt;/p&gt;

&lt;p&gt;The Google Docs exercise works better on micro-edits, revisions at the level of the sentence. The standard process of the exercise—write, collate, and discuss—would take far too long with anything longer than a few lines. The exercise can be particularly useful for those sentences that carry a lot of importance for entire arguments: thesis statements, topic sentences, the first sentences of the document, etc. Where Juxta is entirely quantitative and offers hand graphic visualizations of textual difference, this Google Docs exercise relies on you and the students to collate the materials yourselves. You can recognize subtle differences – a reworded idea vs. a dropped idea, for example. It trains students to internalize the practice of collation and reflect on the interpretive possibilities offered by such differences.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Closing Analysis&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I find that students often think of editing as an intense, sweeping process that involves wholesale transformation from the ground up. Modeling multiple, slightly different versions of the same sentence can allow for a more concrete discussion of the sweeping rhetorical changes that even the smallest edits can make. In this sense, I think using these tools in the classroom allows students to conceive of a single composition as one instantiation among many. Forcing them to compose several different models means that the writing process will be looser. Collation as composition offers students a subjunctive space wherein they dwell in possibilities. It is a vision of composition as de and reconstruction, as a process that is constantly unfolding.&lt;/p&gt;

&lt;p&gt;Digital tools uncover how writing is really always already such a fluid process, and they can allow students to see their own composition process in this way while they are still in the thick of it. Digital collation can offer students the chance to think of their own works as messy, subjunctive spaces, as things in flux. By allowing multiple possible versions of the same text to exist alongside and in relation to one another, they can allow students to slip between different textual realities. Most importantly, the process severs the link between the quality of an idea and the manner of its presentation. Instead of one right answer, students can see that there are many possible solutions to any writing difficulty.&lt;/p&gt;

&lt;p&gt;I have touched on how exercises like these can also encourage students to distill writing principles from the process rather than the other way around. They can also help students to discover editorial principals through their own writing. I am imagining here a praxis-oriented approach to teaching textual editing where practice leads to principal, one where scholarly readings might come after a student has written an essay, revised it, and, in effect, produced their own edition of their text. An exercise with Juxta might lead to a discussion of eclectic editions, while Google Docs could lead to a fruitful discussion of accidentals and substantives. I am not suggesting that these sorts of exercises replace the good work performed by studying classic editions, reading about editorial practices, or producing one’s own edition by carrying out the steps of the editorial process. But in a class that has an explicit focus on composition, exercises with tools like Juxta Commons and Google Docs can help connect textual criticism with writing pedagogy.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The Devil in the Recording</title>
   <link href="http://lanyon.getpoole.com/blog/2015/01/12/deformance-talk/"/>
   <updated>2015-01-12T10:29:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2015/01/12/deformance-talk</id>
   <content type="html">&lt;p&gt;[The following is an only slightly modified version of the talk I gave at the &lt;a href=&quot;http://ach.org/&quot;&gt;ACH&lt;/a&gt;’s panel on “Digital Deformance and Scholarly Forms” at the 2015 MLA conference. For more details on how to reverse audio recordings, see my &lt;a href=&quot;http://walshbr.github.io/blog/2015/01/05/deformance/&quot;&gt;previous post on the subject&lt;/a&gt;.]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Devil in the Recording: Deformative Listening and Sound Reproduction&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It’s a well-known fact that you can find the devil in popular music. Simply take Led Zeppelin’s “Stairway to Heaven,” play it backwards, and voila. You’ll get messages for, if not by, the Lord of the Flies. Obviously I’m being facetious. Few, if any, take this claim seriously, but it does offer serious ways to think about deformance in the context of sound recordings, particularly those with linguistic or literary content. The digital method of deformance I’ll speak about today, then, is a simple one. Using open source tools like &lt;a href=&quot;http://audacity.sourceforge.net/&quot;&gt;Audacity&lt;/a&gt;, it’s easier than ever to play recordings backwards, to reverse a sound clip with the flip of a switch. I’ll touch just a bit on the history of such methods as they pertain to music and then speculate as to what they can tell us about approaches to thinking about literary sound recordings. I’m a modernist, and my examples will reflect this bias. My ultimate conclusions are as follows. First: reading backwards juxtaposed against audio reversal reveals the unique character of literary sound recordings to be simultaneously sounded and print, to be audiotextual objects as I call them. Second: deformance can offer us new modes for thinking about media failures and malfunctions that actually do exist constantly and all around us. In particular, audio deformance is something that the modernists were keenly interested in, and deformance as a practice can get us closer to the relationships they had with media.&lt;/p&gt;

&lt;p&gt;So here is part of “Stairway to Heaven” backwards.&lt;/p&gt;

&lt;audio controls=&quot;&quot;&gt;&lt;source src=&quot;/assets/mp3s/mla-2015/zeppelin_reversed.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;&lt;source src=&quot;/assets/ogg/mla-2015/zeppelin_reversed.ogg&quot; type=&quot;audio/ogg&quot; /&gt;Your browser does not support this audio format.&lt;/audio&gt;

&lt;p&gt;Source: &lt;a href=&quot;http://youtu.be/zGsUcPdPWBg?t=47s&quot;&gt;http://youtu.be/zGsUcPdPWBg?t=47s&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Can’t you hear the devil? The “Stairway to Satan,” as I will call it, suggests that we can find new linguistic content in an already extant sound message. Detractors of the “Stairway to Satan” narrative (numerous on Youtube if you care to check them out) suggest that this is just a function of our minds wanting to make sense of chaos. Is this gibberish? Or is it a collection of scattered sound components that can be reconstituted into a whole? In &lt;a href=&quot;http://www2.iath.virginia.edu/jjm2f/old/deform.html&quot;&gt;Lisa Samuels and Jerome McGann’s essay on deformance&lt;/a&gt; from which this panel takes its cue, they discuss reading Emily Dickinson’s poetry backwards in a mode not too far removed from this discussion. Reading backwards can throw into sharp relief the linguistic components, the very pieces that make up a poem, and at the end of the day, you still have the lines, the words, or even the component letters. It’s possible to reassemble these into semantic meanings.&lt;/p&gt;

&lt;p&gt;But sound recordings are something different. They are bound in time in a different way. Daniel Albright in &lt;em&gt;Untwisting the Serpent&lt;/em&gt; describes music by way of “Lessing’s famous distinction between the spatially juxtapositive arts of &lt;em&gt;nebeinander&lt;/em&gt;, such as painting, sculpture, and architecture, and the temporally progressive arts of &lt;em&gt;nacheinander&lt;/em&gt;, such as poetry and music” (9). Our experience of music and poetry depend upon their ability to move forward in time. To put the distinction in the context of deformance: you can move around a sculpture and view it from different angles, but it remains the same sculpture. Deform a musical recording by reversing its waveform, however, and you end with a different musical artifact entirely, one with different component parts. Hence, it can sound like gibberish.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/waveform-large.jpg&quot; width=&quot;50%&quot; class=&quot;right&quot; alt=&quot;large waveform&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here is the waveform for the Zeppelin clip. The waveform here is a charting of intensity over time, and the reversal literally changes the original artifact. It’s a mirror image, but our ears are hard-pressed to be able to reconnect the new object to its original. Many kinds of deformance you can do on an audio recording would work in the same way – alter the pitches, smash them tighter, stretch them out, etc. You alter that wave, and you get something else entirely. At what point does it become something new?&lt;/p&gt;

&lt;p&gt;But some reversed audio still sounds like a recognizable tune. Behind the “Stairway to Satan” claim is a long history behind it of musical reversal and mirroring. Musicians and listeners have been fascinated with the vectored nature of sound for centuries, and composers have experimented with reversal as a spur to creativity for ages. Take this melody.&lt;/p&gt;

&lt;video width=&quot;320&quot; height=&quot;240&quot; controls=&quot;&quot;&gt;
  &lt;source src=&quot;/assets/videos/canon-retrogrado.mp4&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Source: &lt;a href=&quot;http://www.teoria.com/en/reference/q-r/retrograde.php&quot;&gt;http://www.teoria.com/en/reference/q-r/retrograde.php&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The melody of the first ten measures is followed by a retrograde repetition of itself, meaning that it is a musical palindrome. All of the intervals of this first section become reversed and, if you were to fold the melody in upon itself, it would perfectly line up. Playing backwards is itself built into the creative process. The playback reflects this as the bouncing ball literally moves backwards on the page, but, if you were to write it out, it would look quite different. The kind of deformance that I am describing, that Zeppelin conspiracy theorists lament, and that Samuels and McGann suggest – it’s built into the music itself.&lt;/p&gt;

&lt;p&gt;The melodic reversal of music like this works because, as Walter Pater taught us, music can be thought of as a “perfect identification of matter and form.” Flip the melody and you do not lose information, you get a new melody. The new object is still discernible as music because it is new music. The addition of linguistic content complicates the question - phonemes when reversed do not necessarily and easily coordinate with other phonemes. A recorded object with linguistic content has two distinct characters, each of which overlap with the other. It’s an obvious point, but one that I think has profound implications.&lt;/p&gt;

&lt;p&gt;In Langston Hughes’s 1958 recording of “Motto” in collaboration with Charles Mingus and Leonard Feather, we can start to approach some useful conclusions about what this might all mean. The excerpt starts with an instrumental section and then Hughes comes in. So keep in mind that, in the reversal, we’ll hear the poetry first and then the instrumental part.&lt;/p&gt;

&lt;p&gt;“Motto”&lt;/p&gt;

&lt;audio controls=&quot;&quot;&gt;&lt;source src=&quot;/assets/mp3s/mla-2015/motto.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;&lt;source src=&quot;/assets/ogg/mla-2015/5_motto.ogg&quot; type=&quot;audio/ogg&quot; /&gt;Your browser does not support this audio format.&lt;/audio&gt;

&lt;p&gt;“Motto” Reversed&lt;/p&gt;

&lt;audio controls=&quot;&quot;&gt;&lt;source src=&quot;/assets/mp3s/mla-2015/motto_reversed.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;&lt;source src=&quot;/assets/ogg/mla-2015/motto_reversed.ogg&quot; type=&quot;audio/ogg&quot; /&gt;Your browser does not support this audio format.&lt;/audio&gt;

&lt;p&gt;The recording is a useful analogy for vocal sound recordings more generally in that it has two distinct pieces – a musical (non-verbal sound) component, and a recorded voice (with linguistic content). The two elements often intertwine and are not easily separated (this example not withstanding). You can hear, I think, the stark difference between the reversed poetic content by Hughes and the reversed instrumental content. Hughes reversed sounds like nonsense, while the saxophone in particular still sounds like something of a melody. The digital reversal of sound recordings treats them both as waveforms with no semantic content – it reverses them just as easily and happily as it would any other sound recording.&lt;/p&gt;

&lt;p&gt;We might expect the practice of deformance to throw into sharp relief the status of these recordings as sound objects. The pops, silences, and phonetic meanings of a reading suddenly become especially salient, and we might expect this reversal to make us hyper-aware of their sounded nature. In theory the deformance of these recordings more easily allows us to practice what Charles Bernstein has called “close listening,” examining the sounded nature of these objects. But, as the sounds themselves become distorted almost beyond recognition, the method can only provide clues towards such a practice. We might gain general senses, as with the Hughes, of the general prominence of certain registers or frequencies, silences and gaps, or of sections that are particularly filled with sonic activity. All of these might provide hints of content that might bear out fruitful analysis when put forwards again.&lt;/p&gt;

&lt;p&gt;Deformance of poetic recordings forces us to consider the nature of recorded literary recordings anew. We might extrapolate from the character of this recording that all recorded voices contain a linguistic element as well an audible one. Not fully audio nor fully textual artifacts, I want to say that they are, instead something we might call audiotextual, a term that Jason Camlot has recently used in relation to the classification of Victorian literary recordings as an expansion of McGann’s own historicist approach to textual criticism.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/audiotextual.jpg&quot; width=&quot;40%&quot; class=&quot;right&quot; alt=&quot;Venn diagram of AudioTextual&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I want to use the term as a play on audiovisual to describe the state of such sound recordings. Like the Hughes recording, with both an instrumental, sound component as well as a linguistic one, audiotextual recordings exist in sound as well as in print. It’s a fairly simple idea, but I think it is one that often gets concerned as we discuss sound recordings. Literary sound recordings are not reducible to their relationship with a print text: they have both sounded &lt;em&gt;and&lt;/em&gt; print components. Audiobooks, in particular, not being “poetic” often seem to get left out of close listenings and treated as mere reproductions of print texts. If you read the reviews of any Amazon audiobook or &lt;a href=&quot;http://www.librivox.org&quot;&gt;LibriVox&lt;/a&gt; recording, you will see hundreds of people who expect an audiobook to be an unmediated, honest representation of the print origin. Audiotextual might be used equally to describe both Hughes’s literary sound recordings as well as Hughes’s poetry itself, saturated as it is with traces of the live performance techniques of jazz and blues musicians.&lt;/p&gt;

&lt;p&gt;More profoundly, I think sound recording during the modernist period is an especially good candidate for deformative acts of listening and interpretation. It is well-known and often-noted that modernist authors were obsessed with the gramophone, but consider the nature of such representations. The gramophones are most often marked by the materiality of their failures. In the “Hades” episode of &lt;em&gt;Ulysses&lt;/em&gt;, the machine disintegrates into parody at the very moment at which it is meant to revive the voice of a dead relative:  “After dinner on a Sunday. Put on poor old greatgrandfather Kraahraark! Hellohellohello amawfullyglad kraark awfullygladaseeagain hellohello amawf krpthsth” (114). Sound reproduction during the period was not marked by the high fidelity, by the ability to authentically reproduce a deceptively “real” recording of life. It is a flawed act marked, as in Joyce’s case, by skipping needles, locked grooves, and hissing machines. For Joyce, this means uncovering a renewed sense that sound recordings were imperfect things, themselves subject to deformation by their own young technology. Joyce thinks of the gramophone recording as an object that can reach back into the past. He does not play it backwards as such, but the very act of playing the voice reverses time itself. And it does so in a manner that deforms the recording, altering its shape and transmission as a natural and comical part of the playback process.&lt;/p&gt;

&lt;p&gt;Woolf’s failing gramophone in &lt;em&gt;Between the Acts&lt;/em&gt; draws the elements of my short talk together nicely and can act as a closing image. During the pageant play at the heart of the text, a malfunctioning gramophone provides musical and narrative accompaniment: “The gramophone gurgled Unity-Dispersity. It gurgled Un…dis…And ceased” (201). The words themselves break apart into component syllables; semantic meaning evaporates as the grain of language pushes to the surface, and the heard word gives way to the gurgling materiality of the record itself. Woolf makes us hear the sound of the words as bound with their meanings. Her gramophone falls into locked grooves throughout the novel, transfixing its listeners and forming a community out of the audience of listeners by expanding the time with which they engage with each other. Not reversing time, certainly, but she does meditate on the ability of a malfunctioning gramophone to create anew through performance and deformance.&lt;/p&gt;

&lt;p&gt;For Joyce and Woolf, the machines fail as often as they succeed. Deformance is thoroughly entwined with such performances. We may even go so far as to say that sound reproduction of this sort is a always kind of deformance, that no media form provides a pure, unaltered transmission of its content. As a critical practice, deformance, a systematic and intentionally disruptive form of engagement with materials, actually gets us closer to the kinds of media relationships that these authors would have known. The practice can offer us new perspective on literary and sonic materials, sure, but it can also provide us with something older. Deformative listening then, might be a practice of recovery, of attempting to recreate the phenomenological experience of a 1920s gramophone listening. The devil in the recording proves to be not the sort that conspiracy theorists would have you believe. The darkness lurking beneath sound recordings, be they musical or literary in nature, is the shadow of the materials, their very real failures, and the deformance that has always been present anytime we put needle to disc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Works Cited&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Albright, Daniel. &lt;em&gt;Untwisting the Serpent: Modernism in Music, Literature, and Other Arts&lt;/em&gt;. Chicago, Ill: University of Chicago Press, 2000. Print.&lt;/li&gt;
&lt;li&gt;Bernstein, Charles, ed. &lt;em&gt;Close Listening: Poetry and the Performed Word&lt;/em&gt;. Oxford University Press, USA, 1998. Print.&lt;/li&gt;
&lt;li&gt;Hughes, Langston, Leonard Feather, and Charles Mingus. &lt;em&gt;Weary Blues&lt;/em&gt;. MGM, 1959. CD.&lt;/li&gt;
&lt;li&gt;Joyce, James. &lt;em&gt;Ulysses&lt;/em&gt;. Vintage, 1990. Print.&lt;/li&gt;
&lt;li&gt;Pater, Walter. “&lt;a href=&quot;http://www.victorianweb.org/authors/pater/renaissance/7.html&quot;&gt;The School of Giorgione&lt;/a&gt;.” &lt;em&gt;The Renaissance: Studies in Art and Poetry&lt;/em&gt;. 1873. Web.&lt;/li&gt;
&lt;li&gt;Woolf, Virginia. &lt;em&gt;Between the Acts&lt;/em&gt;. New York: Harcourt Brace Jovanovich, 1969. Print.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Deformance</title>
   <link href="http://lanyon.getpoole.com/blog/2015/01/05/deformance/"/>
   <updated>2015-01-05T10:18:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2015/01/05/deformance</id>
   <content type="html">&lt;p&gt;[The following post is crosslisted on the &lt;a href=&quot;http://ach.org/&quot;&gt;ACH&lt;/a&gt;’s blog. The post details the methods used in putting together a talk for MLA 15 that takes place in 212 VCC West at 12:00 PM on Friday, January 9th.]&lt;/p&gt;

&lt;p&gt;My talk for the ACH’s panel at MLA 15 is entitled “The Devil in the Recording: Deformative Listening and Poetry.” I will be talking about the problems and affordances for deformance in the context of audio recordings, specifically those that have literary content. The particular method I will focus on is the reversal of audio recordings, taking my cue from the infamous claim that you can hear Satanic lyrics in Led Zeppelin’s “Stairway to Heaven” if you play the recording backwards. In the example below I will show how to reverse an audio file, and I will be working with Langston Hughes’s reading of “Motto” with Charles Mingus and Leonard Feather on his 1958 recording &lt;em&gt;Weary Blues&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Professional-grade sound-editing software like &lt;em&gt;&lt;a href=&quot;http://www.avid.com/us/products/family/pro-tools/&quot;&gt;Pro Tools&lt;/a&gt;&lt;/em&gt; or &lt;em&gt;&lt;a href=&quot;https://www.apple.com/logic-pro/&quot;&gt;Logic&lt;/a&gt;&lt;/em&gt; give you the capacity to do a lot in the way of sound mixing and work with music, but I often find myself drowning in their limitless options. They are also quite expensive. &lt;em&gt;&lt;a href=&quot;http://audacity.sourceforge.net/&quot;&gt;Audacity&lt;/a&gt;&lt;/em&gt; is my audio editing software of choice: the tool is open source and, most importantly, fairly intuitive and easy to use. Audacity is somewhat more limited than other options, but it does what it can cleanly and intuitively.&lt;/p&gt;

&lt;p&gt;To reverse an audio file, begin by opening that clip in &lt;em&gt;Audacity&lt;/em&gt; in the same way that you would open a file in any other piece of software. You will get something that looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/waveform.jpg&quot; width=&quot;40%&quot; class=&quot;right&quot; alt=&quot;Waveform&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What you see here is a &lt;a href=&quot;http://manual.audacityteam.org/o/man/audacity_waveform.html&quot;&gt;waveform&lt;/a&gt;, a way of graphically representing the audio file in way that allows you to manipulate it. The y-axis of the waveform corresponds to volume – the taller the waveform, the louder the sound file’s contents are at that particular moment in time. This can be a quick and easy way to identify chunks of activity by looking for spikes in the volume.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/axes.jpg&quot; alt=&quot;Waveforms in Audacity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The x-axis represents time – the Hughes file I have sliced out is 46” long, and the program gives you a timeline along the top of the segment to situate you in the file. Clicking anywhere on the waveform will set the file playback to begin at that point, and you can click and drag to highlight a selection of the clip for processing.&lt;/p&gt;

&lt;p&gt;To process the file, highlight the section that you want reversed. In this case, since we are working with the entire file, we will just select everything. Under the “effect” menu, &lt;em&gt;Audacity&lt;/em&gt; gives you a range of options for remixing your sound data, but we want the “reverse” function.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/reverse.jpg&quot; width=&quot;40%&quot; class=&quot;right&quot; alt=&quot;Audacity effects menu and reverse function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now you have a reversed file at your disposal. Sound tends to work in attack and decay, and much of the strangeness of a reversed recording comes from sounds increasing rather than fading in intensity over time. And, as I will discuss in my talk, the process throws into sharp relief the distinct character of recorded linguistic content.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Audacity&lt;/em&gt; saves files in &lt;em&gt;Audacity&lt;/em&gt; project formats by default, so you will need to export your file to a different file format if you want to play it in a media player. I tend to use both .ogg and .mp3 files for browser compatibility. &lt;em&gt;Audacity&lt;/em&gt; will also give you the opportunity to input light metadata for your file before it exports in case you want to curate your file for inclusion in an archive or home-library.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/export.jpg&quot; width=&quot;40%&quot; class=&quot;right&quot; alt=&quot;Exporting a file to a a format that you can play.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Audacity&lt;/em&gt; gives many other options for experimenting with sound remixing, distortion, and deformance that I would encourage you to explore. The software also gives you many options for working with sound files more generally. I have written &lt;a href=&quot;http://walshbr.github.io/blog/2013/11/13/audio-at-thatcampva/&quot;&gt;elsewhere&lt;/a&gt; about using Audacity to prepare sound files for research and presentation. Check out my other post if you want to learn more about how to slice out clips, mix together two sound files, or process DRM files.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Diss Talk Abstract</title>
   <link href="http://lanyon.getpoole.com/blog/2014/11/05/diss-talk-abstract/"/>
   <updated>2014-11-05T11:55:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2014/11/05/diss-talk-abstract</id>
   <content type="html">&lt;p&gt;On Friday, November 7th I will be giving a talk to the UVA English Department entitled “The Joycean Record: Listening Patterns and Sound Coteries.” The talk is a reworking of material from one of my dissertation chapters that I originally presented at last year’s &lt;em&gt;MLA&lt;/em&gt; meeting in Chicago.&lt;/p&gt;

&lt;p&gt;Abstract:&lt;/p&gt;

&lt;p&gt;Modernist authors famously gathered in a series of small coteries, intellectual clusters centered on the production and reception of their creations. Modernists frequently took to the microphone to record readings of their works as well, and the lives of such sound objects can offer us both new networks of modernist reception and distribution as well as a new conception of modernism’s engagement with sound technology based on lived practices. This talk places James Joyce alongside sociologies of record collecting and reception as a means of rethinking &lt;em&gt;Ulysses&lt;/em&gt;’s engagement with sound recording technology as an ongoing, lived, and social practice. Doing so uncovers a new history of &lt;em&gt;Ulysses&lt;/em&gt; as both participant in and subject of sound communities emerging during the twentieth century, as an object that coordinates networked sound production and reception. From Joyce’s network of friends and collaborators to the coterie that gathers around the production of the 2007 LibriVox recording of &lt;em&gt;Ulysses&lt;/em&gt;, I suggest that group listening enabled by sound recording has always been vital to the life of Joyce’s text.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Prism in the Classroom: Questions to Frame Discussion</title>
   <link href="http://lanyon.getpoole.com/blog/2014/09/16/prism-pedagogy/"/>
   <updated>2014-09-16T13:55:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2014/09/16/prism-pedagogy</id>
   <content type="html">&lt;p&gt;Crossposted on the &lt;a href=&quot;http://scholarslab.org/digital-humanities/prism-in-the-classroom-questions-to-frame-discussion/&quot;&gt;Scholars’ Lab blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I have been touting the use of &lt;a href=&quot;http://prism.scholarslab.org&quot;&gt;Prism&lt;/a&gt; in the university classroom for some time now, but a recent exchange with &lt;a href=&quot;http://annieswafford.wordpress.com/&quot;&gt;Annie Swafford&lt;/a&gt; suggested to me that it might be worth explicitly outlining how I would go about doing so. With that in mind, I’ve composed the following set of questions for how I might frame discussion of Prism in the classroom. I’ve admittedly only had very brief chances to implement the tool in the classroom myself, so the thoughts come largely out of speculation and conversation. It should be noted as well that I assume below that you have already chosen a text and categories along which it should be marked (I may write on ways to approach such choices at a later date). In what follows, I move from general questions that I think would be helpful in framing any discussion of the tool to a particular use-case in &lt;a href=&quot;http://prism.scholarslab.org/prisms/4213c156-aea5-11e2-80bf-c82a14fffe99/visualize?locale=en&quot;&gt;James Joyce’s A Portrait of the Artist as a Young Man&lt;/a&gt;. The former questions inform and engage my latter use-case.&lt;/p&gt;

&lt;p&gt;I prepare for class discussion by assembling a list of questions to be explored, and I would organize a Prism discussion around two lines of inquiry: tool-specific and visualization-specific. Some of these questions can be helpful for framing your own thoughts. Others could usefully be posed to the class as a whole as a means of framing discussion.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tool-Specific Questions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;How do the tool and our framing of it affect how we read the text? How is Prism’s mode of reading different from what we normally do? Is it the same that we’ve always been doing – close reading in a different form? What are the problems with the form? Can we really boil interpretation down to a series of numbers, visualize it, and move forward? Or is there more to interpretation than that? How do individual interpretations join in with the group reading? How much is the interpretive process encapsulated in the marking of a text? The visualization? The conversation that follows? How do the terms you choose for highlighting (the facets) guide the experience of reading the text? How do the explanations you provide for those terms affect the marking experience? When do the terms break down? If the terms propose a binary, what happens to that opposition over the course of the experience?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Visualization-Specific Questions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Which passages were marked the least for a particular category? The most? Why in either case? Which passages were particularly contentious, marked in many different ways? Where do particular categories cluster? How does the visualization show a relationship between the categories? How does your own interpretation link up to the collected visualization produced by the tool? Do the two visualizations tell us anything meaningful? Would we be able to find these meanings on our own? How does the visualization reflect the interpretive process? Why might we care more about a particular visualization for a particular reading? How is the quantified version of interpretation that Prism generates distinct from what we might learn from a discussion on our own? Can we imagine limits to this approach?&lt;/p&gt;

&lt;p&gt;The primary job of an instructor using Prism is to help the students connect the results of the tool to the larger discussions encapsulated by the marking categories. Look at the results with a skeptical eye and ask how they can be meaningfully related to the ideas and provocations of the marking categories. My favorite early use of Prism asked users to mark &lt;a href=&quot;http://prism.scholarslab.org/prisms/4213c156-aea5-11e2-80bf-c82a14fffe99/highlight?locale=en&quot;&gt;James Joyce’s A Portrait of the Artist&lt;/a&gt; as a Young Man along the categories of “modernism” and “realism.” In a class, I would intersperse observations based on the visualizations with a discussion of the passage and the two marking categories. What do we mean by modernism? By realism? How is each expressed at the level of the text? What do we mean by literary experiment? By fragment? By realist details? What different genres does the text move through? Does the text construct a coherent narrative?&lt;/p&gt;

&lt;p&gt;Putting realism and modernism alongside one another in Prism forces students to reconsider the binary, which quickly breaks down in practice. We can talk about whole novels or poems as belonging to one or another category, but can we do the same for individual sentences? For words? 80% of users at the time of this writing believe that the first word of the excerpt, “once,” is modernist. But why? If you look at &lt;a href=&quot;http://prism.scholarslab.org/prisms/4213c156-aea5-11e2-80bf-c82a14fffe99/visualize?locale=en&quot;&gt;the winning facet visualization&lt;/a&gt;, people seem primarily to be marking whole passages as one category – they are interpreting realism and modernism in chunks, not in terms of individual words. Readers tend to mark as modernist those generic changes where the excerpt suddenly adopts the form of nursery rhyme or of a fairy tale, suggesting that it is not any one genre but the shift between several in rapid succession that readers find to be modernist. The font size visualization suggests that those passages referencing physical actions by people are more likely to be associated with realist: “His father told him that story” and “When you wet the bed first it is warm then it gets cold” are marked as being especially realist. With this observation in hand, why these details? Why are the body and the bodily detail markers of a realism? Why might an association with the family suggest realism? How do they come under pressure in the face of aesthetic experiment?&lt;/p&gt;

&lt;p&gt;Obviously these suggestions are just beginnings for how to approach Prism in the classroom. Many other fascinating examples have already surfaced, particularly those that use the tool to teach basic reading and foreign language skills. Get in touch if you have used the tool in your classroom! I would love to hear how you did so.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Prism News - Heroku and LLC</title>
   <link href="http://lanyon.getpoole.com/blog/2014/08/20/prism-heroku/"/>
   <updated>2014-08-20T09:32:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2014/08/20/prism-heroku</id>
   <content type="html">&lt;p&gt;Crossposted on the &lt;a href=&quot;http://www.scholarslab.org/announcements/prism-news-heroku-and-llc/&quot;&gt;Scholars’ Lab blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This past year the Scholars’ Lab has implemented many performance upgrades and bug fixes for &lt;a href=&quot;http://prism.scholarslab.org&quot;&gt;Prism&lt;/a&gt;. The most recent upgrade is particularly exciting: users can now deploy their own personal Prism installations to Heroku with the click of a button. Well - it will take the click of a button and a few other commands. I’ve added a section detailing just how to do so under the “&lt;a href=&quot;https://github.com/scholarslab/prism#deploy-to-heroku&quot;&gt;Deploy to Heroku&lt;/a&gt;” section of the Prism Github readme.&lt;/p&gt;

&lt;p&gt;It was already possible to implement private user communities by marking uploaded prism games as “unlisted” and then distributing the links to your group of participants. The Heroku deploy function makes this process a bit easier by allowing to users to host all of their games in one place. The process also sets you up well to tinker with the Prism codebase using a live app, as Heroku provides instructions for cloning the app to your desktop.&lt;/p&gt;

&lt;p&gt;All of this on the heels of another exciting announcement: the Praxis Program has a short article on Prism appearing in the &lt;a href=&quot;http://llc.oxfordjournals.org/content/early/2014/07/08/llc.fqu030.full?keytype=ref&amp;amp;ijkey=4zaX5fIvQwiLhIJ&quot;&gt;Digital Humanities 2013 special conference issue of Literary and Linguistic Computing&lt;/a&gt;. In the piece, we summarize Prism’s and interventions into conversations on crowdsourcing with special reference to its user interface.&lt;/p&gt;

&lt;p&gt;It’s a good day to e-highlight!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Washington and Lee Trip</title>
   <link href="http://lanyon.getpoole.com/blog/2014/05/09/washingtonlee/"/>
   <updated>2014-05-09T10:31:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2014/05/09/washingtonlee</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Crossposted on the &lt;a href=&quot;http://www.scholarslab.org/uncategorized/washington-and-lee-trip/&quot;&gt;Scholars’ Lab blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Last week &lt;a href=&quot;http://www.scholarslab.org/people/sarah-storti/&quot;&gt;Sarah&lt;/a&gt; and I drove to Washington and Lee University as part of &lt;a href=&quot;https://columns.wlu.edu/wl-announces-digital-humanities-partnership-with-uva/&quot;&gt;a new collaboration&lt;/a&gt; enabled by a grant from the Associated Colleges of the South. As part of the endeavor, Scholars’ Lab fellows are guest teaching pieces of an Introduction to Digital Humanities course. Our task, in particular, was to co-teach for a day on the topics of project management and software development. While we each took part and taught in both conversations, Sarah took the lead on the former topic and I took the latter.&lt;/p&gt;

&lt;p&gt;I can’t rave enough about the experience enough, so I’ve organized my thoughts into three sections below.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Undergraduates + Digital Humanities = Dynamite&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I am endlessly delighted by the reactions of undergraduates when they get introduced to the digital humanities. In virtually every case, I have encountered students hungry to learn the material. The W&amp;amp;L students were no exceptions. We found students ready to learn, eager to participate, and wiling to ask hard questions about the affordances and limitations of the field. You can find reflections by the students on their &lt;a href=&quot;http://dhintro.academic.wlu.edu/&quot;&gt;course blog&lt;/a&gt;. What’s more, the Washington and Lee students stand poised to make real contributions to digital scholarship. They have worked up some really interesting projects on &lt;a href=&quot;http://beyondbowties.academic.wlu.edu/&quot;&gt;the history of coeducation at W&amp;amp;L&lt;/a&gt; and on &lt;a href=&quot;http://leechapel.academic.wlu.edu/&quot;&gt;the changing vision and reality for Robert E. Lee’s Chapel on the university grounds&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Co-Teaching&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Sarah and I work well together, and we have presented together in the past. But we had not taught together before the Washington and Lee trip. Full disclosure: I adore everything about co-teaching. It immediately disrupts the one-way transmission of information from the instructors to the students and forces the conversation to be more collaborative; co-teaching allows you to occupy simultaneously and more obviously the dual roles of student and teacher. It takes the pressure off any one person to keep the ship sailing smoothly, which empowers and enlivens the conversation. Co-teaching seems especially well-suited to the digital humanities, which value collaboration and play. Seminar discussions and workshops are different from working on teams to build projects, but co-instructors can make the experience a bit more lab-like, a bit more collaborative.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Teaching DH!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It is one thing to learn and practice digital humanities. It is another thing entirely to turn around and help others do the same. I have only really been hacking away for two years now, so I felt a bit unqualified to talk down software development as an invited speaker. I tend to assume that the Scholars’ Lab has a better sense of my own abilities than I do in most cases, though, and the invitation to W&amp;amp;L was no exception. The practice of putting together presentations on project management and software development was incredibly empowering. It helped me to have more confidence in myself as a digital humanist. No longer does the prospect of teaching an introduction to digital humanities course appear to be a vague and nebulous question mark. I now know that I could do it, because I have already done so in part. I also have a better sense of my own developing pedagogy of digital humanities. Opportunities to teach digital humanities like this, to perform with no net, are rare.&lt;/p&gt;

&lt;p&gt;You teach to learn, and this is as true in the digital humanities as it is anywhere else. I learned a great deal from the bright undergraduates at W&amp;amp;L.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MLA 2015 Abstracts</title>
   <link href="http://lanyon.getpoole.com/blog/2014/03/21/mla15/"/>
   <updated>2014-03-21T09:23:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2014/03/21/mla15</id>
   <content type="html">&lt;p&gt;It’s abstract time for next year’s big conference season. My two abstracts for MLA 2015 in Vancouver are below. This year I skewed digital humanities in a huge way: one paper would discuss digital collation and pedagogy, while the other would talk about listening practices and sound manipulation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Collation and Writing Pedagogy with Juxta Commons and Google Docs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This talk argues for digital collation tools as means of modeling revision in writing instruction. While collation tools are more typically used to examine already extant textual variants, they can also be used to model rhetorical possibilities in writing that is still in process. I suggest that tools like Juxta Commons and Google Docs, the former explicitly designed for collation and the latter more typically used for collaborative writing, can model a subjunctive mode of composition when used in congress with student writing. By allowing multiple possible versions of the same text to exist alongside and in relation to one another, they allow students to conceive of multiple realities at once, unhooking the quality of an idea from the manner of its presentation and allowing a student to think critically about both. The process allows students to abstract writing principles from revision rather than the other way around. It also allows students to distill editorial concepts by creating real-life editorial scenarios with their own writing as the subject.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Devil in the Recording: Deformative Listening and Poetry&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Modernists at the turn of the twentieth century were enamored of sound recording technology for the new possibilities that it offered for preserving their work, but they also obsessed over the materiality of the new media: skipping needles, record grooves, and the hiss of the recording. This talk examines the possibilities for listening to sound recordings of modernist works in ways newly enabled by digital technologies so as to reflect back on modernist engagement with sound and media. Lisa Samuels and Jerome McGann invoke Emily Dickinson’s suggestion of reading backwards line-by-line as a model for deformative reading. Retrograde constructions have been part of music theory treatises for centuries, and my work works in dialogue with these modes of thought to take the backwards turn a step further by listening to poetry recordings in reverse. Listening to recordings backwards alienates us from the semantic meanings of a text, but the process offers us a new sense of the recordings as sound objects, allows us to reconceive sonic and interpretive enmeshings, and enables us to hear anew the relationship between verse and music in song settings. Ultimately, I suggest that deformative listening practices offer heightened forms of close listening. Digital tools used will likely include Audacity and Sound Arguments, and I will discuss recordings of works by T.S. Eliot and Langston Hughes.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Teaching with Twitter - Part 2</title>
   <link href="http://lanyon.getpoole.com/blog/2014/01/13/twitter-2/"/>
   <updated>2014-01-13T16:07:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2014/01/13/twitter-2</id>
   <content type="html">&lt;p&gt;&lt;em&gt;This post is the second in a series reflecting on my experiments using Twitter in the classroom. Be sure to read the &lt;a href=&quot;/blog/2013/11/02/twitter-1/&quot;&gt;first&lt;/a&gt; post that began the discussion.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In my previous post, I described the process by which I went about integrating Twitter into my discussion section, but I offered few reasons for why instructors might want to do so. There are good pedagogical justifications for including social media, and it benefits interested instructors to give the move considered thought before integrating Twitter into course syllabi. I was prepared for students to push back against the idea of moving class conversation to Twitter, so I gave an opening pitch for the class activity containing several rationales for the experiment to my students. I encouraged students to think about Twitter as an exercise that would broaden their &lt;strong&gt;audience&lt;/strong&gt;, allow them to practice digital &lt;strong&gt;professionalization&lt;/strong&gt;, and challenge them to think small in their &lt;strong&gt;writing&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Audience&lt;/strong&gt;&lt;br /&gt;
In a typical course, students take in a lot of information from a variety of sources, but the primary audience for their ideas is limited to their instructor and fellow students. This trajectory—all input and no output—can leave the activities of the classroom feeling disconnected from the broader scholarly discussion. With Twitter, a student’s audience expands beyond the people in the room to include potential readers around the world. Student comments can be circulated wildly, and I bring in examples of class Twitter activities managed by colleagues at other universities as a way of illustrating this fact. Retweeting student comments that prove particularly insightful can be a good way of underscoring your commitment to this circulation and the quality of their thinking.&lt;/p&gt;

&lt;p&gt;The broad scholarly Twitter community is especially useful when discussing writing practices. Academics often tweet about writing, and a retweet towards your class of a professional writer discussing her own revision process can pay great dividends. Such self-reflective comments help students to see that writers of all stages struggle with the same problems, that writing is always a process - even for professionals. Outside tweets can also give your paper comments added traction by reinforcing them with the spontaneous thoughts of outside sources far removed from your own course.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Professionalization&lt;/strong&gt;&lt;br /&gt;
Students are often familiar with anecdotal evidence that employers regularly examine the social media accounts of potential employees, and framing Twitter in terms of this anxiety can further connect the course to the professional world. Students can fear the importance of their digital actions, or they can start managing their digital footprints now in ways that will benefit them in the future. The benefits of creating a professional digital presence have also been well documented: new networks and opportunities can be easily cultivated on Twitter that might be unavailable in real life, and some careers in professional writing and media outreach virtually require strong digital presences. I first came to Twitter in the interests of developing a professional persona, so I used my own experiences as a model for the benefits that can come from doing so. Framed in these terms, the class activity becomes training in a form of professionalization that will become a major part of the rest of students’ lives. By demonstrating intelligent and measured contributions in public for the purposes of the course, students can begin to take control over their digital personae.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Writing&lt;/strong&gt;&lt;br /&gt;
Twitter forces students to think small. The character limit on responses helps to moderate the size of student comments, keeping them to a relatively standardized length and preventing the sense that a longer response indicates a deeper engagement with the course materials. The format can also offer ongoing practice for students in developing concise, specific thoughts on objects of study. I encourage students to think about twitter comments as a challenge to write micro-essays. Entire, coherent arguments can be constructed in 140 characters, and they will often be clearer for the obscene demand for concision. 140 characters is a short length even for a thesis statement, and the exercise demands no space be wasted—every word must have its place. The genre of the micro-essay can allow conversations about writing into the course on a regular basis as students consistently produce a variety of these mini-thesis statements over the course of a statement.&lt;/p&gt;

&lt;p&gt;Stating your pedagogical motives for students up front encourages students to engage with Twitter in terms that align with your objectives for including the activity in the course in the first place. For more advice on creating professional digital presences in the context of a scholarly community, see Ryan Cordell’s wonderful ProfHacker post on &lt;a href=&quot;http://chronicle.com/blogs/profhacker/creating-and-maintaining-a-professional-presence-online-a-roundup-and-reflection/43030&quot;&gt;Creating and Maintaining a Professional Presence Online&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Audio at THATCampVA</title>
   <link href="http://lanyon.getpoole.com/blog/2013/11/13/audio-at-thatcampva/"/>
   <updated>2013-11-13T10:05:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/11/13/audio-at-thatcampva</id>
   <content type="html">&lt;p&gt;I took part in &lt;a href=&quot;http://virginia2013.thatcamp.org/&quot;&gt;THATCampVA&lt;/a&gt; this past weekend, where I led a session on using Audacity to mix and remix audio files for Digital Humanities projects. This was my session proposal, copied from &lt;a href=&quot;http://virginia2013.thatcamp.org/2013/10/24/audacity-and-audio-in-play-and-in-practice/&quot;&gt;the event’s main page&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;“A session on working and playing with audio files using Audacity, which has a fairly low barrier to entry for editing sound objects. Depending on interest and ability, we can take either a practical or a playful approach. I’m happy to walk people through some of its basic functions useful to DHers working with sound- how to slice out clips properly, deal with proprietary formats, repair audio clips, overlay tracks, etc. Or we can play around with some of audacity’s fun effects – phase shifting, echoes, pitch alterations, reversing sound waves – useful to more creative endeavors and creating sound art. I’m especially interested in how tinkering with sound artifacts might offer us new ways to interpret them. When does a sound object become something else-something new? We can work with any sound files that people may bring in, though I’ll bring in some samples to play with. The prize goes to the person who can process an otherwise human voice into the scariest thing we’ve ever heard.”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.google.com/a/virginia.edu/document/d/1m52vaXn7OaTIKUALypAsV-bTp9u0axPmcHNxSjurVTA/edit&quot;&gt;Here&lt;/a&gt; is the link to my (admittedly fairly schematic) talking notes for the event. The group wound up wanting the introduction to Audacity before we played with the files, so I showed the group how to slice out and mix together a few seconds of a Bach partita to crossfade into the last sentences of &lt;em&gt;Ulysses&lt;/em&gt;. Participants then tried their hand at remixing audio recordings based on their own interests, and a notable experiment took apart Orson Welles’s &lt;em&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=Xs0K4ApWl4g&quot;&gt;War of the Worlds&lt;/a&gt;&lt;/em&gt; broadcast. The group for the session was really great and gave helpful feedback on some ideas I had been kicking around for how to remix poetry readings for literary analysis. Very fun for my first THATcamp ever, and, in the future, I think I have a better idea of the kind of planning that goes into a good session!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Teaching with Twitter - Part One</title>
   <link href="http://lanyon.getpoole.com/blog/2013/11/02/twitter-1/"/>
   <updated>2013-11-02T12:54:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/11/02/twitter-1</id>
   <content type="html">&lt;p&gt;&lt;em&gt;This post begins a series reflecting on my experiments using Twitter in the classroom. Be sure to read the second post that continues the discussion.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I was only recently introduced to Twitter as a part of the &lt;a href=&quot;http://praxis.scholarslab.org/&quot;&gt;Praxis Program&lt;/a&gt;, which encourages its fellows to engage with the social media platform as part of their education in how to engage with the digital humanities. I have become fascinated with Twitter’s ability to generate discussion, facilitate connections, and expand my own sense of the conversation in the field. I wanted to bring all of these elements into my classroom and share them with my students, so this past semester I integrated class Twitter responses into the participation element of my syllabus. Students tweeted several times over the course of the semester rather than post email responses to a private course site. In this post, I offer suggestions for the logistics of setting up such a course requirement and recount my own, while later posts theorize the pedagogical implications of the move and offer suggestions for tweaking student participation.&lt;/p&gt;

&lt;p&gt;The Twitter requirement was not particularly onerous: I required students to tweet at a course hashtag (#ENRN_F or #ENRN_R) seven times over the course of the semester. Students would only be required to respond roughly every other week, so collectively these tweets would barely equal the length of a more typical paragraph response. I asked students to follow the tweets as they came in throughout the week, and I occasionally used the content of student tweets as quiz questions to encourage active engagement. Response tweets could take any form – a link to an image, a film clip from an adaption, a short quote, a thought on a particular character, a theme, etc. – anything that could advance the conversation.&lt;/p&gt;

&lt;p&gt;About half of the students in my courses had used Twitter before, so interested instructors should be prepared to explain the format and offer support for those who are unfamiliar with it. I encouraged students to use &lt;a href=&quot;http://tweetdeck.com/&quot;&gt;TweetDeck&lt;/a&gt; as a free and easy option for following the course hashtag, and we previewed the experience at the first course meeting by putting the app on the class overhead projector. A student tweeted to the hashtag in class at my request, allowing students to see just how instantaneous the class’s twitter engagement could be. I encouraged students to come by office hours during the first week if they wanted help setting up an account, but very few needed the assistance. The activity generated more anxiety up front than actual difficulty in practice.&lt;/p&gt;

&lt;p&gt;I taught two course sections of the same course when I implemented Twitter, so I considered using a shared hashtag for both classes. A single hashtag would allow cross-discussion conversation in ways that would not otherwise be possible. The increased activity that would come from two classes tweeting to the same place could provide a lively sense of community, even if some of those participants remain relative strangers in the context of the course. Separate hashtags make the actual logistics of teaching a bit more manageable: it is easier to lesson plan for the students that will actually be in the room and able to account for thoughts they have expressed online. I eventually opted for separate hashtags, but I encouraged students to follow and tweet at their sister section.&lt;/p&gt;

&lt;p&gt;Some students who already possessed Twitter accounts protected their tweets, but such gestures towards privacy would complicate the course setup: protected tweets would not show up on the course hashtag unless the student allowed every member of the class to follow them. Similarly, while I encouraged students to be excited about the opportunity to engage with a wider community through Twitter, some felt uncomfortable with their ideas exposed to the world. I gave these students the option of creating a new, dummy Twitter account specifically for the purposes of the course. Their name did not have to be associated with the account at all, so long as the rest of the class knew to whom the account belonged. I circulated a list of students’ twitter handles early on so that we could match names to e-identities. Twitter required students to meditate on the public nature of their own intellectual lives and the reach of their own voices, and dummy accounts respected the privacy of concerned students.&lt;/p&gt;

&lt;p&gt;In all, teaching with Twitter requires a relatively small amount of effort to implement, as the barrier to entry for students is quite low. But a little planning about your setup ahead of time goes a long way. For more helpful tips on the logistics of using Twitter in the classroom, check out Mark Sample’s ProfHacker post on “&lt;a href=&quot;http://chronicle.com/blogs/profhacker/practical-advice-for-teaching-with-twitter/26416&quot;&gt;Practical Advice for Teaching with Twitter&lt;/a&gt;.”&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stay tuned for part two in my series on Teaching with Twitter, where I further discuss pedagogical benefits and justifications for class Twitter accounts.&lt;/em&gt; &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The Tri-Wizard Paper Outline Challenge</title>
   <link href="http://lanyon.getpoole.com/blog/2013/10/21/wizard/"/>
   <updated>2013-10-21T10:19:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/10/21/wizard</id>
   <content type="html">&lt;p&gt;This teaching exercise grew directly out of a comment made by Kirk Wilkins in a recent &lt;a href=&quot;http://fycchat.blogspot.com/&quot;&gt;#FYCchat&lt;/a&gt; on how he uses Harry Potter to facilitate group work. I instantly fell in love with the idea, but the semester was a bit too far along to integrate a whole Harry Potter house system into the course. Instead, I developed a one-off group activity in the same spirit: The Tri-Wizard Paper Outline Challenge. Group work with a twist - I sorted the students into the houses from Harry Potter, as they competed for our own &lt;a href=&quot;http://harrypotter.wikia.com/wiki/Triwizard_Cup&quot;&gt;Tri-Wizard Cup&lt;/a&gt;, a literary mug filled with candy. “Let the magic of literature sweep you away to far-off lands!”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mug.jpg&quot; width=&quot;40%&quot; class=&quot;right&quot; alt=&quot;Mug with literary quotations on it.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Enough Harry Potter. On to the activity, which works perfectly fine without the magical theme.&lt;/p&gt;

&lt;p&gt;When teaching a discussion section of a large literature survey that only meets once a week, talking about writing presents a constant challenge. Students are evaluated on their ability to execute writing assignments, but there is little class time in which to develop these skills &lt;em&gt;and&lt;/em&gt; adequately address the literature. I have been working hard this semester to tie literary analysis consistently back to writing practices, and the Tri-Wizard Paper Outline Challenge attempts to do so by asking students to move from analysis to paper structuring in a very short timeframe. The exercise asks students to work in groups towards a possible paper outline in the course of a single class.&lt;/p&gt;

&lt;p&gt;Time Breakdown:&lt;br /&gt;
5-10 minutes to explain the activity and read the passages aloud.&lt;br /&gt;
30 minutes to work in groups&lt;br /&gt;
10 minutes to share, declare a winner, and discuss.&lt;/p&gt;

&lt;p&gt;Split the class into four equal groups, each of which has the same small set of passages and the same paper prompt. In the time allowed, each group must develop a paper outline: a thesis statement and three supporting points that will draw upon close readings of the passages. At the end of 30 minutes, students nominate one student from their group to read their thesis and describe the structure of their group’s proposed paper outline. The instructor then gives very quick feedback on each group’s work and selects a “winner” - the outline most likely to lead a successfully executive argument.&lt;/p&gt;

&lt;p&gt;The exercise works best if things are kept as constrained as possible: common passages and a common paper prompt. The activity encourages aggressive time management, and too many options will likely detract from the students’ ability to complete the exercise. I am currently teaching a course on &lt;a href=&quot;/pedagogy#ENRN3210&quot;&gt;Shakespeare’s Histories and Comedies&lt;/a&gt;, so my passages all drew from a very small portion of Act I Scene I of &lt;em&gt;Merchant of Venice&lt;/em&gt;&lt;img src=&quot;/assets/images/MOV.jpg&quot; width=&quot;60%&quot; class=&quot;left&quot; alt=&quot;Merchant of Venice prompts&quot; /&gt;. For a prompt I asked that students develop a paper broadly related to friendship, sexuality, marriage, or desire in some way. I chose passages that offer up opportunities for analysis and clear readings: the selections I chose had a strong homoerotic subtext, and several of the student groups picked up on this.&lt;/p&gt;

&lt;p&gt;The whole activity is quite frantic in 50 minutes, but it can still work well, so long as you help the students keep a close watch on the time. Ideally, it would be a 75-minute activity, allowing more time for reflection at the end and discussion. I chose to err on the side of not giving enough for follow up discussion of the event: I generally give a short email follow up to each class meeting, so I used this e-space to share more thoughts on why we did the activity and what to take away from it. I would recommend doing the same, even if this is not your usual practice.&lt;/p&gt;

&lt;p&gt;The exercise works especially well when conducted after students have already received feedback on written work and in dialogue with those paper comments. Written feedback from the instructor is essential to a student’s growth, but the ultimate aim is for students to internalize the critical attention so that they can revise their writing on their own. To facilitate this while framing the activity, speak in terms they recognize from your feedback on their papers when discussing how you will judge the final products. I required the theses to be written out because we had stressed the importance of a well-articulated thesis statement with specific language in earlier discussions. I encouraged students to consider alternative paper structures, to consider whether their work was an observation or an argument, and to ask whether their argument was fundamentally interesting or based on plot summary. Many of the group discussions took on aspects of these questions as they shaped their papers.&lt;/p&gt;

&lt;p&gt;Teaching detachment from one’s own writing can be very difficult. Some things just need to be cut, but we often feel personally invested in the words we put on the page. The Tri-Wizard Paper Outline Challenge also allows students to shape a paper outline in which they have little investment. The activity has no grade repercussions beyond participation, allowing students to shape ideas in a collaborative space that models the benefits for developing such detachment. Students have nothing to lose but candy, but what they stand to gain from hearing their peers and themselves speak in the language of good, critical writing - magical.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Writing Out Loud: Google Docs for Live Writing, Revision, and Discussion</title>
   <link href="http://lanyon.getpoole.com/blog/2013/09/25/writing-out-loud/"/>
   <updated>2013-09-25T09:45:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/09/25/writing-out-loud</id>
   <content type="html">&lt;p&gt;I have been using Google Docs as a part of my teaching for almost two years now. The idea first came about in an advanced course on Academic and Professional Writing. We talked a lot about editing in the class, and many of the conversations about style took this shape:&lt;/p&gt;

&lt;p&gt;Student A: “Something about this word feels strange, but I don’t know what it is.” &lt;br /&gt;
Student B: “What if we moved the phrase to the beginning of the sentence?”&lt;br /&gt;
Student C: “We could get rid of that word and use this phrase instead.”&lt;/p&gt;

&lt;p&gt;Hard to wrap your head around, right? Just imagine if those conversations were spoken. &lt;em&gt;Talking&lt;/em&gt; about writing can only get you so far: writing is graphic, after all. As I write and edit, I try out different options on the page. I model possibilities, but I do so &lt;em&gt;in&lt;/em&gt; writing. Discussing the editing process without visual representations of suggested changes can make things too abstract to be meaningful for students. I developed an exercise that I call “Writing Out Loud” that more closely mirrors my actual editing process. Using a Google Doc as a collaborative writing space, students are able to model alternate revisions visually and in real time for discussion.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/WOL_settings.jpg&quot; width=&quot;60%&quot; class=&quot;right&quot; alt=&quot;Set Google docs settings to publicly editable&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The setup requires a projector-equipped classroom and that students bring their laptops to class. Circulate the link to the Google Doc ahead of time, taking care that anyone with the link can edit the document.&lt;/p&gt;

&lt;p&gt;The template of the Google Doc consists of a blank space at the top for displaying the sentence under question and a series of workspaces for each student consisting of their name and a few blank lines. Separate workspaces prevent overlapping revisions, and they also minimize the disorienting effects of having multiple people writing on the same document.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/WOL_template.jpg&quot; width=&quot;60%&quot; class=&quot;left&quot; alt=&quot;Blank writing out loud template with spaces for each student to type.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We usually turn to the exercise when a student feels a particular sentence is not working but cannot articulate why. When this happens, put the Writing Out Loud template on the projector with the original version of the sentence at the top. Using their own laptops, students sign onto the Doc and type out alternative versions of the sentence, and the multiple possible revisions show up on the overhead for everyone to see and discuss. After each student rewrites the sentence to be something that they feel works better, ask for volunteers to explain how the changes affect meaning. The whole process only takes a few minutes, and it allows you to abstract writing principles from the actual process of revision rather that the other way around. How does the structure of a sentence matter? How can word choice change everything? What pieces of a sentence are repetitive?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/WOL_filled.jpg&quot; width=&quot;60%&quot; class=&quot;right&quot; alt=&quot;Examples of the same sentence written a number of different ways.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Obviously Writing Out Loud works better on micro-edits, revisions at the level of the sentence. The standard process of the exercise—write, collate, and discuss—would take far too long with anything longer than a few lines. The exercise can be particularly useful for those sentences that carry a lot of importance for entire arguments: thesis statements, topic sentences, the first sentences of the document, etc.&lt;/p&gt;

&lt;p&gt;I find that students often think of editing as an intense, sweeping process that involves wholesale transformation from the ground up. Modeling multiple, slightly different versions of the same sentence can allow for a more concrete discussion of the sweeping rhetorical changes that even the smallest edits can make.&lt;/p&gt;

&lt;p&gt;You can find a copy of the template &lt;a href=&quot;https://docs.google.com/document/d/1Dk2GpCqvm6o3K-dbfUazekHbiSlqwJeIoE2OZ-OjL00/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Rails Girls Digital Humanities</title>
   <link href="http://lanyon.getpoole.com/blog/2013/09/08/railsgirls/"/>
   <updated>2013-09-08T00:00:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/09/08/railsgirls</id>
   <content type="html">&lt;p&gt;This past weekend I coached at &lt;a href=&quot;http://railsgirls.com/digitalhumanities_fairfax&quot;&gt;Rails Girls Digital Humanities&lt;/a&gt; at the &lt;a href=&quot;http://chnm.gmu.edu/&quot;&gt;Roy Rosenzweig Center for History and New Media&lt;/a&gt;. The event was amazing, the women were inspiring, and the tacos were delicious. It was just wonderful to take a first attempt at teaching Ruby on Rails in a community that was so supportive and welcoming! I learned a lot about teaching from the day. Here are a few thoughts on the experience and on how I would be a better coach in the future.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deep Technical Problems&lt;/strong&gt;&lt;br /&gt;
At my table we ran into a couple problems where Rails refused to play nicely with the version of Windows a student was running. After working on the problem for a while, it became clear that I wasn’t going to be able to solve the issue in the time allotted. I eventually lent the student my laptop so that she could keep learning and building during the course of the afternoon. Of course, this is only a temporary fix, as the Rails issues would come up again when the student got home and tried to continue working. Is the tradeoff worth it? Or did I just delay the frustration until she was home? In the future it might help to have a designated Rails installation expert hanging around that wasn’t coaching to help troubleshoot tech problems like these that show up later, after the installation party is over.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Syntax&lt;/strong&gt;&lt;br /&gt;
Syntax errors often posed the biggest teaching challenge for me. What do you do when you see that the problem is in the syntax before the student does? Suggesting to a student that the issue is with the syntax gave me the feeling that I was withholding information from her, which I can only imagine felt irritating. But I don’t think jumping in to point out mistakes is any good for long-term skill building either. Fellow coach &lt;a href=&quot;http://anglophileinacademia.blogspot.com/&quot;&gt;Annie Swafford&lt;/a&gt; suggested that I use moments like these to teach the process by which I would find a syntax error, and I could definitely do a better job of this in the future. In the context of following a tutorial like the Rails Girls guides, this would mean a few steps. First, I double-check each line meticulously with one finger on my code and another on the tutorial. Second, I read the offending code backwards bit by bit to get my mind away from thinking about the lines semantically, which often tricks you into overlooking things. As a last resort, I copy and paste the tutorial code over top of my own. If nothing changes, I know there is no syntax error and that I need to look elsewhere. Finally, I search online for answers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Frustration&lt;/strong&gt;&lt;br /&gt;
It’s important to learn that we &lt;em&gt;all&lt;/em&gt; break things. Constantly. I tried to stress again and again that I spend far more time breaking and fixing than I do actually building things that function properly. In the future I might even bring copies of some of my own commit messages (&lt;a href=&quot;https://github.com/scholarslab/prism/commit/8fba94b904219d42b5d270660d04a4bef69ed034&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;https://github.com/scholarslab/prism/commit/bfae5eca226dfc8cbbee86f6acbfe63ec0c8c07f&quot;&gt;2&lt;/a&gt;, &lt;a href=&quot;https://github.com/scholarslab/prism/commit/1fbba70b3577d093430426f7b4ee34752aa5c64c&quot;&gt;3&lt;/a&gt;, &lt;a href=&quot;https://github.com/scholarslab/prism/commit/be0a319c44d6d2b3f894168cc26044ff42642c2e&quot;&gt;4&lt;/a&gt;, &lt;a href=&quot;https://github.com/scholarslab/prism/commit/0af47e4d214f1c994714223f93c11801975f09d0&quot;&gt;5&lt;/a&gt;) to illustrate the point and get some laughs. This feeling of helplessness, obviously, can be incredibly frustrating. Rails Girls DH made me wonder: how much frustration is pedagogically useful? How can we teach frustration in such a way that it doesn’t cause students to shut down? One of the hardest parts of coaching was learning to balance my instinct to help with the need to allow people to struggle. The women did an &lt;em&gt;amazing&lt;/em&gt; job working through and learning from issues that popped up, but I wonder if I was doing the best job possible to facilitate their learning. As a coach, do you jump in the moment someone’s face expresses annoyance? Or, do you wait for them to reach out to you? I think at times I was too willing to read facial expressions and jump in to help, possibly out of a feeling that I wasn’t doing enough. Students should learn to feel confident and independent in their tech abilities, and they will only develop these traits by dealing with and pushing through their own frustrations. They should feel that they can ask for help, but they should also learn when they can handle something on their own. In general, I think the women I worked with were better at knowing when to ask for help than I was at knowing when to offer it.&lt;/p&gt;

&lt;p&gt;So, if I were coaching again, I would do the following differently:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Bring an extra laptop.&lt;/li&gt;
  &lt;li&gt;Learn more about the Rails installation process and known issues with different operating systems ahead of time so that I am better equipped to troubleshoot such things.&lt;/li&gt;
  &lt;li&gt;Talk more about processes: of troubleshooting, of asking for and finding help, and even of conceptualizing new projects.&lt;/li&gt;
  &lt;li&gt;Strike a more satisfying balance between jumping in and letting students explore independently.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I’m already looking forward to the next Rails Girls DH event!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Bash-it Plugins</title>
   <link href="http://lanyon.getpoole.com/blog/2013/08/11/bash-it-plugins-and-symlink-troubles/"/>
   <updated>2013-08-11T16:41:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/08/11/bash-it-plugins-and-symlink-troubles</id>
   <content type="html">&lt;p&gt;Sometimes things go wrong. When this happens, I often find a temporary solution that works fine in the moment, but implementing the fix repeatedly can get annoying over time. Here is something that I had been ignoring for a while and only recently took the time to fix.&lt;/p&gt;

&lt;p&gt;I use &lt;a href=&quot;https://github.com/revans/bash-it&quot;&gt;bash-it&lt;/a&gt;, which has lots of neat tricks and functions. Since installing it, however, I had been getting a message every time I open up a terminal window:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sorry, the z plugin is incompatible with the fasd plugin. you may use either, but not both.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The message doesn’t stop you from going about your business, so I never really read it very closely: bash-it tells you everything you need to know. When installing, bash-it prompts you to make a variety of decisions about how many plugins you will use on a regular basis. I told bash-it to enable everything by default, but this decision caused a conflict between two plugins.&lt;/p&gt;

&lt;p&gt;To see which plugins you have enabled, open a terminal window and type:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ bash-it show plugins&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In the output, you should see some flavor of the following diagnosing the problem:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;z [x]     maintains a jump-list of the directories you actually use  
z is DEPRECATED, use fasd instead&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Plugin z causes an error when activated with a newer plugin with the same functionality. Bash-it gives you the fix:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ bash-it disable plugin z&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After that, your terminal should run free of the message.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>TextMate and Git</title>
   <link href="http://lanyon.getpoole.com/blog/2013/08/03/textmate/"/>
   <updated>2013-08-03T10:45:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/08/03/textmate</id>
   <content type="html">&lt;p&gt;This one is for my own files as much as anything else. For some time now, I’ve been getting a persistent error in Git when I try to go through the steps of committing a file online. This particular error came about when trying to pull before pushing up to GitHub:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/bin/mate -w: /usr/bin/mate: No such file or directory
error: There was a problem with the editor '/usr/bin/mate -w'.
Not committing merge; use 'git commit' to complete the merge.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;From what I understand, this comes about because Git can’t find the symbolic link to TextMate, even though it has existed in the past. For whatever reason, this issue seems to come up from time to time on my machine. I’ve tried a number of different solutions online, but none seemed to take.
&lt;a href=&quot;http://stackoverflow.com/questions/9610884/cant-create-a-symbolic-link-with-textmate-in-terminal-mate-command-not-found&quot;&gt;This&lt;/a&gt; solution finally did it for me. First, of course, make sure that you have TextMate installed and updated (my first mistake). The solution:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ln -s /Applications/TextMate.app/Contents/SharedSupport/Support/bin/mate /usr/local/bin/mate&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This very post was made free of the error.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>SelfControl for Working on the Web</title>
   <link href="http://lanyon.getpoole.com/blog/2013/07/28/working-web/"/>
   <updated>2013-07-28T20:53:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/07/28/working-web</id>
   <content type="html">&lt;p&gt;The web enables virtually all of my work as a graduate student, but it can all too easily become a powerful distraction. Sometimes it helps to have a few practical aids in the war against procrastination. Of the several tools that I’ve tried - &lt;a href=&quot;https://addons.mozilla.org/en-us/firefox/addon/foxfilter/&quot;&gt;Fox Filter&lt;/a&gt;, &lt;a href=&quot;https://chrome.google.com/webstore/detail/stayfocusd/laankejkbhbdhmipfmgcngdelahlfoji?hl=en&quot;&gt;StayFocused&lt;/a&gt;, and &lt;a href=&quot;http://macfreedom.com/&quot;&gt;Freedom&lt;/a&gt; - &lt;a href=&quot;http://selfcontrolapp.com/&quot;&gt;SelfControl&lt;/a&gt; remains my favorite. SelfControl provides relentless self-regulating freedom from procrastination. Best of all, it is free.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Self_Control_1.jpg&quot; width=&quot;60%&quot; class=&quot;left&quot; alt=&quot;Self control interface&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SelfControl is an app for Mac OS X that, unlike FoxFilter or StayFocused, works across browsers. When enabled, SelfControl asks you to specify how long you want to block a list of domains, up to 24 hours. The app also sports a “Whitelist” function that works in reverse, disabling everything except for a handful of specified domains.&lt;/p&gt;

&lt;p&gt;Once activated, the blocks remain live until a particularly menacing timer runs down, and only some minor computer hacking will allow you to disable the app’s functionality. This relentlessness is SelfControl’s best and worst feature. The timed function is particularly good for short bursts of productivity, ie. an hour or shorter, but disabling the web for any longer feels too risky: it is easy to imagine time-sensitive emails going unanswered because you have blocked access to the internet for the next five hours.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Self_Control_2.jpg&quot; class=&quot;right&quot; alt=&quot;Self control timer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At its best, SelfControl allows me to temper the impulse to spend a lot of time hovering around my inbox; I tend to use SelfControl in hour long chunks to allow sessions of distraction-free work in between e-mail checks. How do you stay productive during long hours on the computer?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Praxis Posts</title>
   <link href="http://lanyon.getpoole.com/blog/2013/07/23/praxis/"/>
   <updated>2013-07-23T21:19:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/07/23/praxis</id>
   <content type="html">&lt;p&gt;All last year I was a &lt;a href=&quot;http://praxis.scholarslab.org/&quot;&gt;Praxis Fellow&lt;/a&gt; in the &lt;a href=&quot;http://www.scholarslab.org/&quot;&gt;Scholars’ Lab&lt;/a&gt;, where they gave us a “soup to nuts” crash course in all things digital humanities. As a part of the program, the fellows were asked to reflect periodically on their experiences on the Scholars’ Lab blog.&lt;/p&gt;

&lt;p&gt;I did not do a good job of continually cross-posting those blog posts to this site, so I wanted to make sure that they were properly linked here. I posted with the program on a variety of topics from my work as a developer, to reflections on collaborative programming, to our own plan for the year. Many of the posts relate to &lt;a href=&quot;http://www.prism.scholarslab.org&quot;&gt;Prism&lt;/a&gt;, the tool we built over the course of the year. The Scholars’ Lab has &lt;a href=&quot;http://www.scholarslab.org/people/brandon-walsh/&quot;&gt;a list of all my posts to date&lt;/a&gt;. Below I included the posts with a short gloss.&lt;/p&gt;
&lt;ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/hello-world/&quot;&gt;Hello World&lt;/a&gt;: I reflect on how our team would interact with the previous year's Praxis team.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/failure/&quot;&gt;Failure&lt;/a&gt;: On the importance of failing in public and my first stab at creating a personal website.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/marking-and-explanation-in-prism-2/&quot;&gt;Marking and Explanation in Prism&lt;/a&gt;: Thoughts on the marking interface in Prism and its implications for the interpretive process.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/the-direction-of-prism/&quot;&gt;The Direction of Prism&lt;/a&gt;: Attempts to reflect broadly on how particular types of changes to the project might affect its direction.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/prism-proposal-against-anonymity/&quot;&gt;Prism Proposal: Against Anonymity&lt;/a&gt;: An argument for the redesign of Prism to track individual users in relation to the total dataset.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/poster-abstract-and-code-camp/&quot;&gt;Poster Abstract and Code Camp&lt;/a&gt;: Discusses our DH2013 poster abstract and first reflections on learning code.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/your-digital-life-in-140-characters/&quot;&gt;Your Digital Life in 140 Characters&lt;/a&gt;: I discuss my first foray into Twitter.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/fizzing-buzzing/&quot;&gt;Fizzing, Buzzing&lt;/a&gt;: Links my solution to the Fizz Buzz programming homework.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/grading-in-ruby/&quot;&gt;Grading in Ruby&lt;/a&gt;: I develop a very basic program that will compute your end of semester grading for you.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/ruby-grading-2-0/&quot;&gt;Ruby Grading 2.0&lt;/a&gt;: I attempt to redesign the same grading program to have cleaner, more elegant code.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/looking-forward/&quot;&gt;Looking Forward&lt;/a&gt;: Possible directions for the project.  &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/on-learning-code/&quot;&gt;On Learning Code&lt;/a&gt;: Discusses the online tools that I found most helpful for learning coding.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/omniauth/&quot;&gt;Omniauth&lt;/a&gt;: On implementing Omniauth for Prism.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/out-on-a-small-limb/&quot;&gt;Out on a (Small) Limb&lt;/a&gt;: Discusses the importance of small feature branches when working collaboratively.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/grad-student-research/on-tasks-large-and-small/&quot;&gt;On Tasks Large and Small&lt;/a&gt;: On realistic expectations and identifying problems.&lt;/li&gt;  
&lt;li&gt;&lt;a href=&quot;http://www.scholarslab.org/experimental-humanities/arduino-rainbow-hack/&quot;&gt;Arduino Rainbow Hack&lt;/a&gt;: Reflects on an Arduino hackday held in the Scholars' Lab.&lt;/li&gt;
&lt;/ul&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Search Bar</title>
   <link href="http://lanyon.getpoole.com/blog/2013/07/10/search-bar/"/>
   <updated>2013-07-10T19:41:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/07/10/search-bar</id>
   <content type="html">&lt;p&gt;After some tweaking, I managed to get the search bar to play nicely. I unrounded the corners and lightened the borders to match the framing lines elsewhere in the navigation bar. Here is the CSS for it. You’ll want to give it an id selector of your own, a la #searchform.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/walshbr/5968989&quot;&gt;Here&lt;/a&gt; is the CSS for the changes to the search bar.&lt;/p&gt;

&lt;p&gt;In trying to embed the above gist, I noticed that octopress breaks the styling: &lt;img alt=&quot;broken gist image on octopress&quot; src=&quot;/assets/images/Broken_Gist.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now I have something else to work on.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Design Refresh</title>
   <link href="http://lanyon.getpoole.com/blog/2013/07/08/design/"/>
   <updated>2013-07-08T00:39:00-04:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/07/08/design</id>
   <content type="html">&lt;p&gt;At long last, I am ready to unveil the project that I have been working on over the summer - a design refresh for site. The main drive behind this aesthetic: I noticed the sheer abundance of information that the basic octopress theme gives you. This setup leads to a lot of duplicate information that ultimately makes things feel cluttered. I tried to keep things very minimal in this design, eliminating as much overlapping information and noise as possible.&lt;/p&gt;

&lt;p&gt;I used a few different models for the design of the site. The main inspirations came from the sites of &lt;a href=&quot;http://aijazansari.com/&quot;&gt;Aijaz Ansari&lt;/a&gt;, &lt;a href=&quot;http://clioweb.org/&quot;&gt;Jeremy Boggs&lt;/a&gt;, and &lt;a href=&quot;http://inletters.com/&quot;&gt;Daniel Carter&lt;/a&gt;. Ansari’s &lt;a href=&quot;http://aijazansari.com/2012/08/27/how-to-customize-octopress-theme/&quot;&gt;blog post&lt;/a&gt; on customizing Octopress, especially, proved essential as I worked through my own setup. There are still a few things that I could stand to change for this current design, but it felt as thought it was time to let the current iteration see the light of day.&lt;/p&gt;

&lt;p&gt;A couple issues I ran into:&lt;/p&gt;

&lt;p&gt;How minimal is too minimal in an aesthetic like this? I am not crazy about the search bar in the navigation setup, but it does feel necessary to have one. The function there outweighed the desire to keep the aesthetic. In a future refresh, I will probably try to make the search bar a bit more subtle. In addition, at one point I had my links only turn blue when hovered. This looks great, but it presents obvious problems: you never know what is a link. Again, I had to make some sacrifices for the site to function properly.&lt;/p&gt;

&lt;p&gt;How to deal with images in a minimal aesthetic? I initially wanted to have some sort of a banner image at the top where my name serves as a heading. I might explore this in the future, but images offer whole new complications. What kind of image texture would keep the aesthetic alive? Content? Color? I punted the issue for now by opting for my name as the banner, but I will be returning to this in the future.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Looking Forward</title>
   <link href="http://lanyon.getpoole.com/blog/2013/02/01/looking-forward/"/>
   <updated>2013-02-01T18:25:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/02/01/looking-forward</id>
   <content type="html">&lt;p&gt;Cross posted on the &lt;a href=&quot;http://www.scholarslab.org/praxis-program/looking-forward/&quot;&gt;Scholars’ Lab blog.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As we move into the second half of our tenure on the &lt;a href=&quot;http://praxis.scholarslab.org/&quot;&gt;Praxis squad&lt;/a&gt;, we are feeling the pressure to start actually making something. To that end, the &lt;a href=&quot;http://www.scholarslab.org/&quot;&gt;SLab&lt;/a&gt; crew asked us to make a list of our priorities for &lt;a href=&quot;http://prism.scholarslab.org/&quot;&gt;Prism&lt;/a&gt;. Hopefully this will help us make a to do list in the coming weeks. The following was the list that seemed to come out of yesterday’s meeting, though it’s possible that other people could have gotten different impressions from the conversation.&lt;/p&gt;

&lt;p&gt;These seem to be our priorities, in no particular order except roughly that in which they were brought up:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Types of texts&lt;/strong&gt; – we’re interested in opening up the Prism framework to deal with pictures, music, etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Getting a crowd&lt;/strong&gt; – we want to get a large group of people working with Prism, however that might be arranged.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Visualizations&lt;/strong&gt; – we’re interested in expanding Prism’s visualizations to allow you to see the individual set of markings in relation to the crowd and to let you see one marking category’s visualization beside another.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;User uploads&lt;/strong&gt; – we want to make it possible for users/instructors to upload a text for marking themselves, which we see as essential for classroom use.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Complicating the sense of how we highlight&lt;/strong&gt; – there has been discussion of complicating how the marking system works, allowing for a limit to the number of markings or a type of marking economy that is distributed across your selections to encourage different types of engagement with the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Design makeover&lt;/strong&gt; – we want to remake the design of the site with an eye to usability.&lt;/p&gt;

&lt;p&gt;I think my own priorities lie in making it possible for users to upload their own texts for marking and in possibly adding more visualizations. If forced to choose between the two, I would spend the time on making the tool capable of handling user uploads. As quickly became clear, any one of these goals spins off into dozens of other questions. What do we mean by “upload a text”? Will those texts be public? Private? How will we navigate copyright and fair use? In the coming days we’re aiming to get a sense of our collective ordering of the list.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Teaching</title>
   <link href="http://lanyon.getpoole.com/blog/2013/01/25/teaching/"/>
   <updated>2013-01-25T17:26:00-05:00</updated>
   <id>http://lanyon.getpoole.com/blog/2013/01/25/teaching</id>
   <content type="html">&lt;p&gt;After some Git problems were sorted out and explained to me by the staff of the &lt;a href=&quot;http://www.scholarslab.org/&quot;&gt;Scholars’ Lab&lt;/a&gt;, I can make updates to the site again. I have added some content to the &lt;a href=&quot;/pedagogy&quot;&gt;Pedagogy&lt;/a&gt; page: the syllabus for my current writing course among other goodies. Enjoy!&lt;/p&gt;
</content>
 </entry>
 

</feed>
