
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <a href="Top"></a>
  <meta charset="utf-8">
  <title>Brandon Walsh</title>
  <meta name="author" content="Brandon Walsh">

  
  <meta name="description" content="[Crossposted on the Washington and Lee University Digital Humanities Blog] Last Monday several of us here at WLUDH traveled down to Duke University &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://walshbr.com/blog/page/3/">
<!--   <link href="/favicon.png" rel="icon">
 -->  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Brandon Walsh" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37226549-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
	<div id="headtext">
	  <h1><a href="/">Brandon Walsh</a></h1>
	  
	</div>
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:walshbr.com" />
    <input class="search" id="searchform" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about">About</a></li>
  <li><a href="/blog/archives">Archive</a></li>
  <li><a href="/cv/index.html">CV</a></li>
  <li><a href="/teaching">Courses</a></li>
  <li><a href="/research">Research</a></li>
  <li><a href="/digital-projects">Digital Projects</a></li>
</ul>
</nav>
  <div id="main">
    <div id="content">
      <div>
<article role="article">
  
  <div class="blog-index">
  
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2016/02/29/apps-maps-models/">Apps, Maps, & Models: A New View</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2016-02-29T08:54:00-05:00" pubdate data-updated="true">Feb 29<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>[Crossposted on the <a href="http://digitalhumanities.wlu.edu/blog/2016/02/29/1937/">Washington and Lee University Digital Humanities Blog</a>]</em></p>

<p>Last Monday several of us here at WLUDH traveled down to Duke University for their symposium on <a href="http://sites.duke.edu/digsymposium/">Apps, Maps &amp; Models: Digital Pedagogy in Art History, Archaeology &amp; Visual Studies</a>. I found the trip to be enlightening and invigorating. If you are interested in the event, you can find videos of the talks <a href="http://nasher.capture.duke.edu/Panopto/Pages/Viewer.aspx?id=e6b77d46-cad9-442e-981c-473389e8ee15">here</a> and <a href="http://nasher.capture.duke.edu/Panopto/Pages/Viewer.aspx?id=057a7ebb-7406-4d08-94d9-d4cab1e7c753">here</a> as well as a storify of the Twitter action <a href="https://storify.com/dukewired/dah2016">here</a>. That the event was so well documented is a testimony to how well organized it was by the <a href="http://www.dukewired.org/why-wired/">Wired! Lab</a>.</p>

<p>Many speakers at the event considered how the tools they were using might relate to more “traditional” modes for carrying out their research. They considered and responded to tough questions with and about their work. Are digital methods for tracing the topography of a surface, for example, fundamentally different in kind from analog means of doing so? If so, are they meant to displace those old tools? Why should we spend the time to learn the new technologies? A related question that comes up at almost every digital humanities presentation (though not at any of these): can digital humanities methods show us anything that we do not already know?</p>

<p>Such questions can be particularly troubling when we are investing such time and energy on the work they directly critique, but we nonetheless need to have answers for them that demonstrate the value of digital humanities work, in and out of the classroom. Numerous well-known scholars have offered justifications of digital work in a variety of venues, and, to my mind, the symposium offered many answers of its own, in part by showcasing amazing work that spanned a variety of fields related to preservation, public humanities, and academic scholarship. Presenters were using digital technology to rebuild the past, using digital modeling to <a href="https://www.apollo-magazine.com/virtual-florence-a-church-goes-digital/">piece together the fragments of a ruined church that have since been incorporated into other structures</a>. They were using these tools to engage the present, <a href="https://aahvs.duke.edu/articles/medieval-color-comes-light">to draw the attention of museum patrons to overlooked artifacts</a>. The work on display at the symposium struck me, at its core, as engaging with questions and values that cut across disciplines, digital or otherwise.</p>

<p>Most compelling to me, the symposium drew attention to how the tools we use to examine the objects of our study change our relationship to them. The presenters acknowledged that such an idea does hold dangers – after all, we want museum-goers to consider the objects in a collection, not just spend time perusing an iPad application meant to enrich them. But just as new tools offer new complications, changes in medium also offer changes in perspective. As was illustrated repeatedly at the symposium, drone photography, for all its deeply problematic political and personal valences, can offer you a new way of seeing the world, a new way of looking that is more comprehensive than the one we see from the ground. Even as we hold new methodologies and tools up to critique we can still consider how they might cause us to consider an object, a project, or a classroom differently.</p>

<p>Seeing from a different angle allows us to ask new questions and re-evaluate old ones, an idea that speaks directly to my experience at the symposium. I work at the intersections of digital humanities, literary studies, and sound studies. So my participation in the symposium was as something of an outsider, someone ready to learn about an adjacent and overlapping field but, ultimately, not a home discipline. Thinking through my work from an outsider perspective made me want to ask many questions of my own work. The presenters here were deeply engaged in preserving and increasing access to the cultural record. How might I do the same through text analysis or through my work with audio artifacts? What questions and goals are common to all academic disciplines? How might I more thoroughly engage students in public humanities work?</p>

<p>Obviously, the event left me with more questions than answers, but I think that is ultimately the sign of a successful symposium. I would encourage you to check out the videos of the conference, as this short note is necessarily reductive of such a productive event. The talks will offer you new thoughts on old questions and new ways of thinking about digital scholarship no matter your discipline.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2016/02/15/coins-from-zotero/">Embedding COinS Metadata on a Page Using the Zotero API</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2016-02-15T09:33:00-05:00" pubdate data-updated="true">Feb 15<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>[Crossposted on the <a href="http://digitalhumanities.wlu.edu/blog/2016/02/15/embedding-coins-data-on-a-page-using-the-zotero-api/">Washington and Lee University Digital Humanities Blog</a>]</em></p>

<p>This year I am working with Mackenzie, Steve McCormick, and his students on the <a href="http://www.huondauvergne.org/">Huon d’Auvergne</a> project, a digital edition of a Franco-Italian romance epic. Last term we finished TEI-encoding of two of the manuscripts and put them online, and there is still much left to do. Making the digital editions of each manuscript online is a valuable scholarly endeavor in its own right, but we’ve also been spending a lot of time considering other ways in which we can enrich this scholarly production using the digital environment.</p>

<p>All of which brings me to the <a href="http://www.huondauvergne.org/bibliography.html">bibliography</a> for our site. At first, our bibliography page was just a transcription of a text file that Steve would send along with regular updates. This collection of materials is great to have in its own right, but a better solution would be to leverage the many digital humanities approaches to citation management to produce something a bit more dynamic.</p>

<p>Steve already had everything in a Zotero, so my first step was to integrate the site’s bibliography with the Zotero collection that Steve was using to populate the list. I found a <a href="https://github.com/davidswelt/zot_bib_web">python 2 library called zot_bib_web</a> that could do all this quite nicely with a bit of modification. Now, by running the script from my computer, the site’s bibliography will automatically pull in an updated Zotero collection for the project. Not only is it now easier to update our site (no more copying and pasting from a word document), but now others can contribute new resources to the same bibliography on Zotero by requesting to join the group and uploading citations. The project’s bibliography can continue to grow beyond us, and we will capture these additions as well.</p>

<p>Mackenzie suggested that we take things a bit further by including <a href="https://en.wikipedia.org/wiki/COinS">COiNS</a> metadata in the bibliography so that someone coming to our bibliography could export our information into the citation manager of their choosing. Zotero’s API can also do this, and I used a piece of the <a href="https://github.com/urschrei/pyzotero">pyzotero</a> Python library to do so. The first step was to add this piece to the zot_bib_web code:</p>

<p>zot = zotero.Zotero(library_id, library_type, api_key)
  coins = zot.collection_items(collection_id, content=’coins’)
  coin_strings = [str(coin) for coin in coins]
  for coin in coin_strings:
    fullhtml += coin</p>

<p>Now, before the program outputs html for the bibliography, it goes out to the Zotero API and gets COinS metadata for all the citations, converts them into a format that will work for the embedding, and then attaches each returned span to the HTML for the bibliography.</p>

<p>Now that I had the data that I needed, I wanted to make it work a bit more cleanly in our workflow. Initially, the program returned each bibliographic entry in its own page and meant for the whole bibliography to also be a stand-alone page on the website. I got rid of all that and, instead, wanted to embed them within the website as I already had it. I have the python program exporting the bibliography and COinS data into a small HTML file that I then attach to a div with an id of “includedContent”. inserted in the bibliography page. I use some jQuery to do so:</p>

<pre><code>$(function(){
  $("#includedContent").load("/zotero-bib.html");
});
</code></pre>

<p>Instead of distributing content across several different pages, I mark a placeholder area on the main site where all the bibliographic data and metadata will be dumped. All of the relevant data gets saved in a file ‘zot-bib.html’ that gets automatically included inside the shell of the bibliography.html page. From there, I just modified the style so that it would fit into the aesthetic of the site.</p>

<p>Now anyone going to our bibliography page with a Zotero extension will see this in the right of the address bar:</p>

<p><img src="/images/zotero-extension.jpg" /></p>

<p>Clicking on the folder icon will bring up the Zotero interface for downloading any of the items in our collection.</p>

<p><img src="/images/zotero-download.jpg" /></p>

<p>And to update this information we only need to run a single python script from the terminal to re-generate everything.</p>

<p>The code is not live on the Huon site just yet, but you can download and manipulate these pieces from an example file I uploaded to the <a href="https://github.com/wludh/huondauvergne/blob/zotero/zot_bib_web/zot_example.py">Huon GitHub repository</a>. You’ll probably want to start by installing zot_bib_web first to familiarize yourself with the configuration, and you’ll have a few settings to update before it will work for you: the library id, library type, api key, and collection ID will all need to be updated for your particular case, and the jQuery excerpt above will need to point to wherever you output the bibliography file.</p>

<p>These steps have strengthened the way in which we handle bibliographic metadata so that it can be more useful for everyone, and we were really only able to do it because of the many great open source libraries that allow others to build on them. It’s a great thing - not having to reinvent the wheel.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/12/04/dh-mentoring/">Reflections on a Year of DH Mentoring</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-12-04T09:13:00-05:00" pubdate data-updated="true">Dec 4<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>[Crossposted on the <a href="http://scholarslab.org/digital-humanities/reflections-on-a-year-of-dh-mentoring/">Scholars’ Lab blog</a> and the <a href="http://digitalhumanities.wlu.edu/blog/2015/12/03/reflections-on-a-year-of-dh-mentoring/">Digital Humanities at Washington and Lee blog</a>]</em></p>

<p>This year I am working with <a href="http://scholarslab.org/people/eric-rochester/">Eric Rochester</a> in the <a href="http://scholarslab.org/">Scholars’ Lab</a> on a fellowship project that has me learning natural language processing (NLP), the application of computational methods to human languages. We’re adapting these techniques to study quotation marks in the novels of Virginia Woolf (read more about the project <a href="http://scholarslab.org/digital-humanities/virginia-woolf-natural-language-processing-and-the-quotation-mark/">here</a>). We actually started several months before this academic year began, and, as we close out another semester, I have been spending time thinking about just what has made it such an effective learning experience for me. I already had a technical background from my time in the Scholars’ Lab at the beginning of the process, but I had no experience with Python or NLP. Now I feel most comfortable with the former of any other programming language and familiar enough with the latter to experiment with it in my own work.</p>

<p>The general mode of proceeding has been this: depending on schedules and deadlines, we meet once or twice every two weeks. Between our meetings I would work as far and as much as I could, and the sessions would offer a space for Eric and me to talk about what I had done. The following are a handful of things we have done that, I think, have helped to create such an effective environment for learning new technical skills. Though they are particular to this study, I think they can be usefully extrapolated to apply to many other project-based courses of study in digital humanities. They are primarily written from the perspective of a student but with an eye to how and why the methods Eric used proved so effective for me.</p>

<p><strong>Let the Wheel Be Reinvented Before Sharing Shortcuts</strong></p>

<p>I came to Eric with a very small program adapted from Matt Jockers’s book on Text Analysis with R for Students of Literature that did little beyond count quotation marks and give some basic statistics. I was learning as I built the thing, so I was unaware that I was reinventing the wheel in many cases, rebuilding many protocols for dealing with commonly recognized problems that come from working with natural language. After working on my program and my approach to a degree of satisfaction, Eric pulled back the curtain to reveal that a commonly used python module, the Natural Language ToolKit <a href="http://www.nltk.org/">(NLTK)</a>, could address many of my issues and more. NLTK came as something of a revelation, and working inductively in this way gave me a great sense of the underlying problems the tools could address. By inventing my own way to read in a text, clean it to make its text uniformly readable by the computer, and breaking the whole piece into a series of words that could be analyzed, I understood the magic behind a couple lines of NLTK code that could do all that for me. The experience also helped me to recognize ways in which we would have to adapt NLTK for our own purposes as I worked through the book.</p>

<p><strong>Have a Plan, but Be Flexible</strong></p>

<p>After discussing NLTK and how it offered an easier way of doing the things that I wanted, Eric had me systematically work through the <a href="http://www.nltk.org/book/">NLTK book</a> for a few months. Our meetings took on the character of an independent study: the book set the syllabus, and I went through the first seven chapters at my own pace. Working from a book gave our meetings structure, but we were careful not to hew too closely to the material. Not all chapters were relevant to the project, and we cut sections of the book accordingly. We shaped the course of study to the intellectual questions rather than the other way around.</p>

<p><strong>Move from Theory to Practice / Textbook to Project</strong></p>

<p>As I worked through the book, I was able to recognize certain sections that felt most relevant to the Woolf work. Once I felt as though I had reached a critical mass, we switched from the book to the project itself and started working. I tend to learn from doing best, so the shift from theory to execution was a natural one. The quick and satisfying transition helped the work to feel productive right away: I was applying my new skills as I was still learning to feel comfortable with them. Where the initial months had more the feel of a traditional student-teacher interaction, the project-based approach we took up at this point felt more like a real and true collaboration. Eric and I would develop to-do items together, we would work alongside each other, and we would talk over the project together.</p>

<p><strong>Document Everything</strong></p>

<p>Between our meetings I would work as far and as much as I could, carefully noting places at which I encountered problems. In some cases, these were conceptual problems that needed clarifying, and these larger questions frequently found their way into separate notes. But my questions were frequently about what a particular line of code, a particular command or function, might be doing. In that case, I made comments directly in the code describing my confusion. I quickly found that these notes were as much for me as for Eric–I needed to get back in the frame of mind that led to the confusion in the first place, and copious notes helped remind me what the problem was. These notes offered a point of departure for our meetings: we always had a place to start, and we did so based on the work that I had done.</p>

<p><strong>Communicate in as Many Ways as Possible</strong></p>

<p>We met in person as much as possible, but we also used a variety of other platforms to keep things moving. Eric and I had all of our code on <a href="https://github.com/erochest/woolf">GitHub</a> so that we could share everything that we had each been working on and discuss things from a distance if necessary. Email, obviously, can do a lot, but I found the chat capabilities of the Scholars’ Lab’s IRC channel to be far better for this sort of work. If I hit a particular snag that would only require a couple minutes for Eric to answer, we could quickly work things out through a web chat. With Skype and Google Hangouts we could even share the code on the other person’s computer even from hundreds of miles away. All of these things meant that we could keep working around whatever life events happened to call us away.</p>

<p><strong>Recognize Spinning Wheels</strong></p>

<p>These multiple avenues of communication are especially important when teaching technical skills. Not all questions or problems are the same: students can work through some on their own, but others can take them days to troubleshoot. Some amount of frustration is a necessary part of learning, and I do think it’s necessary that students learn to confront technical problems on their own. But not all frustration is pedagogically productive. There comes a point when you have tried a dozen potential solutions and you feel as though you have hit a wall. An extra set of eyes can (and should) help. Eric and I talked constantly about how to recognize when it was time for me to ask for help, and low-impact channels of communication like IRC could allow him to give me quick fixes to what, to me at least, seemed like impossible problems. Software development is a collaborative process, and asking for help is an important skill for humanists to develop.</p>

<p><strong>In-person Meetings Can Take Many Forms</strong></p>

<p>When we met, Eric and I did a lot of different things. First, we would talk through my questions from the previous week. If I felt a particular section of code was clunky or poorly done, he would talk and walk me through rewriting the same piece in a more elegant form. We would often pair program, where Eric would write code while I watched, carefully stopping him each time I had a question about something he was doing. And we often took time to reflect on where the collaboration was going - what my end goal was as well as what my tasks before the next meeting would be. Any project has many pieces that could be dealt with at any time, and Eric was careful to give me solo tasks that he felt I could handle on my own, reserving more difficult tasks for times in which we would be able to work together. All of this is to say that any single hour we spent together was very different from the last. We constantly reinvented what the meetings looked like, which kept them fresh and pedagogically effective.</p>

<p>This is my best attempt to recreate my experience of working in such a close mentoring relationship with Eric. Obviously, the collaboration relies on an extremely low student-to-teacher ratio: I can imagine this same approach working very well for a handful of students, but this work required a lot of individual attention that would be hard to sustain for larger classes. One idea for scaling the process up might be to divide a course into groups, being training one, and then have students later in the process begin to mentor those who are just beginning. Doing so would preserve what I see as the main advantage of this approach: it helps to collapse the hierarchy between student and teacher and engage both in a common project. Learning takes place, but it does so in the context of common effort. I’d have to think more about how this mentorship model could be adapted to fit different scenarios. The work with Eric is ongoing, but it’s already been one of the most valuable learning experiences I have had.</p>

</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/09/20/music-genre-and-spotify-metadata/">Music Genre and Spotify Metadata</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-09-20T16:51:00-04:00" pubdate data-updated="true">Sep 20<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em><a href="http://scholarslab.org/?p=12173">Crossposted on the Scholars’ Lab blog</a></em></p>

<p>For the last couple weeks, I have been exploring APIs useful to sound studies for a sound recording and poetry project I am working on with former Scholars’ Lab fellow <a href="https://annieswafford.wordpress.com/">Annie Swafford</a>. I was especially drawn to playing around with <a href="https://www.spotify.com/us/">Spotify</a>, which has an <a href="https://developer.spotify.com/web-api/">API</a> that allows you to access metadata for the large catalog of music available through their service. The experiment described below focuses on genre: a notoriously messy category that we nonetheless rely on to tell us how to process the materials we read, view, or hear. Genre tells us what to expect from the art we take in, and our construction and reception of generic categories can tell us a lot about ourselves. In music, especially, genres and subgenres can activate fierce debates about authenticity and belonging. Does your favorite group qualify as “authentic” jazz? What composers do you have to know in order to think of yourself as a real classical music aficionado? Playing with an artist’s metadata can expose a lot of the assumptions that were made in its collection, and I was especially interested in the ways in which Spotify models relations among artists.</p>

<p>I wanted to explore Spotify’s metadata in a way that would model the interpretive messiness of generic categories. To do so, I built a program that bounces through Spotify’s metadata to produce multiple readings of the idea of genre in relation to a particular artist. Spotify offers a fairly robust API, and there are a number of handy wrappers that make it easier to work with. I used a Python module called <a href="http://spotipy.readthedocs.org/en/latest/">Spotipy</a> for the material below, and you can find <a href="https://github.com/bmw9t/spotify/blob/master/genre_machine.py">the code for my little genre experiment over on my GitHub page</a>. If you do try to run this on your own machine, note that you will need to clone Spotipy’s repository and manually install it from the terminal with the following command from within the downloaded repository:</p>

<pre><code>$ python setup.py install
</code></pre>

<p>Pip will install an older distribution of the code that will only run in Python 2, but Spotipy’s GitHub page has a more recent release that is compatible with Python 3.</p>

<p>When run, the program outputs what I like to think of as the equivalent of music nerds arguing over musical genres. You provide an artist name and a number, and the terminal will work through Spotify’s API to produce the specified number of individual “mappings” of that artist’s genre as well as an aggregate list of all their associated genres. The program starts by pulling out all the genre categories associated with the given artist as well as those given to artists that Spotify flags as related. Once finished, the program picks one of those related artists at random and continues to do the same until the process returns no new genre categories, building up a list of associated genres over time.</p>

<p>So, in short, you give the program an artist and it offers you a few attempts at describing that artist generically using Spotify’s catalog, the computational equivalent of instigating an argument about genre in your local record store. Here are the results for running the program three times for the band New Order:</p>

<pre><code>Individual genre maps

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'new romantic', 'new wave pop', 'hi nrg', 'europop', 'power pop', 'album rock']

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'gothic metal', 'j-metal', 'visual kei', 'intelligent dance music', 'uk post-punk', 'metropopolis', 'ambient', 'big beat', 'electronic', 'illbient', 'piano rock', 'trance', 'progressive house', 'progressive trance', 'uplifting trance', 'quebecois', 'deep uplifting trance', 'garage rock', 'neo-psychedelic', 'space rock', 'japanese psychedelic']

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'uk post-punk', 'gothic rock', 'discofox', 'madchester', 'britpop', 'latin', 'latin pop', 'teen pop', 'classic colombian pop', 'rai', 'pop rap', 'southern hip hop', 'trap music', 'deep rai']

Aggregate genre map for New Order:

['dance rock', 'new wave', 'permanent wave', 'new romantic', 'new wave pop', 'hi nrg', 'europop', 'power pop', 'album rock', 'gothic metal', 'j-metal', 'visual kei', 'intelligent dance music', 'uk post-punk', 'metropopolis', 'ambient', 'big beat', 'electronic', 'illbient', 'piano rock', 'trance', 'progressive house', 'progressive trance', 'uplifting trance', 'quebecois', 'deep uplifting trance', 'garage rock', 'neo-psychedelic', 'space rock', 'japanese psychedelic', 'gothic rock', 'discofox', 'madchester', 'britpop', 'latin', 'latin pop', 'teen pop', 'classic colombian pop', 'rai', 'pop rap', 'southern hip hop', 'trap music', 'deep rai']
</code></pre>

<p>In each case, the genre maps all begin the same, with the categories directly assigned to the source artist. Because the process is slightly random, the program eventually maps the same artist’s genre differently each time. For each iteration, the program runs until twenty randomly selected related artists return no new genre categories, which I take to be a kind of threshold of completion for one understanding of an artist’s genre.</p>

<p>The results suggest an amalgam of generic influence, shared characteristics, common lineages, and overlapping angles of approach. The decisions I made in how the program interacts with Spotify’s metadata suggest a definition of genre like the one offered by Alastair Fowler: “Representatives of a genre may then be regarded as making up a family whose septs and individual members are related in various ways, without necessarily having any single feature shared in common by all” (41). Genre is fluid and a matter of interpretive opinion - it is not necessarily based on objective links. The program reflects this in its results: sometimes a particular generic mapping feels very coherent, while at other times the script finds its way to very bizarre tangents. The connections do exist in the metadata if you drill down deeply enough, and it is possible to reproduce the links that brought about such output. But the more leaps the program takes from the original artist the more tenuous the connections appear to be. As I wrote this sentence, the program suggested a connection between garage rock revivalists The Strokes and big band jazz music: such output looks less like a conversation among music nerds and more like the material for a Ph.D. dissertation. As the program illustrates, generic description is the beginning of interpretation - not the ending.</p>

<p>Of course, the program does not actually search all music ever: it only has access to the metadata for artists listed in Spotify, and some artists like Prince or the Beatles are notoriously missing from the catalog. Major figures like these have artist pages that serve as stubs for content drawn largely from compilation CDs, and the program can successfully crawl through these results. But this wrinkle points to a larger fact: the results the program produces are as skewed as the collection of musicians in the service’s catalog. Many of the errors I had to troubleshoot were related to the uneven nature of the catalog: early versions of the script were thrown into disarray when Spotify listed no related artists for a musician. On occasion, the API suggested a related artist who did not actually have an artist page in the system (often the case with new or less-established musicians). I massaged these gaps to make this particular exercise work (you’ll now get a tongue in cheek “Musical dead end” or “Artist deleted from Spotify” output for them), but the silences in the archive offer significant reminders of the commercial politics that go into generic and archival formation, particularly when an archive is proprietary. I can imagine tweaking things slightly to create a script that produces only those archival gaps, but that is work for another day. In the meantime, I’ll be trying to figure out <a href="https://en.wikipedia.org/wiki/Yeezus">how Kanye West might be considered Christmas music</a>.</p>

<p>Works Cited:</p>

<p>Fowler, Alastair David Shaw. Kinds of Literature: An Introduction to the Theory of Genres and Modes. Repr. Oxford: Clarendon Press, 1997. Print.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/09/10/woolf-and-the-quotation-mark/">Virginia Woolf, Natural Language Processing, and the Quotation Mark</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-09-10T11:21:00-04:00" pubdate data-updated="true">Sep 10<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Crossposted on the <a href="http://scholarslab.org/?p=12117/">Scholars’ Lab blog</a></em></p>

<p>For my fellowship in the Scholars’ Lab this year I’ll be working with <a href="http://scholarslab.org/people/eric-rochester/">Eric</a> to expand a project we began last year on Virginia Woolf and natural language processing. My dissertation focuses on sound recordings and modernism, and this year I will focus on how Woolf’s quotation marks offer evidence of her engagement with sound as a textual device. In my reading, the quotation mark is the most obvious point at which sound meets text, the most heavily used sound recording technology in use by writers. Patterns in quotation mark usage across large corpora can tell us a lot about the role that sound plays in literature, but, as you might expect, there are <em>lots</em> of quotation marks - hundreds or thousands in any given text. Computational methods can help us make sense of the vast number and turn them into reasonable objects of study.</p>

<p>You can find more information in <a href="http://scholarslab.org/digital-humanities/hearing-silent-woolf/">this post</a> about my thinking on quotation marks and some preliminary results from thinking about them in relation to Woolf. As I discuss there, finding quotation marks in a text is not especially challenging, but this year Eric and I will be focusing on a particular wrinkle in Woolf’s use of the marks, best conveyed in <em>The Hours</em>, Michael Cunningham’s late-century riff on Virginia Woolf. In <em>The Hours</em>, Cunningham offers a fictionalized version of Woolf meditating on her composition process:</p>

<blockquote>
  <p>She passes a couple, a man and woman younger than herself, walking together, leisurely, bent towards each other in the soft lemon-colored glow of a streetlamp, talking (she hears the man, “told me <em>something something something</em> in this establishment, <em>something something</em>, harrumph, indeed”) (166).</p>
</blockquote>

<p>The repeated “<em>somethings</em>” of the passage suggest the character’s imperfect experience of the conversation as well as the limits of her senses. As the moment is conveyed through the character’s perspective, the conversation will always be incomplete. Recording technology was largely unreliable during the early days of the twentieth century, and, similarly, the sound record of this conversation as given by the text is already degraded before we hear it. Cunningham points to how the sounded voice is given character in the ears of the listener, and, in a print context, in the pen of the writer. A printed voice can speak in a variety of ways and in a variety of modes.</p>

<p>Cunningham’s passage contains echoes of what will eventually be the famous first sentence of Woolf’s <em>Mrs. Dalloway</em>: “Mrs. Dalloway said she would buy the flowers herself.” The text implies that Mrs. Dalloway speaks, but it does not mark it as such: the same conversational tone in Cunningham remains here, but the narrator does not differentiate sound event from narrative by using quotation marks. We see moments of indirect speech like this all the time, when discourse becomes submerged in the texture of the narrative, but it doesn’t disappear entirely. Speech implies a lot: social relations, the thoughts of a speaking body, among others. Things get muddy when the line between narrative voice and speech becomes unclear. If quotation marks imply a different level of speech than unquoted speech, might they also imply changes in the social relations they represent?</p>

<p><em>Mrs. Dalloway</em> is filled with moments like these, and this year I’ll be working to find ways to float them to the surface of the text. Examining these moments can tell us how conversation changes during the period, what people are talking about and for, how we conceive of the limits of print and sound, and about changing priorities in literary aesthetics. The goal this year is to train the computer to identify moments like this, moments that a human reader would be able to parse as spoken but that are not marked as such. Our first pass will be to work with the quoted material, which we can easily identify to build a series of trigger words that Woolf uses to flag speech as sound (said, asked, called, etc.). With this lexicon, we can then look for instances in her corpus where they pop up without punctuation. Teaching the computer to classify these passages correctly will be a big task, and this process alone will offer me lots of new material to work with as I untangle the relationship between modernist print and sound. In upcoming posts I’ll talk more about the process of learning natural language processing and about some preliminary results and problems. Stay tuned!</p>

<p>Works Cited:</p>

<p>Cunningham, Michael. <em>The Hours</em>. New York: Picador USA : Distributed by Holtzbrinck Publishers, 2002. Print.</p>

<p>Woolf, Virginia. <em>Mrs. Dalloway</em>. 1st Harvest/HBJ ed. San Diego: Harcourt Brace Jovanovich, 1990. Print.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/4/">&larr; Older</a>
     
     <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/2/">Newer &rarr;</a>
    
  </div>
</div>
  
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    
  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  <a rel="license" href="http://creativecommons.org/licenses/by/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/3.0/80x15.png" /></a><br />This work is by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Brandon Walsh</span> unless otherwise noted and is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/3.0/deed.en_US">Creative Commons Attribution 3.0 Unported License</a>.
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a>.</span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'bmw9t';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'https://walshbr.com/blog/page/3/index.html';
        var disqus_url = 'https://walshbr.com/blog/page/3/index.html';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'https://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
