
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <a href="Top"></a>
  <meta charset="utf-8">
  <title>Brandon Walsh</title>
  <meta name="author" content="Brandon Walsh">

  
  <meta name="description" content="[Crossposted on the Washington and Lee University Digital Humanities Blog] This year I am working with Mackenzie, Steve McCormick, and his students &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://bmw9t.github.com/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Brandon Walsh" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37226549-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
	<div id="headtext">
	  <h1><a href="/">Brandon Walsh</a></h1>
	  
	  
	</div>
</hgroup>

</header>
  <nav role="navigation"><!-- <ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul> -->
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:bmw9t.github.com" />
    <input class="search" id="searchform" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about">About</a></li>
  <li><a href="/blog/archives">Blog Archive</a></li>
  <li><a href="/cv/index.html">CV</a></li>
  <li><a href="/teaching">Courses</a></li>
  <li><a href="/research">Research</a></li>
</ul>
</nav>
  <div id="main">
    <div id="content">
      <div>
<article role="article">
  
  <div class="blog-index">
  
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2016/02/15/coins-from-zotero/">Embedding COinS Metadata on a Page Using the Zotero API</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2016-02-15T09:33:00-05:00" pubdate data-updated="true">Feb 15<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>[Crossposted on the <a href="http://digitalhumanities.wlu.edu/blog/2016/02/15/embedding-coins-data-on-a-page-using-the-zotero-api/">Washington and Lee University Digital Humanities Blog</a>]</em></p>

<p>This year I am working with Mackenzie, Steve McCormick, and his students on the <a href="http://www.huondauvergne.org/">Huon d&#8217;Auvergne</a> project, a digital edition of a Franco-Italian romance epic. Last term we finished TEI-encoding of two of the manuscripts and put them online, and there is still much left to do. Making the digital editions of each manuscript online is a valuable scholarly endeavor in its own right, but we&#8217;ve also been spending a lot of time considering other ways in which we can enrich this scholarly production using the digital environment.</p>

<p>All of which brings me to the <a href="http://www.huondauvergne.org/bibliography.html">bibliography</a> for our site. At first, our bibliography page was just a transcription of a text file that Steve would send along with regular updates. This collection of materials is great to have in its own right, but a better solution would be to leverage the many digital humanities approaches to citation management to produce something a bit more dynamic.</p>

<p>Steve already had everything in a Zotero, so my first step was to integrate the site&#8217;s bibliography with the Zotero collection that Steve was using to populate the list. I found a <a href="https://github.com/davidswelt/zot_bib_web">python 2 library called zot_bib_web</a> that could do all this quite nicely with a bit of modification. Now, by running the script from my computer, the site&#8217;s bibliography will automatically pull in an updated Zotero collection for the project. Not only is it now easier to update our site (no more copying and pasting from a word document), but now others can contribute new resources to the same bibliography on Zotero by requesting to join the group and uploading citations. The project&#8217;s bibliography can continue to grow beyond us, and we will capture these additions as well.</p>

<p>Mackenzie suggested that we take things a bit further by including <a href="https://en.wikipedia.org/wiki/COinS">COiNS</a> metadata in the bibliography so that someone coming to our bibliography could export our information into the citation manager of their choosing. Zotero&#8217;s API can also do this, and I used a piece of the <a href="https://github.com/urschrei/pyzotero">pyzotero</a> Python library to do so. The first step was to add this piece to the zot_bib_web code:</p>

<p>  zot = zotero.Zotero(library_id, library_type, api_key)
  coins = zot.collection_items(collection_id, content=&#8217;coins&#8217;)
  coin_strings = [str(coin) for coin in coins]
  for coin in coin_strings:</p>

<pre><code>fullhtml += coin
</code></pre>

<p>Now, before the program outputs html for the bibliography, it goes out to the Zotero API and gets COinS metadata for all the citations, converts them into a format that will work for the embedding, and then attaches each returned span to the HTML for the bibliography.</p>

<p>Now that I had the data that I needed, I wanted to make it work a bit more cleanly in our workflow. Initially, the program returned each bibliographic entry in its own page and meant for the whole bibliography to also be a stand-alone page on the website. I got rid of all that and, instead, wanted to embed them within the website as I already had it. I have the python program exporting the bibliography and COinS data into a small HTML file that I then attach to a div with an id of &#8220;includedContent&#8221;. inserted in the bibliography page. I use some jQuery to do so:</p>

<p>  <script type="text/javascript"></p>

<pre><code>$(function(){
  $("#includedContent").load("/zotero-bib.html");
});
</code></pre>

<p>  </script></p>

<p>Instead of distributing content across several different pages, I mark a placeholder area on the main site where all the bibliographic data and metadata will be dumped. All of the relevant data gets saved in a file &#8216;zot-bib.html&#8217; that gets automatically included inside the shell of the bibliography.html page. From there, I just modified the style so that it would fit into the aesthetic of the site.</p>

<p>Now anyone going to our bibliography page with a Zotero extension will see this in the right of the address bar:</p>

<p><img src="/images/zotero-extension.jpg"></p>

<p>Clicking on the folder icon will bring up the Zotero interface for downloading any of the items in our collection.</p>

<p><img src="/images/zotero-download.jpg"></p>

<p>And to update this information we only need to run a single python script from the terminal to re-generate everything.</p>

<p>The code is not live on the Huon site just yet, but you can download and manipulate these pieces from an example file I uploaded to the <a href="https://github.com/wludh/huondauvergne/blob/zotero/zot_bib_web/zot_example.py">Huon GitHub repository</a>. You&#8217;ll probably want to start by installing zot_bib_web first to familiarize yourself with the configuration, and you&#8217;ll have a few settings to update before it will work for you: the library id, library type, api key, and collection ID will all need to be updated for your particular case, and the jQuery excerpt above will need to point to wherever you output the bibliography file.</p>

<p>These steps have strengthened the way in which we handle bibliographic metadata so that it can be more useful for everyone, and we were really only able to do it because of the many great open source libraries that allow others to build on them. It&#8217;s a great thing - not having to reinvent the wheel.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/12/04/dh-mentoring/">Reflections on a Year of DH Mentoring</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-12-04T09:13:00-05:00" pubdate data-updated="true">Dec 4<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>[Cross-posted on the <a href="http://scholarslab.org/digital-humanities/reflections-on-a-year-of-dh-mentoring/">Scholars&#8217; Lab blog</a> and the <a href="http://digitalhumanities.wlu.edu/blog/2015/12/03/reflections-on-a-year-of-dh-mentoring/">Digital Humanities at Washington and Lee blog</a>]</em></p>

<p>This year I am working with <a href="http://scholarslab.org/people/eric-rochester/">Eric Rochester</a> in the <a href="http://scholarslab.org/">Scholars&#8217; Lab</a> on a fellowship project that has me learning natural language processing (NLP), the application of computational methods to human languages. We&#8217;re adapting these techniques to study quotation marks in the novels of Virginia Woolf (read more about the project <a href="http://scholarslab.org/digital-humanities/virginia-woolf-natural-language-processing-and-the-quotation-mark/">here</a>). We actually started several months before this academic year began, and, as we close out another semester, I have been spending time thinking about just what has made it such an effective learning experience for me. I already had a technical background from my time in the Scholars&#8217; Lab at the beginning of the process, but I had no experience with Python or NLP. Now I feel most comfortable with the former of any other programming language and familiar enough with the latter to experiment with it in my own work.</p>

<p>The general mode of proceeding has been this: depending on schedules and deadlines, we meet once or twice every two weeks. Between our meetings I would work as far and as much as I could, and the sessions would offer a space for Eric and me to talk about what I had done. The following are a handful of things we have done that, I think, have helped to create such an effective environment for learning new technical skills. Though they are particular to this study, I think they can be usefully extrapolated to apply to many other project-based courses of study in digital humanities. They are primarily written from the perspective of a student but with an eye to how and why the methods Eric used proved so effective for me.</p>

<p><strong>Let the Wheel Be Reinvented Before Sharing Shortcuts</strong></p>

<p>I came to Eric with a very small program adapted from Matt Jockers&#8217;s book on Text Analysis with R for Students of Literature that did little beyond count quotation marks and give some basic statistics. I was learning as I built the thing, so I was unaware that I was reinventing the wheel in many cases, rebuilding many protocols for dealing with commonly recognized problems that come from working with natural language. After working on my program and my approach to a degree of satisfaction, Eric pulled back the curtain to reveal that a commonly used python module, the Natural Language ToolKit <a href="http://www.nltk.org/">(NLTK)</a>, could address many of my issues and more. NLTK came as something of a revelation, and working inductively in this way gave me a great sense of the underlying problems the tools could address. By inventing my own way to read in a text, clean it to make its text uniformly readable by the computer, and breaking the whole piece into a series of words that could be analyzed, I understood the magic behind a couple lines of NLTK code that could do all that for me. The experience also helped me to recognize ways in which we would have to adapt NLTK for our own purposes as I worked through the book.</p>

<p><strong>Have a Plan, but Be Flexible</strong></p>

<p>After discussing NLTK and how it offered an easier way of doing the things that I wanted, Eric had me systematically work through the <a href="http://www.nltk.org/book/">NLTK book</a> for a few months. Our meetings took on the character of an independent study: the book set the syllabus, and I went through the first seven chapters at my own pace. Working from a book gave our meetings structure, but we were careful not to hew too closely to the material. Not all chapters were relevant to the project, and we cut sections of the book accordingly. We shaped the course of study to the intellectual questions rather than the other way around.</p>

<p><strong>Move from Theory to Practice / Textbook to Project</strong></p>

<p>As I worked through the book, I was able to recognize certain sections that felt most relevant to the Woolf work. Once I felt as though I had reached a critical mass, we switched from the book to the project itself and started working. I tend to learn from doing best, so the shift from theory to execution was a natural one. The quick and satisfying transition helped the work to feel productive right away: I was applying my new skills as I was still learning to feel comfortable with them. Where the initial months had more the feel of a traditional student-teacher interaction, the project-based approach we took up at this point felt more like a real and true collaboration. Eric and I would develop to-do items together, we would work alongside each other, and we would talk over the project together.</p>

<p><strong>Document Everything</strong></p>

<p>Between our meetings I would work as far and as much as I could, carefully noting places at which I encountered problems. In some cases, these were conceptual problems that needed clarifying, and these larger questions frequently found their way into separate notes. But my questions were frequently about what a particular line of code, a particular command or function, might be doing. In that case, I made comments directly in the code describing my confusion. I quickly found that these notes were as much for me as for Eric&#8211;I needed to get back in the frame of mind that led to the confusion in the first place, and copious notes helped remind me what the problem was. These notes offered a point of departure for our meetings: we always had a place to start, and we did so based on the work that I had done.</p>

<p><strong>Communicate in as Many Ways as Possible</strong></p>

<p>We met in person as much as possible, but we also used a variety of other platforms to keep things moving. Eric and I had all of our code on <a href="https://github.com/erochest/woolf">GitHub</a> so that we could share everything that we had each been working on and discuss things from a distance if necessary. Email, obviously, can do a lot, but I found the chat capabilities of the Scholars&#8217; Lab&#8217;s IRC channel to be far better for this sort of work. If I hit a particular snag that would only require a couple minutes for Eric to answer, we could quickly work things out through a web chat. With Skype and Google Hangouts we could even share the code on the other person&#8217;s computer even from hundreds of miles away. All of these things meant that we could keep working around whatever life events happened to call us away.</p>

<p><strong>Recognize Spinning Wheels</strong></p>

<p>These multiple avenues of communication are especially important when teaching technical skills. Not all questions or problems are the same: students can work through some on their own, but others can take them days to troubleshoot. Some amount of frustration is a necessary part of learning, and I do think it&#8217;s necessary that students learn to confront technical problems on their own. But not all frustration is pedagogically productive. There comes a point when you have tried a dozen potential solutions and you feel as though you have hit a wall. An extra set of eyes can (and should) help. Eric and I talked constantly about how to recognize when it was time for me to ask for help, and low-impact channels of communication like IRC could allow him to give me quick fixes to what, to me at least, seemed like impossible problems. Software development is a collaborative process, and asking for help is an important skill for humanists to develop.</p>

<p><strong>In-person Meetings Can Take Many Forms</strong></p>

<p>When we met, Eric and I did a lot of different things. First, we would talk through my questions from the previous week. If I felt a particular section of code was clunky or poorly done, he would talk and walk me through rewriting the same piece in a more elegant form. We would often pair program, where Eric would write code while I watched, carefully stopping him each time I had a question about something he was doing. And we often took time to reflect on where the collaboration was going - what my end goal was as well as what my tasks before the next meeting would be. Any project has many pieces that could be dealt with at any time, and Eric was careful to give me solo tasks that he felt I could handle on my own, reserving more difficult tasks for times in which we would be able to work together. All of this is to say that any single hour we spent together was very different from the last. We constantly reinvented what the meetings looked like, which kept them fresh and pedagogically effective.</p>

<p>This is my best attempt to recreate my experience of working in such a close mentoring relationship with Eric. Obviously, the collaboration relies on an extremely low student-to-teacher ratio: I can imagine this same approach working very well for a handful of students, but this work required a lot of individual attention that would be hard to sustain for larger classes. One idea for scaling the process up might be to divide a course into groups, being training one, and then have students later in the process begin to mentor those who are just beginning. Doing so would preserve what I see as the main advantage of this approach: it helps to collapse the hierarchy between student and teacher and engage both in a common project. Learning takes place, but it does so in the context of common effort. I&#8217;d have to think more about how this mentorship model could be adapted to fit different scenarios. The work with Eric is ongoing, but it&#8217;s already been one of the most valuable learning experiences I have had.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/09/20/music-genre-and-spotify-metadata/">Music Genre and Spotify Metadata</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-09-20T16:51:00-04:00" pubdate data-updated="true">Sep 20<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em><a href="http://scholarslab.org/?p=12173">Cross-posted on the Scholars&#8217; Lab blog</a></em></p>

<p>For the last couple weeks, I have been exploring APIs useful to sound studies for a sound recording and poetry project I am working on with former Scholars’ Lab fellow <a href="https://annieswafford.wordpress.com/">Annie Swafford</a>. I was especially drawn to playing around with <a href="https://www.spotify.com/us/">Spotify</a>, which has an <a href="https://developer.spotify.com/web-api/">API</a> that allows you to access metadata for the large catalog of music available through their service. The experiment described below focuses on genre: a notoriously messy category that we nonetheless rely on to tell us how to process the materials we read, view, or hear. Genre tells us what to expect from the art we take in, and our construction and reception of generic categories can tell us a lot about ourselves. In music, especially, genres and subgenres can activate fierce debates about authenticity and belonging. Does your favorite group qualify as &#8220;authentic&#8221; jazz? What composers do you have to know in order to think of yourself as a real classical music aficionado? Playing with an artist&#8217;s metadata can expose a lot of the assumptions that were made in its collection, and I was especially interested in the ways in which Spotify models relations among artists.</p>

<p>I wanted to explore Spotify’s metadata in a way that would model the interpretive messiness of generic categories. To do so, I built a program that bounces through Spotify’s metadata to produce multiple readings of the idea of genre in relation to a particular artist. Spotify offers a fairly robust API, and there are a number of handy wrappers that make it easier to work with. I used a Python module called <a href="http://spotipy.readthedocs.org/en/latest/">Spotipy</a> for the material below, and you can find <a href="https://github.com/bmw9t/spotify/blob/master/genre_machine.py">the code for my little genre experiment over on my GitHub page</a>. If you do try to run this on your own machine, note that you will need to clone Spotipy’s repository and manually install it from the terminal with the following command from within the downloaded repository:</p>

<pre><code>$ python setup.py install
</code></pre>

<p>Pip will install an older distribution of the code that will only run in Python 2, but Spotipy&#8217;s GitHub page has a more recent release that is compatible with Python 3.</p>

<p>When run, the program outputs what I like to think of as the equivalent of music nerds arguing over musical genres. You provide an artist name and a number, and the terminal will work through Spotify’s API to produce the specified number of individual &#8220;mappings&#8221; of that artist’s genre as well as an aggregate list of all their associated genres. The program starts by pulling out all the genre categories associated with the given artist as well as those given to artists that Spotify flags as related. Once finished, the program picks one of those related artists at random and continues to do the same until the process returns no new genre categories, building up a list of associated genres over time.</p>

<p>So, in short, you give the program an artist and it offers you a few attempts at describing that artist generically using Spotify&#8217;s catalog, the computational equivalent of instigating an argument about genre in your local record store. Here are the results for running the program three times for the band New Order:</p>

<pre><code>Individual genre maps

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'new romantic', 'new wave pop', 'hi nrg', 'europop', 'power pop', 'album rock']

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'gothic metal', 'j-metal', 'visual kei', 'intelligent dance music', 'uk post-punk', 'metropopolis', 'ambient', 'big beat', 'electronic', 'illbient', 'piano rock', 'trance', 'progressive house', 'progressive trance', 'uplifting trance', 'quebecois', 'deep uplifting trance', 'garage rock', 'neo-psychedelic', 'space rock', 'japanese psychedelic']

Just one nerd's opinions on New Order:

['dance rock', 'new wave', 'permanent wave', 'uk post-punk', 'gothic rock', 'discofox', 'madchester', 'britpop', 'latin', 'latin pop', 'teen pop', 'classic colombian pop', 'rai', 'pop rap', 'southern hip hop', 'trap music', 'deep rai']

Aggregate genre map for New Order:

['dance rock', 'new wave', 'permanent wave', 'new romantic', 'new wave pop', 'hi nrg', 'europop', 'power pop', 'album rock', 'gothic metal', 'j-metal', 'visual kei', 'intelligent dance music', 'uk post-punk', 'metropopolis', 'ambient', 'big beat', 'electronic', 'illbient', 'piano rock', 'trance', 'progressive house', 'progressive trance', 'uplifting trance', 'quebecois', 'deep uplifting trance', 'garage rock', 'neo-psychedelic', 'space rock', 'japanese psychedelic', 'gothic rock', 'discofox', 'madchester', 'britpop', 'latin', 'latin pop', 'teen pop', 'classic colombian pop', 'rai', 'pop rap', 'southern hip hop', 'trap music', 'deep rai']
</code></pre>

<p>In each case, the genre maps all begin the same, with the categories directly assigned to the source artist. Because the process is slightly random, the program eventually maps the same artist’s genre differently each time. For each iteration, the program runs until twenty randomly selected related artists return no new genre categories, which I take to be a kind of threshold of completion for one understanding of an artist’s genre.</p>

<p>The results suggest an amalgam of generic influence, shared characteristics, common lineages, and overlapping angles of approach. The decisions I made in how the program interacts with Spotify’s metadata suggest a definition of genre like the one offered by Alastair Fowler: “Representatives of a genre may then be regarded as making up a family whose septs and individual members are related in various ways, without necessarily having any single feature shared in common by all” (41). Genre is fluid and a matter of interpretive opinion - it is not necessarily based on objective links. The program reflects this in its results: sometimes a particular generic mapping feels very coherent, while at other times the script finds its way to very bizarre tangents. The connections do exist in the metadata if you drill down deeply enough, and it is possible to reproduce the links that brought about such output. But the more leaps the program takes from the original artist the more tenuous the connections appear to be. As I wrote this sentence, the program suggested a connection between garage rock revivalists The Strokes and big band jazz music: such output looks less like a conversation among music nerds and more like the material for a Ph.D. dissertation. As the program illustrates, generic description is the beginning of interpretation - not the ending.</p>

<p>Of course, the program does not actually search all music ever: it only has access to the metadata for artists listed in Spotify, and some artists like Prince or the Beatles are notoriously missing from the catalog. Major figures like these have artist pages that serve as stubs for content drawn largely from compilation CDs, and the program can successfully crawl through these results. But this wrinkle points to a larger fact: the results the program produces are as skewed as the collection of musicians in the service’s catalog. Many of the errors I had to troubleshoot were related to the uneven nature of the catalog: early versions of the script were thrown into disarray when Spotify listed no related artists for a musician. On occasion, the API suggested a related artist who did not actually have an artist page in the system (often the case with new or less-established musicians). I massaged these gaps to make this particular exercise work (you’ll now get a tongue in cheek “Musical dead end” or “Artist deleted from Spotify” output for them), but the silences in the archive offer significant reminders of the commercial politics that go into generic and archival formation, particularly when an archive is proprietary. I can imagine tweaking things slightly to create a script that produces only those archival gaps, but that is work for another day. In the meantime, I&#8217;ll be trying to figure out <a href="https://en.wikipedia.org/wiki/Yeezus">how Kanye West might be considered Christmas music</a>.</p>

<p>Works Cited:</p>

<p>Fowler, Alastair David Shaw. Kinds of Literature: An Introduction to the Theory of Genres and Modes. Repr. Oxford: Clarendon Press, 1997. Print.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/09/10/woolf-and-the-quotation-mark/">Virginia Woolf, Natural Language Processing, and the Quotation Mark</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-09-10T11:21:00-04:00" pubdate data-updated="true">Sep 10<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Cross-posted on the <a href="http://scholarslab.org/?p=12117/">Scholars&#8217; Lab blog</a></em></p>

<p>For my fellowship in the Scholars&#8217; Lab this year I&#8217;ll be working with <a href="http://scholarslab.org/people/eric-rochester/">Eric</a> to expand a project we began last year on Virginia Woolf and natural language processing. My dissertation focuses on sound recordings and modernism, and this year I will focus on how Woolf&#8217;s quotation marks offer evidence of her engagement with sound as a textual device. In my reading, the quotation mark is the most obvious point at which sound meets text, the most heavily used sound recording technology in use by writers. Patterns in quotation mark usage across large corpora can tell us a lot about the role that sound plays in literature, but, as you might expect, there are <em>lots</em> of quotation marks - hundreds or thousands in any given text. Computational methods can help us make sense of the vast number and turn them into reasonable objects of study.</p>

<p>You can find more information in <a href="http://scholarslab.org/digital-humanities/hearing-silent-woolf/">this post</a> about my thinking on quotation marks and some preliminary results from thinking about them in relation to Woolf. As I discuss there, finding quotation marks in a text is not especially challenging, but this year Eric and I will be focusing on a particular wrinkle in Woolf&#8217;s use of the marks, best conveyed in <em>The Hours</em>, Michael Cunningham&#8217;s late-century riff on Virginia Woolf. In <em>The Hours</em>, Cunningham offers a fictionalized version of Woolf meditating on her composition process:</p>

<blockquote><p>She passes a couple, a man and woman younger than herself, walking together, leisurely, bent towards each other in the soft lemon-colored glow of a streetlamp, talking (she hears the man, “told me <em>something something something</em> in this establishment, <em>something something</em>, harrumph, indeed”) (166).</p></blockquote>

<p>The repeated &#8221;<em>somethings</em>&#8221; of the passage suggest the character&#8217;s imperfect experience of the conversation as well as the limits of her senses. As the moment is conveyed through the character&#8217;s perspective, the conversation will always be incomplete. Recording technology was largely unreliable during the early days of the twentieth century, and, similarly, the sound record of this conversation as given by the text is already degraded before we hear it. Cunningham points to how the sounded voice is given character in the ears of the listener, and, in a print context, in the pen of the writer. A printed voice can speak in a variety of ways and in a variety of modes.</p>

<p>Cunningham&#8217;s passage contains echoes of what will eventually be the famous first sentence of Woolf&#8217;s <em>Mrs. Dalloway</em>: &#8220;Mrs. Dalloway said she would buy the flowers herself.&#8221; The text implies that Mrs. Dalloway speaks, but it does not mark it as such: the same conversational tone in Cunningham remains here, but the narrator does not differentiate sound event from narrative by using quotation marks. We see moments of indirect speech like this all the time, when discourse becomes submerged in the texture of the narrative, but it doesn’t disappear entirely. Speech implies a lot: social relations, the thoughts of a speaking body, among others. Things get muddy when the line between narrative voice and speech becomes unclear. If quotation marks imply a different level of speech than unquoted speech, might they also imply changes in the social relations they represent?</p>

<p><em>Mrs. Dalloway</em> is filled with moments like these, and this year I&#8217;ll be working to find ways to float them to the surface of the text. Examining these moments can tell us how conversation changes during the period, what people are talking about and for, how we conceive of the limits of print and sound, and about changing priorities in literary aesthetics. The goal this year is to train the computer to identify moments like this, moments that a human reader would be able to parse as spoken but that are not marked as such. Our first pass will be to work with the quoted material, which we can easily identify to build a series of trigger words that Woolf uses to flag speech as sound (said, asked, called, etc.). With this lexicon, we can then look for instances in her corpus where they pop up without punctuation. Teaching the computer to classify these passages correctly will be a big task, and this process alone will offer me lots of new material to work with as I untangle the relationship between modernist print and sound. In upcoming posts I&#8217;ll talk more about the process of learning natural language processing and about some preliminary results and problems. Stay tuned!</p>

<p>Works Cited:</p>

<p>Cunningham, Michael. <em>The Hours</em>. New York: Picador USA : Distributed by Holtzbrinck Publishers, 2002. Print.</p>

<p>Woolf, Virginia. <em>Mrs. Dalloway</em>. 1st Harvest/HBJ ed. San Diego: Harcourt Brace Jovanovich, 1990. Print.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/03/23/woolf-huskey/">Hearing Silent Woolf</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-03-23T16:37:00-04:00" pubdate data-updated="true">Mar 23<span>rd</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>[This week I presented at the <a href="http://gradcouncil.com/2015-sessions/">2015 Huskey Research Exhibition</a> at UVA. The talk was delivered from very schematic notes, but below is a rough recreation of what I discussed. The talk I gave is a crash course in a new project I&#8217;ve started working on with the generous help of the <a href="http://scholarslab.org">Scholars&#8217; Lab</a> that thinks about sound in Virginia Woolf&#8217;s career using computational methods. <a href="http://www.ericrochester.com/">Eric Rochester</a>, especially, has been endlessly giving of his time and expertise, helping me think through and prototype work on this material. The talk wound up receiving first prize for the digital humanities panel of which I was a part. The project is still very much inchoate, and I&#8217;d welcome thoughts on it.]</em></p>

<p>When I talk to you, you make certain assumptions about me as a person based on what you&#8217;re hearing. You decide whether or not I might be worth paying attention to, and you develop a sense of our social relations based around the sound of my voice. The voice conveys and generates assumptions about the body and about power: am I making myself heard? Am I registering as a speaking voice? Am I worth listening to?</p>

<p><a href="http://commons.wikimedia.org/wiki/File:Day_14_Occupy_Wall_Street_September_30_2011_Shankbone_2.JPG
"><img src="/images/occupy.jpg" width="60%" class="left"></a></p>

<p>The human microphone, made famous by Occupy Wall Street, nicely encapsulates the social dimensions of sound that interest me: one person speaks, and the people around her repeat what she says more loudly, again and again, amplifying the human voice without technology. Sound literally moves through multiple bodies and structures the social relations between people, and the whole movement is an attempt to make a group of people heard by those who would rather not listen.</p>

<p>As a literary scholar, I am interested in how texts can speak in similar ways. The texts we read frequently contain large amounts of speech within them: conversations, monologues, poetic voice, etc. We talk about sound in texts all the time, and the same social and political dimensions of sound still remain even if a text appears silent on the page. If who can be heard and who gets to speak are both contested questions in the real world, they continue to structure our experiences of printed universes.</p>

<p>All of this brings me to the quotation mark. The humble piece of punctuation does a lot of work for us every day, and I want to think more closely about how it can help us understand how texts speak. The quotation mark is the most obvious point at which sound meets text. Computational methods tend to focus on the vocabulary of a text as the building blocks of meaning, but they can also help us turn quotation marks into objects of inquiry. Quotation marks can tell us a lot about how texts engage with the human voice, but there are <em>lots</em> of them in texts. Digital methods can help us make sense of the scale.</p>

<p><img src="/images/woolf.jpg" width="40%" class="right">I examine Virginia Woolf&#8217;s quotation marks, in particular, for a number of reasons. Aesthetically, we can see her bridging the Victorian and modernist literary periods, though she tends to fall in with the latter of the two. Politically, she lived through periods of intense social and political upheaval at the beginning of the twentieth century. Very few recordings of Woolf remain, but she nonetheless thought deeply about sound recording. The worldwide market for gramophones exploded during her lifetime, and her texts frequently featured technologies of sound reproduction. Woolf&#8217;s gramophones frequently malfunction in her novels, and I&#8217;m interested in seeing how her quotation marks might analogously be irregular or broken intentionally. Woolf is especially good for thinking about punctuation marks in this way: she owned a printing press, and she often set type herself.</p>

<p>The following series of histograms gives a rough estimation of how Woolf&#8217;s use of quotation changes over the course of her career. <a href="https://github.com/erochest/woolf/commits/master">On GitHub</a> you can find the script I&#8217;ve been working on with Eric to generate these results. The number of quotations is plotted on the y-axis against their position in the novel on the x-axis, so each histogram represents more quoted speech with higher bars and more concentrated darknesses. If you have an especially good understanding of a particular novel, <em>Mrs. Dalloway</em>, say, you could pick out moments of intense conversation based on sudden spikes in the number of quotations. The histograms are organized in such a way that to read chronologically through Woolf&#8217;s career you would read left to right line by line, as you would the text of a book. The top-left histogram is Woolf&#8217;s earliest novel, the bottom-right corner her last.</p>

<p><a href="/images/huskey-histograms/1915_the_voyage_out.jpg"><img src="/images/huskey-histograms/1915_the_voyage_out.jpg" width="32%"></a>
<a href="/images/huskey-histograms/1919_night_and_day.jpg"><img src="/images/huskey-histograms/1919_night_and_day.jpg" width="32%"></a>
<a href="/images/huskey-histograms/1922_jacobs_room.jpg"><img src="/images/huskey-histograms/1922_jacobs_room.jpg" width="32%"></a>
<a href="/images/huskey-histograms/1925_mrs.dalloway.jpg"><img src="/images/huskey-histograms/1925_mrs.dalloway.jpg" width="32%"></a>
<a href="/images/huskey-histograms/1927_to_the_lighthouse.jpg"><img src="/images/huskey-histograms/1927_to_the_lighthouse.jpg" width="32%"></a>
<a href="/images/huskey-histograms/1928_orlando.jpg"><img src="/images/huskey-histograms/1928_orlando.jpg" width="32%"></a>
<a href="/images/huskey-histograms/1931_the_waves.jpg"><img src="/images/huskey-histograms/1931_the_waves.jpg" width="32%"></a>
<a href="/images/huskey-histograms/1937_the_years.jpg"><img src="/images/huskey-histograms/1937_the_years.jpg" width="32%"></a>
<a href="/images/huskey-histograms/1941_between_the_acts.jpg"><img src="/images/huskey-histograms/1941_between_the_acts.jpg" width="32%"></a></p>

<p>To my eye, the output suggests high concentrations of conversation in the novels at the beginning and ending of Woolf&#8217;s career. We can see that her middle period, especially, appears to have a significant decrease in the amount of quoted speech. In one sense, this might make sense to someone familiar with Woolf&#8217;s career. Her first two novels feel more typically Victorian in their aesthetics, and she really gets into the thick of modernist experiment with her third novel. One way we often describe the shift from Victorian to the modernist period is as a shift inward, away from society and towards the psychology of the self. So it makes sense that we might see the amount of conversation between multiple speaking bodies significantly fall away over the course of those novels. <a href="/images/huskey-histograms/1931_the_waves.jpg">The seventh histogram</a> is especially interesting, because it suggests the least amount of speech of anything in her corpus. But if we visualize things a different way, we see that this novel, <em>The Waves</em>, actually shows a huge spike in punctuated speech. This graph represents the percentage of each text that is contained within quotation marks, the amount of text represented as punctuated speech.</p>

<p><a href="/images/huskey-histograms/percentage-quoted.jpg"><img src="/images/huskey-histograms/percentage-quoted.jpg" class="right"></a></p>

<p>This might look like a problem with the data: how could the text with the fewest number of quotations also have the highest percentage of quoted speech? But the script is actually giving me exactly what I asked for: <em>The Waves</em> is a series of monologues by six disembodied voices, and the amount of non-speech text is extremely small. More generally, charting the percentage of quoted speech in the corpus appears to support my general readings of the original nine histograms: roughly three times as much punctuated speech in the early novels as in the middle period, with a slight leveling off in the end of her career.</p>

<p>We could think of <em>The Waves</em> as an anomaly, but I think it more clearly calls for a revision of such a reading of speech in Woolf&#8217;s career. The spike in quoted speech is a hint that there is something else going on in Woolf&#8217;s work. Perhaps we can use the example of <em>The Waves</em> to propose that there might be a range of discourses, of types of speech in Woolf&#8217;s corpus. Before I suggested that speech diminished in the middle of Woolf&#8217;s career, but that&#8217;s not exactly true. My suspicion is that it just enters a different mode. Consider these two passages, both quoted from <em>Mrs. Dalloway</em>:</p>

<blockquote><p>Mrs. Dalloway said she would buy the flowers herself.</p>

<p>Times without number Clarissa had visited Evelyn Whitbread in a nursing home.  Was Evelyn ill again?  Evelyn was a good deal out of sorts, said Hugh, intimating by a kind of pout or swell of his very well-covered, manly, extremely handsome, perfectly upholstered body (he was almost too well dressed always, but presumably had to be, with his little job at Court) that his wife had some internal ailment, nothing serious, which, as an old friend, Clarissa Dalloway would quite understand without requiring him to specify.</p></blockquote>

<p>In each case, the text implies speech by Mrs. Dalloway and by Hugh without marking it as such with punctuation marks. Discourse becomes submerged in the texture of the narrative, but it doesn&#8217;t disappear entirely. Moments like these suggest a range of discourses in Woolf&#8217;s corpus: dialogue, monologue, conversation, punctuated, implied, etc. All of these speech types have different implications, but it&#8217;s difficult to get a handle on them because of their scale. I began the project by simply trying to mark down moments of implied speech in <em>Mrs. Dalloway</em> by hand. Once I got to about two hundred, it seemed like it was time to ask the computer for help.</p>

<p>The current plan moving forward is to build a corpus of test passages containing both quoted speech and implied speech, train a python script against this set of passages, and then use this same script to search for instances of implied speech throughout Woolf&#8217;s corpus. Theoretically, at least, the script will search for a series of words that flag text as implied speech to a human reader - said, recalled, exclaimed, etc. Using this lexicon as a basis, the script would then pull out the context surrounding these words to produce a database of sentences meant to serve as speech. At Eric&#8217;s suggestion, I&#8217;m currently exploring the <a href="http://www.nltk.org/index.html">Natural Language Toolkit</a> to take a stab at all of this. My own hypothesis is that there will be an inverse relationship between quoted speech and implied speech in her corpus, that the amount of speech left unflagged by quotation marks will increase in the middle of Woolf&#8217;s career. Once I have all this material, I&#8217;ll be able to subject the results to further analysis and to think more deeply about speech in Woolf&#8217;s work. Who speaks? What about? What counts as a voice, and what is left in an ambiguous, unsounded state?</p>

<p>The project is very much in its beginning stages, but it&#8217;s already opening up the way that I think about speech in Woolf&#8217;s text. It tries to untangle the relationship between our print record and our sonic record, and further work will help show how discourse is unfolding over time in the modernist period.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/02/02/moving-people-linking-lives-dh-symposium/">Moving People, Linking Lives DH Symposium</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-02-02T14:33:00-05:00" pubdate data-updated="true">Feb 2<span>nd</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>[I am very excited to be working with Alison Booth, Jenny Strauss Clay, and Amy Ogden to plan a digital humanities symposium this March. What follows is our general announcement of the event, cross-posted on the <a href="http://scholarslab.org/uncategorized/moving-peoplelinking-lives-dh-symposium/">Scholars&#8217; Lab</a> blog.]</p>

<p>I am pleased to announce that &#8221;<a href="http://movingpeoplelinkinglives.org">Moving People, Linking Lives: An Interdisciplinary Symposium</a>&#8221; will take place March 20-21, 2015 at the University of Virginia. Presentations and workshops will open dialogue across different fields, periods, and methods, from textual interpretation to digital research. Invited participants include specialists on narrative theory and life writing, prosopography or comparative studies of life narratives in groups, and the diverse field of digital humanities or computer-assisted research on cultural materials, from ancient texts to Colonial archives, from printed books to social media.</p>

<p>Invited participants include: Elton Barker, Jason Boyd, James Phelan, Susan Brown, Margaret Cormack, Courtney Evans, Will Hanley, Ben Jasnow, Ruth Page, Sue Perdue, Sidonie Smith. We hope to have lots of locals involved with digital work participate as well, and we particularly encourage graduate students to join in for the weekend!</p>

<p>Our symposium will bridge the gaps among our fields; share the innovations of several digital projects; and welcome the skeptical or the uninitiated, whether in our historical fields or in the applications of technology in the humanities. Booth, Clay, and Ogden have each led digital projects with some common themes and aims: locating, identifying, and interpreting the narratives—or very often, the lack of discursive records—about individuals in groups or documents, in Homer or other ancient text, Medieval French hagiography, and nineteenth-century printed collections of biographies in English. We want to open discussion of many potential methods including our own—data mining and digital editions of texts; relational databases and historical timelines and maps—for research on groups of interlinked persons, narratives or data about their lives, and documents or other records, and synthesizing and visualizing this research in accessible ways that reach students and the public. Digital innovation, however, should be informed by traditions of scholarly interpretation and advanced theoretical insights and commitments. Narrative theory and Theory generally, ideological critique including studies of gender and race, textual and book history studies, transnational and social historiography, philology and language studies, archeology, cultural geography and critical cartography, are all gaining influence on digital projects.</p>

<p>Invited participants will be posting about their research to <a href="http://movingpeoplelinkinglives.org">our blog</a> in the weeks leading up to the symposium, anyone is free to comment on the posts. In addition, our participants will be building a <a href="http://movingpeoplelinkinglives.org/bibliography/">Zotero-powered bibliography</a> in the weeks leading up to the symposium full of rich materials related to the event’s discussion.</p>

<p>Organized and hosted by Alison Booth, Jenny Strauss Clay, and Amy Odgen and sponsored by the Page Barbour Committee, the departments of English, French, and Art, the Institute for Humanities and Global Cultures, the Scholars’ Lab and Institute for Advanced Technology in the Humanities, and other entities at UVa, all events are free and open to the public. More information can be found on the blog as planning progresses, and you can follow us on twitter at @livesdh.</p>

<p>Join in the conversation on the blog at <a href="http://movingpeoplelinkinglives.org">movingpeoplelinkinglives.org</a>, and we hope to see many come out for fruitful interchange in March!</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/01/17/collation/">Collation and Writing Pedagogy</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-17T09:41:00-05:00" pubdate data-updated="true">Jan 17<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>[The following is the talk that I gave at the 2015 MLA Conference on a panel on &#8220;Pedagogy and Digital Editions.&#8221; The Google Docs section is a slight reworking and recontextualization of a <a href="http://bmw9t.github.io/blog/2013/09/25/writing-out-loud/">previous post</a> on the subject. I&#8217;m especially grateful to <a href="https://twitter.com/damozel_">Sarah Storti</a> and <a href="https://twitter.com/andrew_stauffer">Andrew Stauffer</a> for their suggestions and comments on how to use Juxta Commons to teach writing.]</p>

<p><strong>Collation and Writing Pedagogy with Juxta Commons and Google Docs</strong></p>

<p>We typically think about using digital collation to compare those documents that already exist. The usual model gathers multiple copies, multiple witnesses, of the same text, and juxtaposes them to gather a sense of the very small, micro changes that have been made to a document. We use these changes to deconstruct our sense of a complete and unified final whole. Instead, we get a sense of a series of related texts, of a work manifesting in different forms, and of stages of a revision process for which we were not present. I am especially interested in the last of these categories: collation tools allow us to uncover revision histories that might be otherwise obscured. They help us to uncover past stages of the writing process, breaking apart a text that might seem concrete and fixed and make it appear fluid and subject to change.</p>

<p>The illusion of a final unified text is a problem for textual editing, and collation tools have helped us to solve it for decades. This same problem, the tendency to think of texts as final objects with no prior histories, is at its core one of the key difficulties facing student writers. There is a danger for students to think of writing as crafting a marble structure – you chip away at it piece by piece until it forms a perfect, fixed form – the form it was meant to possess all along. Instead, I want to argue that collation tools can be used by teachers to help students conceive of writing as a kind of assemblage, a piecing together that instantiates one possible combination among many of a set of textual components. This mode of writing is, by contrast, characterized by play, transformation, and fluidity.</p>

<p>I will talk about two tools today in this context - <a href="http://juxtacommons.org/">Juxta Commons</a> and <a href="http://www.google.com/docs/about/">Google Docs</a> – and the exercises I use with each. The former is a collation tool proper, and, while the latter is more typically used for collaborative writing, it lends itself quite readily to the practice. So my focus here is on the practical – how to think about and use these tools for to teach writing and revision. I hope to tease out more of their implications in the discussion.</p>

<p><strong>Juxta Commons</strong></p>

<p>Juxta Commons, probably familiar to many, is the latest iteration of Juxta, a piece of software that allows a user to upload multiple textual witnesses and, at a glance, discern the differences. The tool’s digital nature means that the process is quantified and streamlined – no laboring over the collator. It also has the benefit of offering a number of visualizations for graphically understanding the differences between two witnesses, a fact that I find helpful for talking about student writing.</p>

<p>A potential writing exercise for use with Juxta is simple: a student writes a paragraph, and they then rewrite that paragraph several times. Finally, the student uploads each version to Juxta before writing a brief reflection on the differences between the drafts. What remains constant? Where do changes cluster? Do these edits indicate any special anxiety or concern with any one particular element of the writing process – transitional sentences, thematic chaining, logic, etc.? Do the ideas themselves stay the same? Fixating on these details can allow students to conceive of writing as an assemblage of various components that result in the illusion of a coherent whole.</p>

<p><img src="/images/variants.jpg" width="100%"></p>

<p>In the example above, the student is writing a grant proposal for his tennis team. In an early draft, the class noted that the writing held the team at too much of a remove when the author wanted to stress its importance to him as a second family. Such a charge can seem like a big task, but processing the paragraph through the Juxta assignment throws into sharp relief the minute edits created in a revision to create such systemic change. Comparing the two revisions in Juxta, we can see that, by and large, the student revised the subjects of this first paragraph. “I” becomes “we,” and “friends” will become a “family.” He works to increase the sense of unity among the group of people he describes, a unity that will later become essential in his argument that the organization provides more to the community than just a place to play sports. The Juxta assignment allows a student better insight into how each of these component pieces can easily be sent into motion and radically change the character of the whole document. A large, sweeping suggestion like “adjust your tone” becomes revision by way of a thousand moving pieces. Much more doable.</p>

<p>Juxta Commons has the added bonus of being envisioned as a commons - an online community of textual scholars. It is quite easy to share sets with others, and it would take little effort to set up a repository of shared collation sets among a classroom. To encourage objective reflection as a component of writing, I would ask each student to write a short reflection on a different student’s collation set, observing the differences and reflecting on the minute changes that got them there.</p>

<p>Juxta’s strength as a collation tool is also its limitation for the sort of teaching exercise that I am describing. Juxta has the benefit of being quantitative: its visualizations can offer users quick and accurate depictions of things that might otherwise go unrecognized – a missing comma, or a single different word. Juxta works best with large documents that are largely the same. But if the corresponding passages become too different Juxta will be thrown into disarray.</p>

<p><img src="/images/too_much_difference.jpg" width="100%"></p>

<p>While it is very good at processing texts to find small differences, the software does not quite work if the documents are too different from one another. Its system allows for either exact similarity or difference at the level of character. It cannot tell, for example, if you have reworded a particular phrase or removed it entirely. The paragraph in this example was heavily rewritten, with only a few words in common between the two drafts. While this sort of at a glance collation could be useful to identify revised sections in longer documents, it does little to unsettle the idea of writing as a search for a fully realized whole. Juxta Commons works best for helping students to see the massive change that can be wrought by a collection of small changes.</p>

<p><strong>Google Docs</strong></p>

<p>One of the difficulties with using Juxta to collate is that it relies on a student’s already extant drafts – revision must already have taken place, which seems to defeat the whole purpose of an exercise designed to unsettle the writing process. Google Docs is not a tool made for collation, but I do think that it can helpfully generate just those many witnesses that <strong>could</strong> be collated. By using Google Docs as a collaborative writing space, classmates can help another generate different textual possibilities for a single sentence. My use of Google Docs in conjunction with a discussion of writing first came about in an advanced course on Academic and Professional Writing. We talked a lot about editing in the class, and many of the conversations about style took this shape:</p>

<p>Student A: &#8220;Something about this word feels strange, but I don&#8217;t know what it is.&#8221; <br/>
Student B: &#8220;What if we moved the phrase to the beginning of the sentence?&#8221;<br/>
Student C: &#8220;We could get rid of that word and use this phrase instead.”</p>

<p>Those statements are hard to wrap your head around. Just imagine if those conversations were spoken. Talking about writing can only get you so far: writing is graphic, after all. As I write and edit, I try out different options on the page. I model possibilities, but I do so <em>in</em> writing. Discussing the editing process without visual representations of suggested changes can make things too abstract to be meaningful for students. They need to see the different possibilities, the different potential witnesses. I developed an exercise that I call “Writing Out Loud” that more closely mirrors my actual editing process. Using a Google Doc as a collaborative writing space, students are able to model alternate revisions visually and in real time for discussion.</p>

<p>The setup requires a projector-equipped classroom and that students bring their laptops to class. Circulate the link to the Google Doc ahead of time, taking care that anyone with the link can edit the document. The template of the Google Doc consists of a blank space at the top for displaying the sentence under question and a series of workspaces for each student consisting of their name and a few blank lines. Separate workspaces prevent overlapping revisions, and they also minimize the disorienting effects of having multiple people writing on the same document.</p>

<p><img src="/images/WOL_template.jpg" width="40%" class="right"></p>

<p>We usually turn to the exercise when a student feels a particular sentence is not working but cannot articulate why. When this happens, I put the Writing Out Loud template on the projector with the original version of the sentence at the top. Using their own laptops, students sign onto the Doc and type out alternative versions of the sentence, and the multiple possible revisions show up on the overhead for everyone to see and discuss. After each student rewrites the sentence to be something that they feel works better, ask for volunteers to explain how the changes affect meaning. The whole process only takes a few minutes, and it allows you to abstract writing principles from the actual process of revision rather that the other way around. How does the structure of a sentence matter? How can word choice change everything? What pieces of a sentence are repetitive?</p>

<p><img src="/images/WOL_filled.jpg" width="100%"></p>

<p>I especially like this exercise because it asks multiple students to engage in the revision process. It is always easier to revise when you have critical distance on a piece of writing, and outside editors with no attachment to a particular word or phrase can offer just that. In the above example, the sentence under discussion contained the colloquial phrase “get the word out.” The class offered a range of alternatives that range in their formality. Instead of receiving an edict to professionalize their tone, the student gets a glimpse of many possibilities from which he can choose. The exercise also allows the choices to exist side by side, making collation possible in a way that the usual revision process makes difficult. Most students, I would wager, work with one or, at most, two drafts open at a single time. Google Docs can allow a number of possibilities to emerge.</p>

<p>The Google Docs exercise works better on micro-edits, revisions at the level of the sentence. The standard process of the exercise—write, collate, and discuss—would take far too long with anything longer than a few lines. The exercise can be particularly useful for those sentences that carry a lot of importance for entire arguments: thesis statements, topic sentences, the first sentences of the document, etc. Where Juxta is entirely quantitative and offers hand graphic visualizations of textual difference, this Google Docs exercise relies on you and the students to collate the materials yourselves. You can recognize subtle differences – a reworded idea vs. a dropped idea, for example. It trains students to internalize the practice of collation and reflect on the interpretive possibilities offered by such differences.</p>

<p><strong>Closing Analysis</strong></p>

<p>I find that students often think of editing as an intense, sweeping process that involves wholesale transformation from the ground up. Modeling multiple, slightly different versions of the same sentence can allow for a more concrete discussion of the sweeping rhetorical changes that even the smallest edits can make. In this sense, I think using these tools in the classroom allows students to conceive of a single composition as one instantiation among many. Forcing them to compose several different models means that the writing process will be looser. Collation as composition offers students a subjunctive space wherein they dwell in possibilities. It is a vision of composition as de and reconstruction, as a process that is constantly unfolding.</p>

<p>Digital tools uncover how writing is really always already such a fluid process, and they can allow students to see their own composition process in this way while they are still in the thick of it. Digital collation can offer students the chance to think of their own works as messy, subjunctive spaces, as things in flux. By allowing multiple possible versions of the same text to exist alongside and in relation to one another, they can allow students to slip between different textual realities. Most importantly, the process severs the link between the quality of an idea and the manner of its presentation. Instead of one right answer, students can see that there are many possible solutions to any writing difficulty.</p>

<p>I have touched on how exercises like these can also encourage students to distill writing principles from the process rather than the other way around. They can also help students to discover editorial principals through their own writing. I am imagining here a praxis-oriented approach to teaching textual editing where practice leads to principal, one where scholarly readings might come after a student has written an essay, revised it, and, in effect, produced their own edition of their text. An exercise with Juxta might lead to a discussion of eclectic editions, while Google Docs could lead to a fruitful discussion of accidentals and substantives. I am not suggesting that these sorts of exercises replace the good work performed by studying classic editions, reading about editorial practices, or producing one’s own edition by carrying out the steps of the editorial process. But in a class that has an explicit focus on composition, exercises with tools like Juxta Commons and Google Docs can help connect textual criticism with writing pedagogy.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/01/12/deformance-talk/">The Devil in the Recording</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-12T10:29:00-05:00" pubdate data-updated="true">Jan 12<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>[The following is an only slightly modified version of the talk I gave at the <a href="http://ach.org/">ACH</a>&#8217;s panel on &#8220;Digital Deformance and Scholarly Forms&#8221; at the 2015 MLA conference. For more details on how to reverse audio recordings, see my <a href="http://bmw9t.github.io/blog/2015/01/05/deformance/">previous post on the subject</a>.]</p>

<p><strong>The Devil in the Recording: Deformative Listening and Sound Reproduction</strong></p>

<p>It’s a well-known fact that you can find the devil in popular music. Simply take Led Zeppelin’s “Stairway to Heaven,” play it backwards, and voila. You’ll get messages for, if not by, the Lord of the Flies. Obviously I’m being facetious. Few, if any, take this claim seriously, but it does offer serious ways to think about deformance in the context of sound recordings, particularly those with linguistic or literary content. The digital method of deformance I’ll speak about today, then, is a simple one. Using open source tools like <a href="http://audacity.sourceforge.net/">Audacity</a>, it’s easier than ever to play recordings backwards, to reverse a sound clip with the flip of a switch. I’ll touch just a bit on the history of such methods as they pertain to music and then speculate as to what they can tell us about approaches to thinking about literary sound recordings. I’m a modernist, and my examples will reflect this bias. My ultimate conclusions are as follows. First: reading backwards juxtaposed against audio reversal reveals the unique character of literary sound recordings to be simultaneously sounded and print, to be audiotextual objects as I call them. Second: deformance can offer us new modes for thinking about media failures and malfunctions that actually do exist constantly and all around us. In particular, audio deformance is something that the modernists were keenly interested in, and deformance as a practice can get us closer to the relationships they had with media.</p>

<p>So here is part of “Stairway to Heaven” backwards.</p>

<p><audio controls><source src="/MP3s/zeppelin_reversed.mp3" type="audio/mpeg"><source src="/ogg/zeppelin_reversed.ogg" type="audio/ogg">Your browser does not support this audio format.</audio></p>

<p>Source: <a href="http://youtu.be/zGsUcPdPWBg?t=47s">http://youtu.be/zGsUcPdPWBg?t=47s</a></p>

<p>Can’t you hear the devil? The “Stairway to Satan,” as I will call it, suggests that we can find new linguistic content in an already extant sound message. Detractors of the “Stairway to Satan” narrative (numerous on Youtube if you care to check them out) suggest that this is just a function of our minds wanting to make sense of chaos. Is this gibberish? Or is it a collection of scattered sound components that can be reconstituted into a whole? In <a href="http://www2.iath.virginia.edu/jjm2f/old/deform.html">Lisa Samuels and Jerome McGann’s essay on deformance</a> from which this panel takes its cue, they discuss reading Emily Dickinson’s poetry backwards in a mode not too far removed from this discussion. Reading backwards can throw into sharp relief the linguistic components, the very pieces that make up a poem, and at the end of the day, you still have the lines, the words, or even the component letters. It’s possible to reassemble these into semantic meanings.</p>

<p>But sound recordings are something different. They are bound in time in a different way. Daniel Albright in <em>Untwisting the Serpent</em> describes music by way of “Lessing’s famous distinction between the spatially juxtapositive arts of <em>nebeinander</em>, such as painting, sculpture, and architecture, and the temporally progressive arts of <em>nacheinander</em>, such as poetry and music” (9). Our experience of music and poetry depend upon their ability to move forward in time. To put the distinction in the context of deformance: you can move around a sculpture and view it from different angles, but it remains the same sculpture. Deform a musical recording by reversing its waveform, however, and you end with a different musical artifact entirely, one with different component parts. Hence, it can sound like gibberish.</p>

<p><img src="/images/waveform-large.jpg" width="50%" class="right"></p>

<p>Here is the waveform for the Zeppelin clip. The waveform here is a charting of intensity over time, and the reversal literally changes the original artifact. It’s a mirror image, but our ears are hard-pressed to be able to reconnect the new object to its original. Many kinds of deformance you can do on an audio recording would work in the same way – alter the pitches, smash them tighter, stretch them out, etc. You alter that wave, and you get something else entirely. At what point does it become something new?</p>

<p>But some reversed audio still sounds like a recognizable tune. Behind the “Stairway to Satan” claim is a long history behind it of musical reversal and mirroring. Musicians and listeners have been fascinated with the vectored nature of sound for centuries, and composers have experimented with reversal as a spur to creativity for ages. Take this melody.</p>

<p><video width="320" height="240" controls>
  <source src="/videos/canon-retrogrado.mp4" type="video/mp4">
Your browser does not support the video tag.
</video></p>

<p>Source: <a href="" title="http://www.teoria.com/en/reference/q-r/retrograde.php">http://www.teoria.com/en/reference/q-r/retrograde.php</a></p>

<p>The melody of the first ten measures is followed by a retrograde repetition of itself, meaning that it is a musical palindrome. All of the intervals of this first section become reversed and, if you were to fold the melody in upon itself, it would perfectly line up. Playing backwards is itself built into the creative process. The playback reflects this as the bouncing ball literally moves backwards on the page, but, if you were to write it out, it would look quite different. The kind of deformance that I am describing, that Zeppelin conspiracy theorists lament, and that Samuels and McGann suggest – it’s built into the music itself.</p>

<p>The melodic reversal of music like this works because, as Walter Pater taught us, music can be thought of as a “perfect identification of matter and form.&#8221; Flip the melody and you do not lose information, you get a new melody. The new object is still discernible as music because it is new music. The addition of linguistic content complicates the question - phonemes when reversed do not necessarily and easily coordinate with other phonemes. A recorded object with linguistic content has two distinct characters, each of which overlap with the other. It’s an obvious point, but one that I think has profound implications.</p>

<p>In Langston Hughes’s 1958 recording of “Motto” in collaboration with Charles Mingus and Leonard Feather, we can start to approach some useful conclusions about what this might all mean. The excerpt starts with an instrumental section and then Hughes comes in. So keep in mind that, in the reversal, we’ll hear the poetry first and then the instrumental part.</p>

<p>&#8220;Motto&#8221;</p>

<p><audio controls><source src="/MP3s/5_motto.mp3" type="audio/mpeg"><source src="/ogg/5_motto.ogg" type="audio/ogg">Your browser does not support this audio format.</audio></p>

<p>&#8220;Motto&#8221; Reversed</p>

<p><audio controls><source src="/MP3s/motto_reversed.mp3" type="audio/mpeg"><source src="/ogg/motto_reversed.ogg" type="audio/ogg">Your browser does not support this audio format.</audio></p>

<p>The recording is a useful analogy for vocal sound recordings more generally in that it has two distinct pieces – a musical (non-verbal sound) component, and a recorded voice (with linguistic content). The two elements often intertwine and are not easily separated (this example not withstanding). You can hear, I think, the stark difference between the reversed poetic content by Hughes and the reversed instrumental content. Hughes reversed sounds like nonsense, while the saxophone in particular still sounds like something of a melody. The digital reversal of sound recordings treats them both as waveforms with no semantic content – it reverses them just as easily and happily as it would any other sound recording.</p>

<p>We might expect the practice of deformance to throw into sharp relief the status of these recordings as sound objects. The pops, silences, and phonetic meanings of a reading suddenly become especially salient, and we might expect this reversal to make us hyper-aware of their sounded nature. In theory the deformance of these recordings more easily allows us to practice what Charles Bernstein has called “close listening,” examining the sounded nature of these objects. But, as the sounds themselves become distorted almost beyond recognition, the method can only provide clues towards such a practice. We might gain general senses, as with the Hughes, of the general prominence of certain registers or frequencies, silences and gaps, or of sections that are particularly filled with sonic activity. All of these might provide hints of content that might bear out fruitful analysis when put forwards again.</p>

<p>Deformance of poetic recordings forces us to consider the nature of recorded literary recordings anew. We might extrapolate from the character of this recording that all recorded voices contain a linguistic element as well an audible one. Not fully audio nor fully textual artifacts, I want to say that they are, instead something we might call audiotextual, a term that Jason Camlot has recently used in relation to the classification of Victorian literary recordings as an expansion of McGann’s own historicist approach to textual criticism.</p>

<p><img src="/images/audiotextual.jpg" width="40%" class="right"></p>

<p>I want to use the term as a play on audiovisual to describe the state of such sound recordings. Like the Hughes recording, with both an instrumental, sound component as well as a linguistic one, audiotextual recordings exist in sound as well as in print. It’s a fairly simple idea, but I think it is one that often gets concerned as we discuss sound recordings. Literary sound recordings are not reducible to their relationship with a print text: they have both sounded <em>and</em> print components. Audiobooks, in particular, not being “poetic” often seem to get left out of close listenings and treated as mere reproductions of print texts. If you read the reviews of any Amazon audiobook or <a href="http://www.librivox.org">LibriVox</a> recording, you will see hundreds of people who expect an audiobook to be an unmediated, honest representation of the print origin. Audiotextual might be used equally to describe both Hughes’s literary sound recordings as well as Hughes’s poetry itself, saturated as it is with traces of the live performance techniques of jazz and blues musicians.</p>

<p>More profoundly, I think sound recording during the modernist period is an especially good candidate for deformative acts of listening and interpretation. It is well-known and often-noted that modernist authors were obsessed with the gramophone, but consider the nature of such representations. The gramophones are most often marked by the materiality of their failures. In the “Hades” episode of <em>Ulysses</em>, the machine disintegrates into parody at the very moment at which it is meant to revive the voice of a dead relative:  “After dinner on a Sunday. Put on poor old greatgrandfather Kraahraark! Hellohellohello amawfullyglad kraark awfullygladaseeagain hellohello amawf krpthsth” (114). Sound reproduction during the period was not marked by the high fidelity, by the ability to authentically reproduce a deceptively “real” recording of life. It is a flawed act marked, as in Joyce’s case, by skipping needles, locked grooves, and hissing machines. For Joyce, this means uncovering a renewed sense that sound recordings were imperfect things, themselves subject to deformation by their own young technology. Joyce thinks of the gramophone recording as an object that can reach back into the past. He does not play it backwards as such, but the very act of playing the voice reverses time itself. And it does so in a manner that deforms the recording, altering its shape and transmission as a natural and comical part of the playback process.</p>

<p>Woolf’s failing gramophone in <em>Between the Acts</em> draws the elements of my short talk together nicely and can act as a closing image. During the pageant play at the heart of the text, a malfunctioning gramophone provides musical and narrative accompaniment: “The gramophone gurgled Unity-Dispersity. It gurgled Un…dis…And ceased” (201). The words themselves break apart into component syllables; semantic meaning evaporates as the grain of language pushes to the surface, and the heard word gives way to the gurgling materiality of the record itself. Woolf makes us hear the sound of the words as bound with their meanings. Her gramophone falls into locked grooves throughout the novel, transfixing its listeners and forming a community out of the audience of listeners by expanding the time with which they engage with each other. Not reversing time, certainly, but she does meditate on the ability of a malfunctioning gramophone to create anew through performance and deformance.</p>

<p>For Joyce and Woolf, the machines fail as often as they succeed. Deformance is thoroughly entwined with such performances. We may even go so far as to say that sound reproduction of this sort is a always kind of deformance, that no media form provides a pure, unaltered transmission of its content. As a critical practice, deformance, a systematic and intentionally disruptive form of engagement with materials, actually gets us closer to the kinds of media relationships that these authors would have known. The practice can offer us new perspective on literary and sonic materials, sure, but it can also provide us with something older. Deformative listening then, might be a practice of recovery, of attempting to recreate the phenomenological experience of a 1920s gramophone listening. The devil in the recording proves to be not the sort that conspiracy theorists would have you believe. The darkness lurking beneath sound recordings, be they musical or literary in nature, is the shadow of the materials, their very real failures, and the deformance that has always been present anytime we put needle to disc.</p>

<p><strong>Works Cited</strong></p>

<ul>
<li>Albright, Daniel. <em>Untwisting the Serpent: Modernism in Music, Literature, and Other Arts</em>. Chicago, Ill: University of Chicago Press, 2000. Print.</li>
<li>Bernstein, Charles, ed. <em>Close Listening: Poetry and the Performed Word</em>. Oxford University Press, USA, 1998. Print.</li>
<li>Hughes, Langston, Leonard Feather, and Charles Mingus. <em>Weary Blues</em>. MGM, 1959. CD.</li>
<li>Joyce, James. <em>Ulysses</em>. Vintage, 1990. Print.</li>
<li>Pater, Walter. “<a href="http://www.victorianweb.org/authors/pater/renaissance/7.html">The School of Giorgione</a>.” <em>The Renaissance: Studies in Art and Poetry</em>. 1873. Web.</li>
<li>Woolf, Virginia. <em>Between the Acts</em>. New York: Harcourt Brace Jovanovich, 1969. Print.</li>
</ul>



</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2015/01/05/deformance/">Deformance</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-05T10:18:00-05:00" pubdate data-updated="true">Jan 5<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>[The following post is cross-listed on the <a href="http://ach.org/">ACH</a>&#8217;s blog. The post details the methods used in putting together a talk for MLA 15 that takes place in 212 VCC West at 12:00 PM on Friday, January 9th.]</p>

<p>My talk for the ACH’s panel at MLA 15 is entitled “The Devil in the Recording: Deformative Listening and Poetry.” I will be talking about the problems and affordances for deformance in the context of audio recordings, specifically those that have literary content. The particular method I will focus on is the reversal of audio recordings, taking my cue from the infamous claim that you can hear Satanic lyrics in Led Zeppelin’s “Stairway to Heaven” if you play the recording backwards. In the example below I will show how to reverse an audio file, and I will be working with Langston Hughes’s reading of “Motto” with Charles Mingus and Leonard Feather on his 1958 recording <em>Weary Blues</em>.</p>

<p>Professional-grade sound-editing software like <em><a href="http://www.avid.com/us/products/family/pro-tools/">Pro Tools</a></em> or <em><a href="https://www.apple.com/logic-pro/">Logic</a></em> give you the capacity to do a lot in the way of sound mixing and work with music, but I often find myself drowning in their limitless options. They are also quite expensive. <em><a href="http://audacity.sourceforge.net/">Audacity</a></em> is my audio editing software of choice: the tool is open source and, most importantly, fairly intuitive and easy to use. Audacity is somewhat more limited than other options, but it does what it can cleanly and intuitively.</p>

<p>To reverse an audio file, begin by opening that clip in <em>Audacity</em> in the same way that you would open a file in any other piece of software. You will get something that looks like this:</p>

<p><img src="/images/waveform.jpg" width="40%" class="right"></p>

<p>What you see here is a <a href="http://manual.audacityteam.org/o/man/audacity_waveform.html">waveform</a>, a way of graphically representing the audio file in way that allows you to manipulate it. The y-axis of the waveform corresponds to volume – the taller the waveform, the louder the sound file’s contents are at that particular moment in time. This can be a quick and easy way to identify chunks of activity by looking for spikes in the volume.</p>

<p><img src="/images/axes.jpg"></p>

<p>The x-axis represents time – the Hughes file I have sliced out is 46” long, and the program gives you a timeline along the top of the segment to situate you in the file. Clicking anywhere on the waveform will set the file playback to begin at that point, and you can click and drag to highlight a selection of the clip for processing.</p>

<p>To process the file, highlight the section that you want reversed. In this case, since we are working with the entire file, we will just select everything. Under the “effect” menu, <em>Audacity</em> gives you a range of options for remixing your sound data, but we want the “reverse” function.</p>

<p><img src="/images/reverse.jpg" width="40%" class="right"></p>

<p>Now you have a reversed file at your disposal. Sound tends to work in attack and decay, and much of the strangeness of a reversed recording comes from sounds increasing rather than fading in intensity over time. And, as I will discuss in my talk, the process throws into sharp relief the distinct character of recorded linguistic content.</p>

<p><em>Audacity</em> saves files in <em>Audacity</em> project formats by default, so you will need to export your file to a different file format if you want to play it in a media player. I tend to use both .ogg and .mp3 files for browser compatibility. <em>Audacity</em> will also give you the opportunity to input light metadata for your file before it exports in case you want to curate your file for inclusion in an archive or home-library.</p>

<p><img src="/images/export.jpg" width="40%" class="right"></p>

<p><em>Audacity</em> gives many other options for experimenting with sound remixing, distortion, and deformance that I would encourage you to explore. The software also gives you many options for working with sound files more generally. I have written <a href="http://bmw9t.github.io/blog/2013/11/13/audio-at-thatcampva/">elsewhere</a> about using Audacity to prepare sound files for research and presentation. Check out my other post if you want to learn more about how to slice out clips, mix together two sound files, or process DRM files.</p>
</div>
  
  


    </article>
  
  

    <article>
      
  <header>
    
      <h2 class="entry-title"><a href="/blog/2014/11/05/diss-talk-abstract/">Diss Talk Abstract</a></h2>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-05T11:55:00-05:00" pubdate data-updated="true">Nov 5<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>On Friday, November 7th I will be giving a talk to the UVA English Department entitled “The Joycean Record: Listening Patterns and Sound Coteries.&#8221; The talk is a reworking of material from one of my dissertation chapters that I originally presented at last year&#8217;s <em>MLA</em> meeting in Chicago.</p>

<p>Abstract:</p>

<p>Modernist authors famously gathered in a series of small coteries, intellectual clusters centered on the production and reception of their creations. Modernists frequently took to the microphone to record readings of their works as well, and the lives of such sound objects can offer us both new networks of modernist reception and distribution as well as a new conception of modernism’s engagement with sound technology based on lived practices. This talk places James Joyce alongside sociologies of record collecting and reception as a means of rethinking <em>Ulysses</em>’s engagement with sound recording technology as an ongoing, lived, and social practice. Doing so uncovers a new history of <em>Ulysses</em> as both participant in and subject of sound communities emerging during the twentieth century, as an object that coordinates networked sound production and reception. From Joyce’s network of friends and collaborators to the coterie that gathers around the production of the 2007 LibriVox recording of <em>Ulysses</em>, I suggest that group listening enabled by sound recording has always been vital to the life of Joyce’s text.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
     
     <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
  
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    
  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  <a rel="license" href="http://creativecommons.org/licenses/by/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by/3.0/80x15.png" /></a><br />This work is by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Brandon Walsh</span> unless otherwise noted and is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/3.0/deed.en_US">Creative Commons Attribution 3.0 Unported License</a>.
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a>.</span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'bmw9t';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://bmw9t.github.com/index.html';
        var disqus_url = 'http://bmw9t.github.com/index.html';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
